{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988ab225-f6f0-44b6-b24d-7d1374847765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "%matplotlib inline\n",
    "#A100 80GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f5cf08-0f69-4dc4-830d-ba271bd8ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "gpuid = 0\n",
    "torch.cuda.set_device(gpuid)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a32cb66-5320-421b-9259-880db0f5aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/shenwanxiang/Research/bidd-clsar/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde33631-dc5e-419f-b970-26e4b10535fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clsar.dataset import LSSNS, HSSMS\n",
    "from clsar.feature import Gen39AtomFeatures\n",
    "from clsar.model.model import ACANet_PNA, get_deg, _fix_reproducibility # model\n",
    "from clsar.model.loss import ACALoss, get_best_cliff\n",
    "_fix_reproducibility(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca7d324-4af1-4477-99c4-4b0a96157fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, aca_loss):\n",
    "\n",
    "    total_examples = 0\n",
    "    total_loss =  0    \n",
    "    total_tsm_loss = 0\n",
    "    total_reg_loss = 0  \n",
    "    \n",
    "    n_label_triplets = []\n",
    "    n_structure_triplets = []\n",
    "    n_triplets = []\n",
    "    n_hv_triplets = []\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions, embeddings = model(data.x.float(), data.edge_index, \n",
    "                                        data.edge_attr, data.batch)\n",
    "        \n",
    "        loss_out = aca_loss(labels = data.y, \n",
    "                            predictions = predictions,\n",
    "                            embeddings = embeddings,\n",
    "                            fingerprints = data.fp)\n",
    "        \n",
    "        loss, reg_loss, tsm_loss,  N_Y_ACTs, N_S_ACTs, N_ACTs, N_HV_ACTs = loss_out\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_tsm_loss += float(tsm_loss) * data.num_graphs        \n",
    "        total_reg_loss += float(reg_loss) * data.num_graphs        \n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "        n_label_triplets.append(int(N_Y_ACTs))\n",
    "        n_structure_triplets.append(int(N_S_ACTs))\n",
    "        n_triplets.append(int(N_ACTs))\n",
    "        n_hv_triplets.append(int(N_HV_ACTs))\n",
    "    \n",
    "    train_loss = total_loss / total_examples\n",
    "    total_tsm_loss = total_tsm_loss / total_examples\n",
    "    total_reg_loss = total_reg_loss / total_examples\n",
    "\n",
    "    n_label_triplets = int(sum(n_label_triplets) / (i+1))\n",
    "    n_structure_triplets = int(sum(n_structure_triplets) / (i+1))\n",
    "    n_triplets = int(sum(n_triplets) / (i+1))\n",
    "    n_hv_triplets = int(sum(n_hv_triplets) / (i+1))\n",
    "    \n",
    "    return train_loss, total_tsm_loss, total_reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(test_loader, model, aca_loss):\n",
    "    model.eval()\n",
    "    total_examples = 0\n",
    "    total_loss = 0\n",
    "    total_tsm_loss = 0\n",
    "    total_reg_loss = 0\n",
    "\n",
    "    n_label_triplets = []\n",
    "    n_structure_triplets = []\n",
    "    n_triplets = []\n",
    "    n_hv_triplets = []\n",
    "    \n",
    "    mse = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        predictions, embeddings = model(data.x.float(), data.edge_index,\n",
    "                                        data.edge_attr, data.batch)\n",
    "        loss_out = aca_loss(labels = data.y, \n",
    "                            predictions = predictions,\n",
    "                            embeddings = embeddings,\n",
    "                           fingerprints = data.fp)\n",
    "        \n",
    "        loss, reg_loss, tsm_loss,  N_Y_ACTs, N_S_ACTs, N_ACTs, N_HV_ACTs = loss_out\n",
    "\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_tsm_loss += float(tsm_loss) * data.num_graphs\n",
    "        total_reg_loss += float(reg_loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "        n_label_triplets.append(int(N_Y_ACTs))\n",
    "        n_structure_triplets.append(int(N_S_ACTs))\n",
    "        n_triplets.append(int(N_ACTs))\n",
    "        n_hv_triplets.append(int(N_HV_ACTs))\n",
    "\n",
    "        mse.append(F.mse_loss(predictions, data.y, reduction='none').cpu())\n",
    "\n",
    "    test_loss = total_loss / total_examples\n",
    "    total_tsm_loss = total_tsm_loss / total_examples\n",
    "    total_reg_loss = total_reg_loss / total_examples\n",
    "\n",
    "    n_label_triplets = int(sum(n_label_triplets) / (i+1))\n",
    "    n_structure_triplets = int(sum(n_structure_triplets) / (i+1))\n",
    "    n_triplets = int(sum(n_triplets) / (i+1))\n",
    "    n_hv_triplets = int(sum(n_hv_triplets) / (i+1))\n",
    "    \n",
    "    test_rmse = float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "    \n",
    "    return test_loss, total_tsm_loss, total_reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets, test_rmse\n",
    "\n",
    "\n",
    "\n",
    "def Test_performance(alpha=1.0, similarity_gate = True):\n",
    "    \n",
    "    model = ACANet_PNA(**pub_args, deg=deg).to(device)  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=10**-5)\n",
    "    aca_loss = ACALoss(alpha=alpha, \n",
    "                        cliff_lower = 1., \n",
    "                        cliff_upper = 1.,\n",
    "                        squared = False,\n",
    "                        similarity_gate = similarity_gate,\n",
    "                        similarity_neg = 0.8,\n",
    "                        similarity_pos = 0.2,\n",
    "                        dev_mode = True,)\n",
    "    \n",
    "    history = []\n",
    "    #ls_his = []\n",
    "    for epoch in range(1, epochs):\n",
    "        train_loss, tsm_loss, reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets = train(train_loader, model, optimizer, aca_loss)\n",
    "\n",
    "        _, _, _, _, _, _, train_n_hv_triplets, train_rmse = test(train_loader, model, aca_loss)\n",
    "        _, _, _, _, _, _, val_n_hv_triplets, val_rmse = test(val_loader, model, aca_loss)\n",
    "        _, _, _, _, _, _, test_n_hv_triplets, test_rmse = test(test_loader, model, aca_loss)\n",
    "\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f} tsm_loss: {tsm_loss:.4f} reg_loss: {reg_loss:.4f} '\n",
    "              f'N_Y: {n_label_triplets:03d} N_S: {n_structure_triplets:03d} N: {n_triplets:03d} N_HV: {n_hv_triplets:03d} '\n",
    "              f'Val: {val_rmse:.4f} Test: {test_rmse:.4f}')\n",
    "    \n",
    "        history.append({'Epoch':epoch, 'train_loss':train_loss, 'train_triplet_loss':tsm_loss,\n",
    "                        'train_reg_loss':reg_loss, 'val_rmse':val_rmse, \n",
    "                        'test_rmse':test_rmse, 'train_rmse':train_rmse,\n",
    "                        \n",
    "                        'n_label_triplets': n_label_triplets, \n",
    "                        'n_structure_triplets':n_structure_triplets,\n",
    "                        'n_triplets':n_triplets,\n",
    "                        'n_hv_triplets':n_hv_triplets,\n",
    "                        \n",
    "\n",
    "                        'train_n_hv_triplets':train_n_hv_triplets,\n",
    "                        'val_n_hv_triplets':val_n_hv_triplets,\n",
    "                        'test_n_hv_triplets':test_n_hv_triplets,\n",
    "                       \n",
    "                       })\n",
    "        #ls_his.append({'Epoch':epoch, 'mae_loss':float(mae_loss), 'triplet_loss':float(triplet_loss)})\n",
    "    dfh = pd.DataFrame(history)\n",
    "    return dfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa1d63b-0567-406f-9f48-291959b18978",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'CHEMBL3979_EC50'\n",
    "Dataset =  HSSMS #LSSNS \n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "\n",
    "pre_transform = Gen39AtomFeatures()\n",
    "in_channels = pre_transform.in_channels\n",
    "path = './data/'\n",
    "\n",
    "## model HPs\n",
    "pub_args = {'in_channels':pre_transform.in_channels, \n",
    "            'edge_dim':pre_transform.edge_dim,\n",
    "            'convs_layers': [64, 128, 256, 512],   \n",
    "            'dense_layers': [256, 128, 32], \n",
    "            'out_channels':1, \n",
    "            'aggregators': ['mean', 'min', 'max', 'sum','std'],\n",
    "            'scalers':['identity', 'amplification', 'attenuation'] ,\n",
    "            'dropout_p': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7b5051-3408-450a-9901-79b1042719d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset(path, name=dataset_name, pre_transform=pre_transform).shuffle(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6da88-ccba-4731-a70b-f53c5c006652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# train, valid, test splitting\n",
    "res1 = []\n",
    "res2 = []\n",
    "res3 = []\n",
    "for seed in [8, 16, 24, 42, 64, 128, 256, 512, 1024, 2048]: #, \n",
    "    dataset = Dataset(path, name=dataset_name, pre_transform=pre_transform).shuffle(42)\n",
    "    N = len(dataset) // 5\n",
    "    val_dataset = dataset[:N]\n",
    "    test_dataset = dataset[N:2 * N]\n",
    "    train_dataset = dataset[2 * N:]\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    deg = get_deg(train_dataset)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # With AC-Awareness ($\\alpha = 1$)\n",
    "    df1 = Test_performance(alpha=1.0, similarity_gate = False)\n",
    "    df1['seed'] = seed\n",
    "    # Without AC-Awareness ($\\alpha = 0$)\n",
    "    df2 = Test_performance(alpha=0.0, similarity_gate = False)\n",
    "    df2['seed'] = seed\n",
    "\n",
    "    # With AC-Awareness and structure gate\n",
    "    df3 = Test_performance(alpha=1.0, similarity_gate = True)\n",
    "    df3['seed'] = seed\n",
    "    \n",
    "    res1.append(df1)\n",
    "    res2.append(df2) #212814\n",
    "    res3.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59ad23-a5a4-4366-833d-001a20e59ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat(res1)\n",
    "df2 = pd.concat(res2)\n",
    "df3 = pd.concat(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31c76b-0328-4014-8c25-a783ad1a785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./with_aca.csv')\n",
    "df2.to_csv('./without_aca.csv')\n",
    "df3.to_csv('./without_aca_with_gate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995c527-19cf-43d0-ada5-b151a620b906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c7cc2-eb12-4d33-8446-0b8e3b4cd53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a95e88-f850-48a7-8f0b-f0fe3ed48878",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "colors = ['#FFE699','#00B0F0','red']\n",
    "\n",
    "y = 'val_rmse'\n",
    "\n",
    "n1 = r'With AC-awareness' # ($\\mathcal{L}_{mae}$)\n",
    "n2 = r'Without AC-awareness'\n",
    "n3 = r'With AC-awareness and structure gate'\n",
    "\n",
    "\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "#ax.set_ylim(0.60, 1.0)\n",
    "ax.set_ylabel('Validation RMSE')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#ax.set_xlim(1,800)\n",
    "\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "fig.savefig('./Validation_RMSE.svg', bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Validation_RMSE.pdf', bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae243a-9b9d-4001-baab-16b8750003a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110c566-a71d-4d5c-afe0-185322298de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ab1d9-b7b4-4ec4-bc0c-d46590478bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "y = 'test_rmse'\n",
    "\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "#ax.set_ylim(0.60, 1.0)\n",
    "ax.set_ylabel('Test RMSE')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#ax.set_xlim(1,800)\n",
    "\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "fig.savefig('./Test_RMSE.svg' , bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Test_RMSE.pdf' , bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7e564-cf50-4d1f-b7d0-c9a7fa127e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "\n",
    "y = 'train_n_hv_triplets'\n",
    "\n",
    "\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "ax.legend(loc='center', bbox_to_anchor=(0.55, 0.5))\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "ax.set_ylabel(\"No. of HV-ACTs ($M^'$)\")\n",
    "ax.set_xlabel('epochs')\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "#ax.set_xlim(-5,800)\n",
    "\n",
    "\n",
    "fig.savefig('./Number_of_mined_ACTs_during_training.svg' , bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Number_of_mined_ACTs_during_training.pdf' , bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b16ad-c854-408d-9fcc-9ec0014dc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "y = 'train_triplet_loss'\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "# ax.set_xlim(-5,800)\n",
    "# ax.set_ylim(-1,10)\n",
    "\n",
    "ax.set_ylabel('Training TSM Loss')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "fig.savefig('./Triplet_loss_during_training.svg', bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Triplet_loss_during_training.pdf', bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded27b9a-5db5-4c6d-a50f-018db4be7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "y = 'train_reg_loss'\n",
    "\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "#ax.set_ylim(0.0, 0.8)\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "ax.set_ylabel('Training MAE loss')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.legend(loc='center', bbox_to_anchor=(0.55, 0.5))\n",
    "\n",
    "#ax.set_xlim(1,800)\n",
    "\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "fig.savefig('./Train_mae_los.svg', bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Train_mae_los.pdf', bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314788a9-afe4-486c-a861-9e1c5708f870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f5326-f4d7-42ae-935c-c20f2df351a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8aa35-2eaa-4c90-8168-4d62ff358d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4f511-db6b-4395-b2bd-2e993b9167f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16898f-b4bb-46ae-8d18-229ad9ab42b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
