{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988ab225-f6f0-44b6-b24d-7d1374847765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "%matplotlib inline\n",
    "#A100 80GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f5cf08-0f69-4dc4-830d-ba271bd8ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "gpuid = 0\n",
    "torch.cuda.set_device(gpuid)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a32cb66-5320-421b-9259-880db0f5aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/mnt/cc/onlytest/NewNew_ACANet/ACANet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde33631-dc5e-419f-b970-26e4b10535fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clsar.dataset import LSSNS, HSSMS\n",
    "from clsar.feature import Gen39AtomFeatures, Gen39AtomFeatures_full\n",
    "from clsar.model.model import ACANet_PNA, get_deg, _fix_reproducibility # model\n",
    "from clsar.model.loss import ACALoss, get_best_cliff, get_best_structure_batch\n",
    "_fix_reproducibility(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca7d324-4af1-4477-99c4-4b0a96157fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, aca_loss):\n",
    "\n",
    "    total_examples = 0\n",
    "    total_loss =  0    \n",
    "    total_tsm_loss = 0\n",
    "    total_reg_loss = 0  \n",
    "    \n",
    "    n_label_triplets = []\n",
    "    n_structure_triplets = []\n",
    "    n_triplets = []\n",
    "    n_hv_triplets = []\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions, embeddings = model(data.x.float(), data.edge_index, \n",
    "                                        data.edge_attr, data.batch)\n",
    "        \n",
    "        loss_out = aca_loss(labels = data.y, \n",
    "                            predictions = predictions,\n",
    "                            embeddings = embeddings,\n",
    "                            fingerprints = data.fp, scaffolds=data.scaffold_fp, smiles=data.smiles)\n",
    "        \n",
    "        loss, reg_loss, tsm_loss,  N_Y_ACTs, N_S_ACTs, N_ACTs, N_HV_ACTs = loss_out\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_tsm_loss += float(tsm_loss) * data.num_graphs        \n",
    "        total_reg_loss += float(reg_loss) * data.num_graphs        \n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "        n_label_triplets.append(int(N_Y_ACTs))\n",
    "        n_structure_triplets.append(int(N_S_ACTs))\n",
    "        n_triplets.append(int(N_ACTs))\n",
    "        n_hv_triplets.append(int(N_HV_ACTs))\n",
    "    \n",
    "    train_loss = total_loss / total_examples\n",
    "    total_tsm_loss = total_tsm_loss / total_examples\n",
    "    total_reg_loss = total_reg_loss / total_examples\n",
    "\n",
    "    n_label_triplets = int(sum(n_label_triplets) / (i+1))\n",
    "    n_structure_triplets = int(sum(n_structure_triplets) / (i+1))\n",
    "    n_triplets = int(sum(n_triplets) / (i+1))\n",
    "    n_hv_triplets = int(sum(n_hv_triplets) / (i+1))\n",
    "    \n",
    "    return train_loss, total_tsm_loss, total_reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(test_loader, model, aca_loss):\n",
    "    model.eval()\n",
    "    total_examples = 0\n",
    "    total_loss = 0\n",
    "    total_tsm_loss = 0\n",
    "    total_reg_loss = 0\n",
    "\n",
    "    n_label_triplets = []\n",
    "    n_structure_triplets = []\n",
    "    n_triplets = []\n",
    "    n_hv_triplets = []\n",
    "    \n",
    "    mse = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        predictions, embeddings = model(data.x.float(), data.edge_index,\n",
    "                                        data.edge_attr, data.batch)\n",
    "        loss_out = aca_loss(labels = data.y, \n",
    "                            predictions = predictions,\n",
    "                            embeddings = embeddings,\n",
    "                           fingerprints = data.fp, scaffolds=data.scaffold_fp, smiles=data.smiles)\n",
    "        \n",
    "        loss, reg_loss, tsm_loss,  N_Y_ACTs, N_S_ACTs, N_ACTs, N_HV_ACTs = loss_out\n",
    "\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_tsm_loss += float(tsm_loss) * data.num_graphs\n",
    "        total_reg_loss += float(reg_loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "        n_label_triplets.append(int(N_Y_ACTs))\n",
    "        n_structure_triplets.append(int(N_S_ACTs))\n",
    "        n_triplets.append(int(N_ACTs))\n",
    "        n_hv_triplets.append(int(N_HV_ACTs))\n",
    "\n",
    "        mse.append(F.mse_loss(predictions, data.y, reduction='none').cpu())\n",
    "\n",
    "    test_loss = total_loss / total_examples\n",
    "    total_tsm_loss = total_tsm_loss / total_examples\n",
    "    total_reg_loss = total_reg_loss / total_examples\n",
    "\n",
    "    n_label_triplets = int(sum(n_label_triplets) / (i+1))\n",
    "    n_structure_triplets = int(sum(n_structure_triplets) / (i+1))\n",
    "    n_triplets = int(sum(n_triplets) / (i+1))\n",
    "    n_hv_triplets = int(sum(n_hv_triplets) / (i+1))\n",
    "    \n",
    "    test_rmse = float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "    \n",
    "    return test_loss, total_tsm_loss, total_reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets, test_rmse\n",
    "\n",
    "\n",
    "\n",
    "def Test_performance(alpha=1.0, similarity_gate = True):\n",
    "    _fix_reproducibility(42)\n",
    "    model = ACANet_PNA(**pub_args, deg=deg).to(device)  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=10**-5)\n",
    "    aca_loss = ACALoss(alpha=alpha, \n",
    "                        cliff_lower = 1., \n",
    "                        cliff_upper = 1.,\n",
    "                        squared = False,\n",
    "                        similarity_gate = similarity_gate,\n",
    "                        similarity_neg = 0.7, #0.\n",
    "                        similarity_pos = 0.3, #1\n",
    "                        dev_mode = True,)\n",
    "    \n",
    "    history = []\n",
    "    #ls_his = []\n",
    "    for epoch in range(1, epochs):\n",
    "        train_loss, tsm_loss, reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets = train(train_loader, model, optimizer, aca_loss)\n",
    "\n",
    "        _, _, _, _, _, _, train_n_hv_triplets, train_rmse = test(train_loader, model, aca_loss)\n",
    "        _, _, _, _, _, _, val_n_hv_triplets, val_rmse = test(val_loader, model, aca_loss)\n",
    "        _, _, _, _, _, _, test_n_hv_triplets, test_rmse = test(test_loader, model, aca_loss)\n",
    "\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f} tsm_loss: {tsm_loss:.4f} reg_loss: {reg_loss:.4f} '\n",
    "              f'N_Y: {n_label_triplets:03d} N_S: {n_structure_triplets:03d} N: {n_triplets:03d} N_HV: {n_hv_triplets:03d} '\n",
    "              f'Val: {val_rmse:.4f} Test: {test_rmse:.4f}')\n",
    "    \n",
    "        history.append({'Epoch':epoch, 'train_loss':train_loss, 'train_triplet_loss':tsm_loss,\n",
    "                        'train_reg_loss':reg_loss, 'val_rmse':val_rmse, \n",
    "                        'test_rmse':test_rmse, 'train_rmse':train_rmse,\n",
    "                        \n",
    "                        'n_label_triplets': n_label_triplets, \n",
    "                        'n_structure_triplets':n_structure_triplets,\n",
    "                        'n_triplets':n_triplets,\n",
    "                        'n_hv_triplets':n_hv_triplets,\n",
    "                        \n",
    "\n",
    "                        'train_n_hv_triplets':train_n_hv_triplets,\n",
    "                        'val_n_hv_triplets':val_n_hv_triplets,\n",
    "                        'test_n_hv_triplets':test_n_hv_triplets,\n",
    "                       \n",
    "                       })\n",
    "        #ls_his.append({'Epoch':epoch, 'mae_loss':float(mae_loss), 'triplet_loss':float(triplet_loss)})\n",
    "    dfh = pd.DataFrame(history)\n",
    "    return dfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa1d63b-0567-406f-9f48-291959b18978",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'CHEMBL3979_EC50'\n",
    "Dataset =  HSSMS #LSSNS \n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "\n",
    "pre_transform = Gen39AtomFeatures_full()\n",
    "in_channels = pre_transform.in_channels\n",
    "path = './data/'\n",
    "\n",
    "## model HPs\n",
    "pub_args = {'in_channels':pre_transform.in_channels, \n",
    "            'edge_dim':pre_transform.edge_dim,\n",
    "            'convs_layers': [64, 128, 256, 512],   \n",
    "            'dense_layers': [256, 128, 32], \n",
    "            'out_channels':1, \n",
    "            'aggregators': ['mean', 'min', 'max', 'sum','std'],\n",
    "            'scalers':['identity', 'amplification', 'attenuation'] ,\n",
    "            'dropout_p': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7b5051-3408-450a-9901-79b1042719d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cc/onlytest/NewNew_ACANet/ACANet/clsar/dataset/data.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset(path, name=dataset_name, pre_transform=pre_transform).shuffle(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008463ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[30, 39], edge_index=[2, 62], edge_attr=[62, 10], y=[1, 1], fp=[1, 1024], scaffold='O=C(NCCc1ccccc1)c1ccccc1', cliff=[1], split='train', y_nm=[1, 1], y_nm_lg=[1, 1], smiles='CCC(Cc1ccc(OC)c(C(=O)NCCc2ccc(C(F)(F)F)cc2)c1)C(=O)O', scaffold_fp=[1, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset(path, name=dataset_name, pre_transform=pre_transform)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f6da88-ccba-4731-a70b-f53c5c006652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/cc_home/anaconda3/envs/acanet2/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/raid/cc_home/anaconda3/envs/acanet2/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/raid/cc_home/anaconda3/envs/acanet2/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 10.1150 tsm_loss: 3.3647 reg_loss: 6.7503 N_Y: 407843 N_S: 1506499 N: 1547320 N_HV: 729402 Val: 6.9626 Test: 6.9831\n",
      "Epoch: 002, Loss: 7.5962 tsm_loss: 1.3666 reg_loss: 6.2297 N_Y: 403186 N_S: 1513246 N: 1552955 N_HV: 725854 Val: 6.9556 Test: 6.9763\n",
      "Epoch: 003, Loss: 6.6207 tsm_loss: 1.0271 reg_loss: 5.5936 N_Y: 405580 N_S: 1510121 N: 1550834 N_HV: 725345 Val: 6.9359 Test: 6.9569\n",
      "Epoch: 004, Loss: 5.5823 tsm_loss: 0.8794 reg_loss: 4.7029 N_Y: 406000 N_S: 1512838 N: 1552229 N_HV: 726852 Val: 6.8806 Test: 6.9024\n",
      "Epoch: 005, Loss: 4.2077 tsm_loss: 0.8907 reg_loss: 3.3170 N_Y: 406169 N_S: 1511585 N: 1551504 N_HV: 727297 Val: 6.7286 Test: 6.7514\n",
      "Epoch: 006, Loss: 2.4319 tsm_loss: 0.9872 reg_loss: 1.4447 N_Y: 404414 N_S: 1508748 N: 1549578 N_HV: 722867 Val: 6.2787 Test: 6.3021\n",
      "Epoch: 007, Loss: 1.8064 tsm_loss: 0.9169 reg_loss: 0.8895 N_Y: 405844 N_S: 1505225 N: 1545896 N_HV: 721423 Val: 5.1359 Test: 5.1560\n",
      "Epoch: 008, Loss: 1.6381 tsm_loss: 0.8440 reg_loss: 0.7941 N_Y: 406738 N_S: 1501614 N: 1544510 N_HV: 722564 Val: 3.6491 Test: 3.6578\n",
      "Epoch: 009, Loss: 1.4763 tsm_loss: 0.7067 reg_loss: 0.7697 N_Y: 405450 N_S: 1503261 N: 1545667 N_HV: 721235 Val: 2.5238 Test: 2.5257\n",
      "Epoch: 010, Loss: 1.4034 tsm_loss: 0.6550 reg_loss: 0.7484 N_Y: 406218 N_S: 1506937 N: 1546951 N_HV: 720836 Val: 1.7645 Test: 1.7552\n",
      "Epoch: 011, Loss: 1.3229 tsm_loss: 0.5979 reg_loss: 0.7250 N_Y: 405649 N_S: 1507360 N: 1547704 N_HV: 722799 Val: 1.2602 Test: 1.2405\n",
      "Epoch: 012, Loss: 1.2841 tsm_loss: 0.5819 reg_loss: 0.7022 N_Y: 406217 N_S: 1509408 N: 1549624 N_HV: 724628 Val: 0.9694 Test: 0.9502\n",
      "Epoch: 013, Loss: 1.2605 tsm_loss: 0.5557 reg_loss: 0.7048 N_Y: 406272 N_S: 1509408 N: 1548993 N_HV: 727882 Val: 0.8695 Test: 0.8712\n",
      "Epoch: 014, Loss: 1.2471 tsm_loss: 0.5473 reg_loss: 0.6998 N_Y: 408158 N_S: 1510360 N: 1550321 N_HV: 728725 Val: 0.8473 Test: 0.8401\n",
      "Epoch: 015, Loss: 1.2065 tsm_loss: 0.5183 reg_loss: 0.6883 N_Y: 406436 N_S: 1509919 N: 1550551 N_HV: 726293 Val: 0.8618 Test: 0.8395\n",
      "Epoch: 016, Loss: 1.1946 tsm_loss: 0.5167 reg_loss: 0.6779 N_Y: 404438 N_S: 1512120 N: 1550961 N_HV: 727075 Val: 0.8255 Test: 0.8382\n",
      "Epoch: 017, Loss: 1.1783 tsm_loss: 0.5130 reg_loss: 0.6652 N_Y: 406418 N_S: 1507065 N: 1547373 N_HV: 725648 Val: 0.8734 Test: 0.8658\n",
      "Epoch: 018, Loss: 1.1561 tsm_loss: 0.4937 reg_loss: 0.6623 N_Y: 404922 N_S: 1513032 N: 1552516 N_HV: 732069 Val: 0.8193 Test: 0.8209\n",
      "Epoch: 019, Loss: 1.1517 tsm_loss: 0.4963 reg_loss: 0.6553 N_Y: 405618 N_S: 1506705 N: 1547062 N_HV: 727210 Val: 0.8117 Test: 0.7974\n",
      "Epoch: 020, Loss: 1.1232 tsm_loss: 0.4873 reg_loss: 0.6359 N_Y: 407960 N_S: 1507299 N: 1547724 N_HV: 726292 Val: 0.8280 Test: 0.8209\n",
      "Epoch: 021, Loss: 1.0989 tsm_loss: 0.4633 reg_loss: 0.6356 N_Y: 405658 N_S: 1500581 N: 1542789 N_HV: 724417 Val: 0.7919 Test: 0.7928\n",
      "Epoch: 022, Loss: 1.0847 tsm_loss: 0.4600 reg_loss: 0.6247 N_Y: 405801 N_S: 1500733 N: 1541580 N_HV: 723466 Val: 0.7989 Test: 0.7887\n",
      "Epoch: 023, Loss: 1.0841 tsm_loss: 0.4766 reg_loss: 0.6074 N_Y: 406015 N_S: 1509827 N: 1549707 N_HV: 727621 Val: 0.7904 Test: 0.7835\n",
      "Epoch: 024, Loss: 1.0661 tsm_loss: 0.4625 reg_loss: 0.6036 N_Y: 407094 N_S: 1500664 N: 1542366 N_HV: 722124 Val: 0.7855 Test: 0.7936\n"
     ]
    }
   ],
   "source": [
    "# train, valid, test splitting\n",
    "res1 = []\n",
    "res2 = []\n",
    "res3 = []\n",
    "for seed in [8, 16, 24, 42, 64, 128, 256, 512, 1024, 2048]: #, \n",
    "    dataset = Dataset(path, name=dataset_name, pre_transform=pre_transform).shuffle(42)\n",
    "    N = len(dataset) // 5\n",
    "    val_dataset = dataset[:N]\n",
    "    test_dataset = dataset[N:2 * N]\n",
    "    train_dataset = dataset[2 * N:]\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    deg = get_deg(train_dataset)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # With AC-Awareness and structure gate\n",
    "    df3 = Test_performance(alpha=1.0, similarity_gate = True)\n",
    "    df3['seed'] = seed\n",
    "    \n",
    "    # With AC-Awareness ($\\alpha = 1$)\n",
    "    df1 = Test_performance(alpha=1.0, similarity_gate = False)\n",
    "    df1['seed'] = seed\n",
    "    # Without AC-Awareness ($\\alpha = 0$)\n",
    "    df2 = Test_performance(alpha=0.0, similarity_gate = False)\n",
    "    df2['seed'] = seed\n",
    "\n",
    "    \n",
    "    res1.append(df1)\n",
    "    res2.append(df2) #212814\n",
    "    res3.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706585de-fc76-487c-a8c9-f90a3cc76fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    res1.append(df1)\n",
    "    res2.append(df2) #212814\n",
    "    res3.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59ad23-a5a4-4366-833d-001a20e59ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat(res1)\n",
    "df2 = pd.concat(res2)\n",
    "df3 = pd.concat(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31c76b-0328-4014-8c25-a783ad1a785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./with_aca.csv')\n",
    "df2.to_csv('./without_aca.csv')\n",
    "df3.to_csv('./without_aca_with_gate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995c527-19cf-43d0-ada5-b151a620b906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a95e88-f850-48a7-8f0b-f0fe3ed48878",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "colors = ['#FFE699','#00B0F0','red']\n",
    "\n",
    "y = 'val_rmse'\n",
    "\n",
    "n1 = r'With AC-awareness' # ($\\mathcal{L}_{mae}$)\n",
    "n2 = r'Without AC-awareness'\n",
    "n3 = r'With AC-awareness and structure gate'\n",
    "\n",
    "\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "ax.set_ylim(0.60, 1.0)\n",
    "ax.set_ylabel('Validation RMSE')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#ax.set_xlim(1,800)\n",
    "\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "fig.savefig('./Validation_RMSE.svg', bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Validation_RMSE.pdf', bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae243a-9b9d-4001-baab-16b8750003a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110c566-a71d-4d5c-afe0-185322298de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ab1d9-b7b4-4ec4-bc0c-d46590478bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "y = 'test_rmse'\n",
    "\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "ax.set_ylim(0.60, 1.0)\n",
    "ax.set_ylabel('Test RMSE')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#ax.set_xlim(1,800)\n",
    "\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "fig.savefig('./Test_RMSE.svg' , bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Test_RMSE.pdf' , bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7e564-cf50-4d1f-b7d0-c9a7fa127e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "\n",
    "y = 'train_n_hv_triplets'\n",
    "\n",
    "\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "ax.legend(loc='center', bbox_to_anchor=(0.55, 0.5))\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "ax.set_ylabel(\"No. of HV-ACTs ($M^'$)\")\n",
    "ax.set_xlabel('epochs')\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "#ax.set_xlim(-5,800)\n",
    "\n",
    "\n",
    "fig.savefig('./Number_of_mined_ACTs_during_training.svg' , bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Number_of_mined_ACTs_during_training.pdf' , bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b16ad-c854-408d-9fcc-9ec0014dc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "y = 'train_triplet_loss'\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "# ax.set_xlim(-5,800)\n",
    "ax.set_ylim(-1,10)\n",
    "\n",
    "ax.set_ylabel('Training TSM Loss')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "fig.savefig('./Triplet_loss_during_training.svg', bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Triplet_loss_during_training.pdf', bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded27b9a-5db5-4c6d-a50f-018db4be7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "y = 'train_reg_loss'\n",
    "\n",
    "dfp = df2.groupby('Epoch').mean()[y].to_frame(name = n2).join(df1.groupby('Epoch').mean()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').mean()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "dfp_std = df2.groupby('Epoch').std()[y].to_frame(name = n2).join(df1.groupby('Epoch').std()[y].to_frame(name = n1)).rolling(1).mean().join(df3.groupby('Epoch').std()[y].to_frame(name = n3)).rolling(1).mean()\n",
    "\n",
    "dfp.plot(lw = 2, ax=ax,color = colors, alpha =1)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n1], (dfp + dfp_std)[n1], color=colors[1], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n2], (dfp + dfp_std)[n2], color=colors[0], alpha=0.2)\n",
    "ax.fill_between(dfp.index, (dfp - dfp_std)[n3], (dfp + dfp_std)[n3], color=colors[2], alpha=0.2)\n",
    "\n",
    "ax.set_ylim(0.0, 0.8)\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "ax.set_ylabel('Training MAE loss')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.legend(loc='center', bbox_to_anchor=(0.55, 0.5))\n",
    "\n",
    "#ax.set_xlim(1,800)\n",
    "\n",
    "ax.tick_params(left='off', labelleft='on', labelbottom='on', bottom = 'off',  pad=.5,)\n",
    "fig.savefig('./Train_mae_los.svg', bbox_inches='tight', dpi=400) \n",
    "fig.savefig('./Train_mae_los.pdf', bbox_inches='tight', dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314788a9-afe4-486c-a861-9e1c5708f870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f5326-f4d7-42ae-935c-c20f2df351a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8aa35-2eaa-4c90-8168-4d62ff358d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4f511-db6b-4395-b2bd-2e993b9167f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16898f-b4bb-46ae-8d18-229ad9ab42b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d62189-e6b5-4d5c-8e51-bafc0c9fe2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
