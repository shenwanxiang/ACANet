{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988ab225-f6f0-44b6-b24d-7d1374847765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "%matplotlib inline\n",
    "#A100 80GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f5cf08-0f69-4dc4-830d-ba271bd8ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "gpuid = 0\n",
    "torch.cuda.set_device(gpuid)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262db189-1b3f-468e-9bf5-6289fa415cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a32cb66-5320-421b-9259-880db0f5aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/shenwanxiang/Research/bidd-clsar/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde33631-dc5e-419f-b970-26e4b10535fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clsar.dataset import LSSNS, HSSMS\n",
    "from clsar.feature import Gen39AtomFeatures\n",
    "from clsar.model.model import ACANet_PNA, get_deg, _fix_reproducibility # model\n",
    "from clsar.model.loss import ACALoss, get_best_cliff, get_best_structure_batch\n",
    "_fix_reproducibility(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca7d324-4af1-4477-99c4-4b0a96157fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, aca_loss):\n",
    "\n",
    "    total_examples = 0\n",
    "    total_loss =  0    \n",
    "    total_tsm_loss = 0\n",
    "    total_reg_loss = 0  \n",
    "    \n",
    "    n_label_triplets = []\n",
    "    n_structure_triplets = []\n",
    "    n_triplets = []\n",
    "    n_hv_triplets = []\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions, embeddings = model(data.x.float(), data.edge_index, \n",
    "                                        data.edge_attr, data.batch)\n",
    "        \n",
    "        loss_out = aca_loss(labels = data.y, \n",
    "                            predictions = predictions,\n",
    "                            embeddings = embeddings,\n",
    "                            fps_smiles = data.fp_smiles,\n",
    "                            fps_scaffold = data.fp_scaffold,                           \n",
    "                            smiles_list = data.smiles,                           \n",
    "                           )\n",
    "        \n",
    "        \n",
    "        loss, reg_loss, tsm_loss,  N_Y_ACTs, N_S_ACTs, N_ACTs, N_HV_ACTs = loss_out\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_tsm_loss += float(tsm_loss) * data.num_graphs        \n",
    "        total_reg_loss += float(reg_loss) * data.num_graphs        \n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "        n_label_triplets.append(int(N_Y_ACTs))\n",
    "        n_structure_triplets.append(int(N_S_ACTs))\n",
    "        n_triplets.append(int(N_ACTs))\n",
    "        n_hv_triplets.append(int(N_HV_ACTs))\n",
    "    \n",
    "    train_loss = total_loss / total_examples\n",
    "    total_tsm_loss = total_tsm_loss / total_examples\n",
    "    total_reg_loss = total_reg_loss / total_examples\n",
    "\n",
    "    n_label_triplets = int(sum(n_label_triplets) / (i+1))\n",
    "    n_structure_triplets = int(sum(n_structure_triplets) / (i+1))\n",
    "    n_triplets = int(sum(n_triplets) / (i+1))\n",
    "    n_hv_triplets = int(sum(n_hv_triplets) / (i+1))\n",
    "    \n",
    "    return train_loss, total_tsm_loss, total_reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(test_loader, model, aca_loss):\n",
    "    model.eval()\n",
    "    total_examples = 0\n",
    "    total_loss = 0\n",
    "    total_tsm_loss = 0\n",
    "    total_reg_loss = 0\n",
    "\n",
    "    n_label_triplets = []\n",
    "    n_structure_triplets = []\n",
    "    n_triplets = []\n",
    "    n_hv_triplets = []\n",
    "    \n",
    "    mse = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        predictions, embeddings = model(data.x.float(), data.edge_index,\n",
    "                                        data.edge_attr, data.batch)\n",
    "        loss_out = aca_loss(labels = data.y, \n",
    "                            predictions = predictions,\n",
    "                            embeddings = embeddings,\n",
    "                            fps_smiles = data.fp_smiles,\n",
    "                            fps_scaffold = data.fp_scaffold,                           \n",
    "                            smiles_list = data.smiles,                           \n",
    "                           )\n",
    "        \n",
    "        \n",
    "        loss, reg_loss, tsm_loss,  N_Y_ACTs, N_S_ACTs, N_ACTs, N_HV_ACTs = loss_out\n",
    "\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_tsm_loss += float(tsm_loss) * data.num_graphs\n",
    "        total_reg_loss += float(reg_loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "        n_label_triplets.append(int(N_Y_ACTs))\n",
    "        n_structure_triplets.append(int(N_S_ACTs))\n",
    "        n_triplets.append(int(N_ACTs))\n",
    "        n_hv_triplets.append(int(N_HV_ACTs))\n",
    "\n",
    "        mse.append(F.mse_loss(predictions, data.y, reduction='none').cpu())\n",
    "\n",
    "    test_loss = total_loss / total_examples\n",
    "    total_tsm_loss = total_tsm_loss / total_examples\n",
    "    total_reg_loss = total_reg_loss / total_examples\n",
    "\n",
    "    n_label_triplets = int(sum(n_label_triplets) / (i+1))\n",
    "    n_structure_triplets = int(sum(n_structure_triplets) / (i+1))\n",
    "    n_triplets = int(sum(n_triplets) / (i+1))\n",
    "    n_hv_triplets = int(sum(n_hv_triplets) / (i+1))\n",
    "    \n",
    "    test_rmse = float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "    \n",
    "    return test_loss, total_tsm_loss, total_reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets, test_rmse\n",
    "\n",
    "\n",
    "\n",
    "def Test_performance(alpha=1.0, similarity_gate = True, gate_type = 'AND', similarity_neg = 0., similarity_pos = 1):\n",
    "    _fix_reproducibility(42)\n",
    "    model = ACANet_PNA(**pub_args, deg=deg).to(device)  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=10**-5)\n",
    "    aca_loss = ACALoss(alpha=alpha, \n",
    "                        cliff_lower = 1., \n",
    "                        cliff_upper = 1.,\n",
    "                        squared = False,\n",
    "                        similarity_gate = similarity_gate,\n",
    "                        similarity_neg = similarity_neg, #0.\n",
    "                        similarity_pos = similarity_pos, #1\n",
    "                        gate_type = gate_type,\n",
    "                        dev_mode = True,)\n",
    "    \n",
    "    history = []\n",
    "    #ls_his = []\n",
    "    for epoch in range(1, epochs):\n",
    "        train_loss, tsm_loss, reg_loss, n_label_triplets, n_structure_triplets, n_triplets, n_hv_triplets = train(train_loader, \n",
    "                                                                                                                  model, \n",
    "                                                                                                                  optimizer,\n",
    "                                                                                                                  aca_loss)\n",
    "\n",
    "        _, _, _, _, _, _, train_n_hv_triplets, train_rmse = test(train_loader, model, aca_loss)\n",
    "        _, _, _, _, _, _, val_n_hv_triplets, val_rmse = test(val_loader, model, aca_loss)\n",
    "        _, _, _, _, _, _, test_n_hv_triplets, test_rmse = test(test_loader, model, aca_loss)\n",
    "\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f} tsm_loss: {tsm_loss:.4f} reg_loss: {reg_loss:.4f} '\n",
    "              f'N_Y: {n_label_triplets:03d} N_S: {n_structure_triplets:03d} N: {n_triplets:03d} N_HV: {n_hv_triplets:03d} '\n",
    "              f'Val: {val_rmse:.4f} Test: {test_rmse:.4f}')\n",
    "    \n",
    "        history.append({'Epoch':epoch, 'train_loss':train_loss, 'train_triplet_loss':tsm_loss,\n",
    "                        'train_reg_loss':reg_loss, 'val_rmse':val_rmse, \n",
    "                        'test_rmse':test_rmse, 'train_rmse':train_rmse,\n",
    "                        \n",
    "                        'n_label_triplets': n_label_triplets, \n",
    "                        'n_structure_triplets':n_structure_triplets,\n",
    "                        'n_triplets':n_triplets,\n",
    "                        'n_hv_triplets':n_hv_triplets,\n",
    "                        \n",
    "\n",
    "                        'train_n_hv_triplets':train_n_hv_triplets,\n",
    "                        'val_n_hv_triplets':val_n_hv_triplets,\n",
    "                        'test_n_hv_triplets':test_n_hv_triplets,\n",
    "                        'alpha':alpha, 'similarity_gate':similarity_gate,\n",
    "                        'gate_type':gate_type, 'similarity_neg':similarity_neg,\n",
    "                        'similarity_pos':similarity_pos\n",
    "                       \n",
    "                       })\n",
    "        #ls_his.append({'Epoch':epoch, 'mae_loss':float(mae_loss), 'triplet_loss':float(triplet_loss)})\n",
    "    dfh = pd.DataFrame(history)\n",
    "    return dfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa1d63b-0567-406f-9f48-291959b18978",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'BRAF'\n",
    "Dataset =  LSSNS #LSSNS \n",
    "epochs = 300\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "\n",
    "pre_transform = Gen39AtomFeatures()\n",
    "in_channels = pre_transform.in_channels\n",
    "path = './data/'\n",
    "\n",
    "## model HPs\n",
    "pub_args = {'in_channels':pre_transform.in_channels, \n",
    "            'edge_dim':pre_transform.edge_dim,\n",
    "            'convs_layers': [64, 128, 256, 512],   \n",
    "            'dense_layers': [256, 128, 32], \n",
    "            'out_channels':1, \n",
    "            'aggregators': ['mean', 'min', 'max', 'sum','std'],\n",
    "            'scalers':['identity', 'amplification', 'attenuation'] ,\n",
    "            'dropout_p': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7b5051-3408-450a-9901-79b1042719d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://bidd-group.github.io/MPCD/dataset/LSSNS/BRAF.csv\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset(path, name=dataset_name, pre_transform=pre_transform).shuffle(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6da88-ccba-4731-a70b-f53c5c006652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 6.7996 tsm_loss: 0.0000 reg_loss: 6.7996 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7409 Test: 6.7409\n",
      "Epoch: 002, Loss: 6.5556 tsm_loss: 0.0000 reg_loss: 6.5556 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7400 Test: 6.7400\n",
      "Epoch: 003, Loss: 6.3399 tsm_loss: 0.0000 reg_loss: 6.3399 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7393 Test: 6.7393\n",
      "Epoch: 004, Loss: 6.1508 tsm_loss: 0.0000 reg_loss: 6.1508 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7389 Test: 6.7389\n",
      "Epoch: 005, Loss: 5.9816 tsm_loss: 0.0000 reg_loss: 5.9816 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7388 Test: 6.7388\n",
      "Epoch: 006, Loss: 5.8223 tsm_loss: 0.0000 reg_loss: 5.8223 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7387 Test: 6.7387\n",
      "Epoch: 007, Loss: 5.6683 tsm_loss: 0.0000 reg_loss: 5.6683 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7387 Test: 6.7387\n",
      "Epoch: 008, Loss: 5.5139 tsm_loss: 0.0000 reg_loss: 5.5139 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7387 Test: 6.7387\n",
      "Epoch: 009, Loss: 5.3571 tsm_loss: 0.0000 reg_loss: 5.3571 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7386 Test: 6.7386\n",
      "Epoch: 010, Loss: 5.1975 tsm_loss: 0.0000 reg_loss: 5.1975 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7385 Test: 6.7385\n",
      "Epoch: 011, Loss: 5.0326 tsm_loss: 0.0000 reg_loss: 5.0326 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7383 Test: 6.7383\n",
      "Epoch: 012, Loss: 4.8628 tsm_loss: 0.0000 reg_loss: 4.8628 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7378 Test: 6.7378\n",
      "Epoch: 013, Loss: 4.6859 tsm_loss: 0.0000 reg_loss: 4.6859 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7373 Test: 6.7373\n",
      "Epoch: 014, Loss: 4.5045 tsm_loss: 0.0000 reg_loss: 4.5045 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7368 Test: 6.7368\n",
      "Epoch: 015, Loss: 4.3193 tsm_loss: 0.0000 reg_loss: 4.3193 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7365 Test: 6.7365\n",
      "Epoch: 016, Loss: 4.1267 tsm_loss: 0.0000 reg_loss: 4.1267 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7362 Test: 6.7362\n",
      "Epoch: 017, Loss: 3.9181 tsm_loss: 0.0000 reg_loss: 3.9181 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7359 Test: 6.7359\n",
      "Epoch: 018, Loss: 3.6950 tsm_loss: 0.0000 reg_loss: 3.6950 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7354 Test: 6.7354\n",
      "Epoch: 019, Loss: 3.4655 tsm_loss: 0.0000 reg_loss: 3.4655 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7346 Test: 6.7346\n",
      "Epoch: 020, Loss: 3.2139 tsm_loss: 0.0000 reg_loss: 3.2139 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7336 Test: 6.7336\n",
      "Epoch: 021, Loss: 2.9508 tsm_loss: 0.0000 reg_loss: 2.9508 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7326 Test: 6.7326\n",
      "Epoch: 022, Loss: 2.6723 tsm_loss: 0.0000 reg_loss: 2.6723 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7315 Test: 6.7315\n",
      "Epoch: 023, Loss: 2.3730 tsm_loss: 0.0000 reg_loss: 2.3730 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7300 Test: 6.7300\n",
      "Epoch: 024, Loss: 2.0491 tsm_loss: 0.0000 reg_loss: 2.0491 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7280 Test: 6.7280\n",
      "Epoch: 025, Loss: 1.7064 tsm_loss: 0.0000 reg_loss: 1.7064 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7256 Test: 6.7256\n",
      "Epoch: 026, Loss: 1.3481 tsm_loss: 0.0000 reg_loss: 1.3481 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7226 Test: 6.7226\n",
      "Epoch: 027, Loss: 1.0050 tsm_loss: 0.0000 reg_loss: 1.0050 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7189 Test: 6.7189\n",
      "Epoch: 028, Loss: 0.7990 tsm_loss: 0.0000 reg_loss: 0.7990 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7098 Test: 6.7098\n",
      "Epoch: 029, Loss: 0.6439 tsm_loss: 0.0000 reg_loss: 0.6439 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.6936 Test: 6.6936\n",
      "Epoch: 030, Loss: 0.5785 tsm_loss: 0.0000 reg_loss: 0.5785 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.6658 Test: 6.6658\n",
      "Epoch: 031, Loss: 0.5449 tsm_loss: 0.0000 reg_loss: 0.5449 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.6213 Test: 6.6213\n",
      "Epoch: 032, Loss: 0.4428 tsm_loss: 0.0000 reg_loss: 0.4428 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.5597 Test: 6.5597\n",
      "Epoch: 033, Loss: 0.3405 tsm_loss: 0.0000 reg_loss: 0.3405 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.4919 Test: 6.4919\n",
      "Epoch: 034, Loss: 0.3197 tsm_loss: 0.0000 reg_loss: 0.3197 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.4178 Test: 6.4178\n",
      "Epoch: 035, Loss: 0.3107 tsm_loss: 0.0000 reg_loss: 0.3107 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.3257 Test: 6.3257\n",
      "Epoch: 036, Loss: 0.2647 tsm_loss: 0.0000 reg_loss: 0.2647 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.2113 Test: 6.2113\n",
      "Epoch: 037, Loss: 0.2539 tsm_loss: 0.0000 reg_loss: 0.2539 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.0910 Test: 6.0910\n",
      "Epoch: 038, Loss: 0.2257 tsm_loss: 0.0000 reg_loss: 0.2257 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.9507 Test: 5.9507\n",
      "Epoch: 039, Loss: 0.2091 tsm_loss: 0.0000 reg_loss: 0.2091 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.7954 Test: 5.7954\n",
      "Epoch: 040, Loss: 0.1908 tsm_loss: 0.0000 reg_loss: 0.1908 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.6380 Test: 5.6380\n",
      "Epoch: 041, Loss: 0.1886 tsm_loss: 0.0000 reg_loss: 0.1886 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.4832 Test: 5.4832\n",
      "Epoch: 042, Loss: 0.1738 tsm_loss: 0.0000 reg_loss: 0.1738 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.3307 Test: 5.3307\n",
      "Epoch: 043, Loss: 0.1684 tsm_loss: 0.0000 reg_loss: 0.1684 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.1473 Test: 5.1473\n",
      "Epoch: 044, Loss: 0.2023 tsm_loss: 0.0000 reg_loss: 0.2023 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 4.9414 Test: 4.9414\n",
      "Epoch: 045, Loss: 0.1640 tsm_loss: 0.0000 reg_loss: 0.1640 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 4.7010 Test: 4.7010\n",
      "Epoch: 046, Loss: 0.1512 tsm_loss: 0.0000 reg_loss: 0.1512 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 4.4882 Test: 4.4882\n",
      "Epoch: 047, Loss: 0.1677 tsm_loss: 0.0000 reg_loss: 0.1677 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 4.3179 Test: 4.3179\n",
      "Epoch: 048, Loss: 0.2221 tsm_loss: 0.0000 reg_loss: 0.2221 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 4.0890 Test: 4.0890\n",
      "Epoch: 049, Loss: 0.1617 tsm_loss: 0.0000 reg_loss: 0.1617 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 3.8811 Test: 3.8811\n",
      "Epoch: 050, Loss: 0.2137 tsm_loss: 0.0000 reg_loss: 0.2137 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 3.7234 Test: 3.7234\n",
      "Epoch: 051, Loss: 0.1952 tsm_loss: 0.0000 reg_loss: 0.1952 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 3.5641 Test: 3.5641\n",
      "Epoch: 052, Loss: 0.1568 tsm_loss: 0.0000 reg_loss: 0.1568 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 3.4104 Test: 3.4104\n",
      "Epoch: 053, Loss: 0.1904 tsm_loss: 0.0000 reg_loss: 0.1904 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 3.2290 Test: 3.2290\n",
      "Epoch: 054, Loss: 0.1481 tsm_loss: 0.0000 reg_loss: 0.1481 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 3.0576 Test: 3.0576\n",
      "Epoch: 055, Loss: 0.1796 tsm_loss: 0.0000 reg_loss: 0.1796 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 2.9063 Test: 2.9063\n",
      "Epoch: 056, Loss: 0.1370 tsm_loss: 0.0000 reg_loss: 0.1370 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 2.7736 Test: 2.7736\n",
      "Epoch: 057, Loss: 0.1542 tsm_loss: 0.0000 reg_loss: 0.1542 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 2.6589 Test: 2.6589\n",
      "Epoch: 058, Loss: 0.1571 tsm_loss: 0.0000 reg_loss: 0.1571 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 2.5610 Test: 2.5610\n",
      "Epoch: 059, Loss: 0.1381 tsm_loss: 0.0000 reg_loss: 0.1381 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 2.4435 Test: 2.4435\n",
      "Epoch: 060, Loss: 0.1372 tsm_loss: 0.0000 reg_loss: 0.1372 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 2.2895 Test: 2.2895\n",
      "Epoch: 061, Loss: 0.1339 tsm_loss: 0.0000 reg_loss: 0.1339 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 2.1176 Test: 2.1176\n",
      "Epoch: 062, Loss: 0.1379 tsm_loss: 0.0000 reg_loss: 0.1379 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.9570 Test: 1.9570\n",
      "Epoch: 063, Loss: 0.1326 tsm_loss: 0.0000 reg_loss: 0.1326 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.8039 Test: 1.8039\n",
      "Epoch: 064, Loss: 0.1323 tsm_loss: 0.0000 reg_loss: 0.1323 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.7077 Test: 1.7077\n",
      "Epoch: 065, Loss: 0.1237 tsm_loss: 0.0000 reg_loss: 0.1237 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.6784 Test: 1.6784\n",
      "Epoch: 066, Loss: 0.1148 tsm_loss: 0.0000 reg_loss: 0.1148 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.6188 Test: 1.6188\n",
      "Epoch: 067, Loss: 0.1238 tsm_loss: 0.0000 reg_loss: 0.1238 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.5380 Test: 1.5380\n",
      "Epoch: 068, Loss: 0.1184 tsm_loss: 0.0000 reg_loss: 0.1184 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.4807 Test: 1.4807\n",
      "Epoch: 069, Loss: 0.1413 tsm_loss: 0.0000 reg_loss: 0.1413 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.3774 Test: 1.3774\n",
      "Epoch: 070, Loss: 0.1070 tsm_loss: 0.0000 reg_loss: 0.1070 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.2712 Test: 1.2712\n",
      "Epoch: 071, Loss: 0.1300 tsm_loss: 0.0000 reg_loss: 0.1300 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.2372 Test: 1.2372\n",
      "Epoch: 072, Loss: 0.1179 tsm_loss: 0.0000 reg_loss: 0.1179 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.2247 Test: 1.2247\n",
      "Epoch: 073, Loss: 0.1446 tsm_loss: 0.0000 reg_loss: 0.1446 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.2052 Test: 1.2052\n",
      "Epoch: 074, Loss: 0.1131 tsm_loss: 0.0000 reg_loss: 0.1131 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.0907 Test: 1.0907\n",
      "Epoch: 075, Loss: 0.1342 tsm_loss: 0.0000 reg_loss: 0.1342 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.0419 Test: 1.0419\n",
      "Epoch: 076, Loss: 0.1156 tsm_loss: 0.0000 reg_loss: 0.1156 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 1.0745 Test: 1.0745\n",
      "Epoch: 077, Loss: 0.1423 tsm_loss: 0.0000 reg_loss: 0.1423 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.9801 Test: 0.9801\n",
      "Epoch: 078, Loss: 0.1445 tsm_loss: 0.0000 reg_loss: 0.1445 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.8336 Test: 0.8336\n",
      "Epoch: 079, Loss: 0.0957 tsm_loss: 0.0000 reg_loss: 0.0957 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.6991 Test: 0.6991\n",
      "Epoch: 080, Loss: 0.1353 tsm_loss: 0.0000 reg_loss: 0.1353 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.6539 Test: 0.6539\n",
      "Epoch: 081, Loss: 0.1055 tsm_loss: 0.0000 reg_loss: 0.1055 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.6204 Test: 0.6204\n",
      "Epoch: 082, Loss: 0.1277 tsm_loss: 0.0000 reg_loss: 0.1277 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.5933 Test: 0.5933\n",
      "Epoch: 083, Loss: 0.1258 tsm_loss: 0.0000 reg_loss: 0.1258 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.5090 Test: 0.5090\n",
      "Epoch: 084, Loss: 0.0949 tsm_loss: 0.0000 reg_loss: 0.0949 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4577 Test: 0.4577\n",
      "Epoch: 085, Loss: 0.1259 tsm_loss: 0.0000 reg_loss: 0.1259 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4711 Test: 0.4711\n",
      "Epoch: 086, Loss: 0.1022 tsm_loss: 0.0000 reg_loss: 0.1022 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4568 Test: 0.4568\n",
      "Epoch: 087, Loss: 0.1123 tsm_loss: 0.0000 reg_loss: 0.1123 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4094 Test: 0.4094\n",
      "Epoch: 088, Loss: 0.1145 tsm_loss: 0.0000 reg_loss: 0.1145 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3894 Test: 0.3894\n",
      "Epoch: 089, Loss: 0.0921 tsm_loss: 0.0000 reg_loss: 0.0921 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3989 Test: 0.3989\n",
      "Epoch: 090, Loss: 0.1032 tsm_loss: 0.0000 reg_loss: 0.1032 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4020 Test: 0.4020\n",
      "Epoch: 091, Loss: 0.0918 tsm_loss: 0.0000 reg_loss: 0.0918 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4257 Test: 0.4257\n",
      "Epoch: 092, Loss: 0.0974 tsm_loss: 0.0000 reg_loss: 0.0974 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4182 Test: 0.4182\n",
      "Epoch: 093, Loss: 0.0844 tsm_loss: 0.0000 reg_loss: 0.0844 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3909 Test: 0.3909\n",
      "Epoch: 094, Loss: 0.0955 tsm_loss: 0.0000 reg_loss: 0.0955 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4020 Test: 0.4020\n",
      "Epoch: 095, Loss: 0.0980 tsm_loss: 0.0000 reg_loss: 0.0980 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4101 Test: 0.4101\n",
      "Epoch: 096, Loss: 0.0811 tsm_loss: 0.0000 reg_loss: 0.0811 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4376 Test: 0.4376\n",
      "Epoch: 097, Loss: 0.0837 tsm_loss: 0.0000 reg_loss: 0.0837 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4440 Test: 0.4440\n",
      "Epoch: 098, Loss: 0.0897 tsm_loss: 0.0000 reg_loss: 0.0897 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4139 Test: 0.4139\n",
      "Epoch: 099, Loss: 0.0801 tsm_loss: 0.0000 reg_loss: 0.0801 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4160 Test: 0.4160\n",
      "Epoch: 100, Loss: 0.0856 tsm_loss: 0.0000 reg_loss: 0.0856 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4368 Test: 0.4368\n",
      "Epoch: 101, Loss: 0.0930 tsm_loss: 0.0000 reg_loss: 0.0930 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4200 Test: 0.4200\n",
      "Epoch: 102, Loss: 0.0812 tsm_loss: 0.0000 reg_loss: 0.0812 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4070 Test: 0.4070\n",
      "Epoch: 103, Loss: 0.0736 tsm_loss: 0.0000 reg_loss: 0.0736 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4219 Test: 0.4219\n",
      "Epoch: 104, Loss: 0.0949 tsm_loss: 0.0000 reg_loss: 0.0949 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4076 Test: 0.4076\n",
      "Epoch: 105, Loss: 0.0938 tsm_loss: 0.0000 reg_loss: 0.0938 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4220 Test: 0.4220\n",
      "Epoch: 106, Loss: 0.0771 tsm_loss: 0.0000 reg_loss: 0.0771 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4310 Test: 0.4310\n",
      "Epoch: 107, Loss: 0.1082 tsm_loss: 0.0000 reg_loss: 0.1082 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4127 Test: 0.4127\n",
      "Epoch: 108, Loss: 0.0877 tsm_loss: 0.0000 reg_loss: 0.0877 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3890 Test: 0.3890\n",
      "Epoch: 109, Loss: 0.1005 tsm_loss: 0.0000 reg_loss: 0.1005 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3863 Test: 0.3863\n",
      "Epoch: 110, Loss: 0.0922 tsm_loss: 0.0000 reg_loss: 0.0922 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3925 Test: 0.3925\n",
      "Epoch: 111, Loss: 0.0760 tsm_loss: 0.0000 reg_loss: 0.0760 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4265 Test: 0.4265\n",
      "Epoch: 112, Loss: 0.0817 tsm_loss: 0.0000 reg_loss: 0.0817 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4207 Test: 0.4207\n",
      "Epoch: 113, Loss: 0.0808 tsm_loss: 0.0000 reg_loss: 0.0808 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3811 Test: 0.3811\n",
      "Epoch: 114, Loss: 0.0749 tsm_loss: 0.0000 reg_loss: 0.0749 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3567 Test: 0.3567\n",
      "Epoch: 115, Loss: 0.0801 tsm_loss: 0.0000 reg_loss: 0.0801 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3860 Test: 0.3860\n",
      "Epoch: 116, Loss: 0.0762 tsm_loss: 0.0000 reg_loss: 0.0762 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4035 Test: 0.4035\n",
      "Epoch: 117, Loss: 0.0993 tsm_loss: 0.0000 reg_loss: 0.0993 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4548 Test: 0.4548\n",
      "Epoch: 118, Loss: 0.0887 tsm_loss: 0.0000 reg_loss: 0.0887 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4410 Test: 0.4410\n",
      "Epoch: 119, Loss: 0.1069 tsm_loss: 0.0000 reg_loss: 0.1069 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3685 Test: 0.3685\n",
      "Epoch: 120, Loss: 0.0732 tsm_loss: 0.0000 reg_loss: 0.0732 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3588 Test: 0.3588\n",
      "Epoch: 121, Loss: 0.0900 tsm_loss: 0.0000 reg_loss: 0.0900 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4046 Test: 0.4046\n",
      "Epoch: 122, Loss: 0.0881 tsm_loss: 0.0000 reg_loss: 0.0881 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4195 Test: 0.4195\n",
      "Epoch: 123, Loss: 0.0647 tsm_loss: 0.0000 reg_loss: 0.0647 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4190 Test: 0.4190\n",
      "Epoch: 124, Loss: 0.0905 tsm_loss: 0.0000 reg_loss: 0.0905 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4476 Test: 0.4476\n",
      "Epoch: 125, Loss: 0.0891 tsm_loss: 0.0000 reg_loss: 0.0891 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4090 Test: 0.4090\n",
      "Epoch: 126, Loss: 0.0669 tsm_loss: 0.0000 reg_loss: 0.0669 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3575 Test: 0.3575\n",
      "Epoch: 127, Loss: 0.0734 tsm_loss: 0.0000 reg_loss: 0.0734 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3497 Test: 0.3497\n",
      "Epoch: 128, Loss: 0.0862 tsm_loss: 0.0000 reg_loss: 0.0862 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3806 Test: 0.3806\n",
      "Epoch: 129, Loss: 0.0738 tsm_loss: 0.0000 reg_loss: 0.0738 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4142 Test: 0.4142\n",
      "Epoch: 130, Loss: 0.0902 tsm_loss: 0.0000 reg_loss: 0.0902 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3965 Test: 0.3965\n",
      "Epoch: 131, Loss: 0.0707 tsm_loss: 0.0000 reg_loss: 0.0707 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3720 Test: 0.3720\n",
      "Epoch: 132, Loss: 0.0793 tsm_loss: 0.0000 reg_loss: 0.0793 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3774 Test: 0.3774\n",
      "Epoch: 133, Loss: 0.0770 tsm_loss: 0.0000 reg_loss: 0.0770 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4005 Test: 0.4005\n",
      "Epoch: 134, Loss: 0.0661 tsm_loss: 0.0000 reg_loss: 0.0661 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4226 Test: 0.4226\n",
      "Epoch: 135, Loss: 0.0624 tsm_loss: 0.0000 reg_loss: 0.0624 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4183 Test: 0.4183\n",
      "Epoch: 136, Loss: 0.0924 tsm_loss: 0.0000 reg_loss: 0.0924 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4271 Test: 0.4271\n",
      "Epoch: 137, Loss: 0.0688 tsm_loss: 0.0000 reg_loss: 0.0688 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4274 Test: 0.4274\n",
      "Epoch: 138, Loss: 0.0706 tsm_loss: 0.0000 reg_loss: 0.0706 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4110 Test: 0.4110\n",
      "Epoch: 139, Loss: 0.0928 tsm_loss: 0.0000 reg_loss: 0.0928 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4193 Test: 0.4193\n",
      "Epoch: 140, Loss: 0.0686 tsm_loss: 0.0000 reg_loss: 0.0686 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4376 Test: 0.4376\n",
      "Epoch: 141, Loss: 0.0988 tsm_loss: 0.0000 reg_loss: 0.0988 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4074 Test: 0.4074\n",
      "Epoch: 142, Loss: 0.0749 tsm_loss: 0.0000 reg_loss: 0.0749 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3986 Test: 0.3986\n",
      "Epoch: 143, Loss: 0.1021 tsm_loss: 0.0000 reg_loss: 0.1021 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4264 Test: 0.4264\n",
      "Epoch: 144, Loss: 0.0830 tsm_loss: 0.0000 reg_loss: 0.0830 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4366 Test: 0.4366\n",
      "Epoch: 145, Loss: 0.0946 tsm_loss: 0.0000 reg_loss: 0.0946 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4271 Test: 0.4271\n",
      "Epoch: 146, Loss: 0.0827 tsm_loss: 0.0000 reg_loss: 0.0827 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4191 Test: 0.4191\n",
      "Epoch: 147, Loss: 0.0913 tsm_loss: 0.0000 reg_loss: 0.0913 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4020 Test: 0.4020\n",
      "Epoch: 148, Loss: 0.0969 tsm_loss: 0.0000 reg_loss: 0.0969 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4028 Test: 0.4028\n",
      "Epoch: 149, Loss: 0.0796 tsm_loss: 0.0000 reg_loss: 0.0796 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4220 Test: 0.4220\n",
      "Epoch: 150, Loss: 0.0722 tsm_loss: 0.0000 reg_loss: 0.0722 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4516 Test: 0.4516\n",
      "Epoch: 151, Loss: 0.0734 tsm_loss: 0.0000 reg_loss: 0.0734 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4467 Test: 0.4467\n",
      "Epoch: 152, Loss: 0.0733 tsm_loss: 0.0000 reg_loss: 0.0733 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4127 Test: 0.4127\n",
      "Epoch: 153, Loss: 0.0618 tsm_loss: 0.0000 reg_loss: 0.0618 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4089 Test: 0.4089\n",
      "Epoch: 154, Loss: 0.0794 tsm_loss: 0.0000 reg_loss: 0.0794 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4118 Test: 0.4118\n",
      "Epoch: 155, Loss: 0.0737 tsm_loss: 0.0000 reg_loss: 0.0737 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3966 Test: 0.3966\n",
      "Epoch: 156, Loss: 0.0711 tsm_loss: 0.0000 reg_loss: 0.0711 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4029 Test: 0.4029\n",
      "Epoch: 157, Loss: 0.0746 tsm_loss: 0.0000 reg_loss: 0.0746 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3971 Test: 0.3971\n",
      "Epoch: 158, Loss: 0.0650 tsm_loss: 0.0000 reg_loss: 0.0650 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3957 Test: 0.3957\n",
      "Epoch: 159, Loss: 0.0802 tsm_loss: 0.0000 reg_loss: 0.0802 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3788 Test: 0.3788\n",
      "Epoch: 160, Loss: 0.0674 tsm_loss: 0.0000 reg_loss: 0.0674 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3915 Test: 0.3915\n",
      "Epoch: 161, Loss: 0.0846 tsm_loss: 0.0000 reg_loss: 0.0846 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4000 Test: 0.4000\n",
      "Epoch: 162, Loss: 0.0585 tsm_loss: 0.0000 reg_loss: 0.0585 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3822 Test: 0.3822\n",
      "Epoch: 163, Loss: 0.0636 tsm_loss: 0.0000 reg_loss: 0.0636 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3792 Test: 0.3792\n",
      "Epoch: 164, Loss: 0.0772 tsm_loss: 0.0000 reg_loss: 0.0772 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3782 Test: 0.3782\n",
      "Epoch: 165, Loss: 0.0597 tsm_loss: 0.0000 reg_loss: 0.0597 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3785 Test: 0.3785\n",
      "Epoch: 166, Loss: 0.0630 tsm_loss: 0.0000 reg_loss: 0.0630 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3794 Test: 0.3794\n",
      "Epoch: 167, Loss: 0.0760 tsm_loss: 0.0000 reg_loss: 0.0760 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3694 Test: 0.3694\n",
      "Epoch: 168, Loss: 0.0583 tsm_loss: 0.0000 reg_loss: 0.0583 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3960 Test: 0.3960\n",
      "Epoch: 169, Loss: 0.0718 tsm_loss: 0.0000 reg_loss: 0.0718 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4041 Test: 0.4041\n",
      "Epoch: 170, Loss: 0.0705 tsm_loss: 0.0000 reg_loss: 0.0705 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4038 Test: 0.4038\n",
      "Epoch: 171, Loss: 0.0633 tsm_loss: 0.0000 reg_loss: 0.0633 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3872 Test: 0.3872\n",
      "Epoch: 172, Loss: 0.0620 tsm_loss: 0.0000 reg_loss: 0.0620 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3587 Test: 0.3587\n",
      "Epoch: 173, Loss: 0.0614 tsm_loss: 0.0000 reg_loss: 0.0614 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3605 Test: 0.3605\n",
      "Epoch: 174, Loss: 0.0569 tsm_loss: 0.0000 reg_loss: 0.0569 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3856 Test: 0.3856\n",
      "Epoch: 175, Loss: 0.0510 tsm_loss: 0.0000 reg_loss: 0.0510 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4053 Test: 0.4053\n",
      "Epoch: 176, Loss: 0.0552 tsm_loss: 0.0000 reg_loss: 0.0552 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4201 Test: 0.4201\n",
      "Epoch: 177, Loss: 0.0630 tsm_loss: 0.0000 reg_loss: 0.0630 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3887 Test: 0.3887\n",
      "Epoch: 178, Loss: 0.0471 tsm_loss: 0.0000 reg_loss: 0.0471 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3849 Test: 0.3849\n",
      "Epoch: 179, Loss: 0.0592 tsm_loss: 0.0000 reg_loss: 0.0592 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3936 Test: 0.3936\n",
      "Epoch: 180, Loss: 0.0534 tsm_loss: 0.0000 reg_loss: 0.0534 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3995 Test: 0.3995\n",
      "Epoch: 181, Loss: 0.0589 tsm_loss: 0.0000 reg_loss: 0.0589 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4247 Test: 0.4247\n",
      "Epoch: 182, Loss: 0.0585 tsm_loss: 0.0000 reg_loss: 0.0585 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4243 Test: 0.4243\n",
      "Epoch: 183, Loss: 0.0529 tsm_loss: 0.0000 reg_loss: 0.0529 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3963 Test: 0.3963\n",
      "Epoch: 184, Loss: 0.0618 tsm_loss: 0.0000 reg_loss: 0.0618 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3886 Test: 0.3886\n",
      "Epoch: 185, Loss: 0.0489 tsm_loss: 0.0000 reg_loss: 0.0489 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3940 Test: 0.3940\n",
      "Epoch: 186, Loss: 0.0644 tsm_loss: 0.0000 reg_loss: 0.0644 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3979 Test: 0.3979\n",
      "Epoch: 187, Loss: 0.0525 tsm_loss: 0.0000 reg_loss: 0.0525 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4274 Test: 0.4274\n",
      "Epoch: 188, Loss: 0.0527 tsm_loss: 0.0000 reg_loss: 0.0527 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4156 Test: 0.4156\n",
      "Epoch: 189, Loss: 0.0518 tsm_loss: 0.0000 reg_loss: 0.0518 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3819 Test: 0.3819\n",
      "Epoch: 190, Loss: 0.0653 tsm_loss: 0.0000 reg_loss: 0.0653 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3987 Test: 0.3987\n",
      "Epoch: 191, Loss: 0.0590 tsm_loss: 0.0000 reg_loss: 0.0590 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4056 Test: 0.4056\n",
      "Epoch: 192, Loss: 0.0471 tsm_loss: 0.0000 reg_loss: 0.0471 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3822 Test: 0.3822\n",
      "Epoch: 193, Loss: 0.0741 tsm_loss: 0.0000 reg_loss: 0.0741 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3791 Test: 0.3791\n",
      "Epoch: 194, Loss: 0.0505 tsm_loss: 0.0000 reg_loss: 0.0505 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3680 Test: 0.3680\n",
      "Epoch: 195, Loss: 0.0557 tsm_loss: 0.0000 reg_loss: 0.0557 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3841 Test: 0.3841\n",
      "Epoch: 196, Loss: 0.0519 tsm_loss: 0.0000 reg_loss: 0.0519 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3820 Test: 0.3820\n",
      "Epoch: 197, Loss: 0.0567 tsm_loss: 0.0000 reg_loss: 0.0567 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3800 Test: 0.3800\n",
      "Epoch: 198, Loss: 0.0481 tsm_loss: 0.0000 reg_loss: 0.0481 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3818 Test: 0.3818\n",
      "Epoch: 199, Loss: 0.0462 tsm_loss: 0.0000 reg_loss: 0.0462 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3910 Test: 0.3910\n",
      "Epoch: 200, Loss: 0.0478 tsm_loss: 0.0000 reg_loss: 0.0478 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3772 Test: 0.3772\n",
      "Epoch: 201, Loss: 0.0544 tsm_loss: 0.0000 reg_loss: 0.0544 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3695 Test: 0.3695\n",
      "Epoch: 202, Loss: 0.0429 tsm_loss: 0.0000 reg_loss: 0.0429 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3869 Test: 0.3869\n",
      "Epoch: 203, Loss: 0.0589 tsm_loss: 0.0000 reg_loss: 0.0589 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3874 Test: 0.3874\n",
      "Epoch: 204, Loss: 0.0488 tsm_loss: 0.0000 reg_loss: 0.0488 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3614 Test: 0.3614\n",
      "Epoch: 205, Loss: 0.0930 tsm_loss: 0.0000 reg_loss: 0.0930 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3614 Test: 0.3614\n",
      "Epoch: 206, Loss: 0.0537 tsm_loss: 0.0000 reg_loss: 0.0537 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3896 Test: 0.3896\n",
      "Epoch: 207, Loss: 0.0824 tsm_loss: 0.0000 reg_loss: 0.0824 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3944 Test: 0.3944\n",
      "Epoch: 208, Loss: 0.0668 tsm_loss: 0.0000 reg_loss: 0.0668 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3955 Test: 0.3955\n",
      "Epoch: 209, Loss: 0.0757 tsm_loss: 0.0000 reg_loss: 0.0757 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4010 Test: 0.4010\n",
      "Epoch: 210, Loss: 0.1014 tsm_loss: 0.0000 reg_loss: 0.1014 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3910 Test: 0.3910\n",
      "Epoch: 211, Loss: 0.0822 tsm_loss: 0.0000 reg_loss: 0.0822 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3861 Test: 0.3861\n",
      "Epoch: 212, Loss: 0.0702 tsm_loss: 0.0000 reg_loss: 0.0702 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3875 Test: 0.3875\n",
      "Epoch: 213, Loss: 0.0764 tsm_loss: 0.0000 reg_loss: 0.0764 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3903 Test: 0.3903\n",
      "Epoch: 214, Loss: 0.0556 tsm_loss: 0.0000 reg_loss: 0.0556 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4199 Test: 0.4199\n",
      "Epoch: 215, Loss: 0.0605 tsm_loss: 0.0000 reg_loss: 0.0605 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4322 Test: 0.4322\n",
      "Epoch: 216, Loss: 0.0666 tsm_loss: 0.0000 reg_loss: 0.0666 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4074 Test: 0.4074\n",
      "Epoch: 217, Loss: 0.0662 tsm_loss: 0.0000 reg_loss: 0.0662 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3883 Test: 0.3883\n",
      "Epoch: 218, Loss: 0.0481 tsm_loss: 0.0000 reg_loss: 0.0481 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4009 Test: 0.4009\n",
      "Epoch: 219, Loss: 0.0486 tsm_loss: 0.0000 reg_loss: 0.0486 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4195 Test: 0.4195\n",
      "Epoch: 220, Loss: 0.0515 tsm_loss: 0.0000 reg_loss: 0.0515 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4150 Test: 0.4150\n",
      "Epoch: 221, Loss: 0.0400 tsm_loss: 0.0000 reg_loss: 0.0400 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3793 Test: 0.3793\n",
      "Epoch: 222, Loss: 0.0451 tsm_loss: 0.0000 reg_loss: 0.0451 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3729 Test: 0.3729\n",
      "Epoch: 223, Loss: 0.0500 tsm_loss: 0.0000 reg_loss: 0.0500 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3890 Test: 0.3890\n",
      "Epoch: 224, Loss: 0.0468 tsm_loss: 0.0000 reg_loss: 0.0468 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4069 Test: 0.4069\n",
      "Epoch: 225, Loss: 0.0461 tsm_loss: 0.0000 reg_loss: 0.0461 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4073 Test: 0.4073\n",
      "Epoch: 226, Loss: 0.0394 tsm_loss: 0.0000 reg_loss: 0.0394 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3891 Test: 0.3891\n",
      "Epoch: 227, Loss: 0.0471 tsm_loss: 0.0000 reg_loss: 0.0471 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3836 Test: 0.3836\n",
      "Epoch: 228, Loss: 0.0511 tsm_loss: 0.0000 reg_loss: 0.0511 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3965 Test: 0.3965\n",
      "Epoch: 229, Loss: 0.0468 tsm_loss: 0.0000 reg_loss: 0.0468 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4052 Test: 0.4052\n",
      "Epoch: 230, Loss: 0.0468 tsm_loss: 0.0000 reg_loss: 0.0468 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3963 Test: 0.3963\n",
      "Epoch: 231, Loss: 0.0418 tsm_loss: 0.0000 reg_loss: 0.0418 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3734 Test: 0.3734\n",
      "Epoch: 232, Loss: 0.0440 tsm_loss: 0.0000 reg_loss: 0.0440 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3831 Test: 0.3831\n",
      "Epoch: 233, Loss: 0.0418 tsm_loss: 0.0000 reg_loss: 0.0418 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4020 Test: 0.4020\n",
      "Epoch: 234, Loss: 0.0446 tsm_loss: 0.0000 reg_loss: 0.0446 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3844 Test: 0.3844\n",
      "Epoch: 235, Loss: 0.0744 tsm_loss: 0.0000 reg_loss: 0.0744 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4030 Test: 0.4030\n",
      "Epoch: 236, Loss: 0.0506 tsm_loss: 0.0000 reg_loss: 0.0506 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3731 Test: 0.3731\n",
      "Epoch: 237, Loss: 0.0445 tsm_loss: 0.0000 reg_loss: 0.0445 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3859 Test: 0.3859\n",
      "Epoch: 238, Loss: 0.0780 tsm_loss: 0.0000 reg_loss: 0.0780 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3767 Test: 0.3767\n",
      "Epoch: 239, Loss: 0.0543 tsm_loss: 0.0000 reg_loss: 0.0543 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3685 Test: 0.3685\n",
      "Epoch: 240, Loss: 0.0938 tsm_loss: 0.0000 reg_loss: 0.0938 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3715 Test: 0.3715\n",
      "Epoch: 241, Loss: 0.0690 tsm_loss: 0.0000 reg_loss: 0.0690 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3715 Test: 0.3715\n",
      "Epoch: 242, Loss: 0.0929 tsm_loss: 0.0000 reg_loss: 0.0929 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3916 Test: 0.3916\n",
      "Epoch: 243, Loss: 0.0562 tsm_loss: 0.0000 reg_loss: 0.0562 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3919 Test: 0.3919\n",
      "Epoch: 244, Loss: 0.1030 tsm_loss: 0.0000 reg_loss: 0.1030 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4093 Test: 0.4093\n",
      "Epoch: 245, Loss: 0.0857 tsm_loss: 0.0000 reg_loss: 0.0857 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4446 Test: 0.4446\n",
      "Epoch: 246, Loss: 0.0789 tsm_loss: 0.0000 reg_loss: 0.0789 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4170 Test: 0.4170\n",
      "Epoch: 247, Loss: 0.0846 tsm_loss: 0.0000 reg_loss: 0.0846 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3900 Test: 0.3900\n",
      "Epoch: 248, Loss: 0.0591 tsm_loss: 0.0000 reg_loss: 0.0591 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3986 Test: 0.3986\n",
      "Epoch: 249, Loss: 0.0744 tsm_loss: 0.0000 reg_loss: 0.0744 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3908 Test: 0.3908\n",
      "Epoch: 250, Loss: 0.0501 tsm_loss: 0.0000 reg_loss: 0.0501 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4148 Test: 0.4148\n",
      "Epoch: 251, Loss: 0.0615 tsm_loss: 0.0000 reg_loss: 0.0615 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4090 Test: 0.4090\n",
      "Epoch: 252, Loss: 0.0563 tsm_loss: 0.0000 reg_loss: 0.0563 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3965 Test: 0.3965\n",
      "Epoch: 253, Loss: 0.0601 tsm_loss: 0.0000 reg_loss: 0.0601 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3996 Test: 0.3996\n",
      "Epoch: 254, Loss: 0.0687 tsm_loss: 0.0000 reg_loss: 0.0687 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3765 Test: 0.3765\n",
      "Epoch: 255, Loss: 0.0593 tsm_loss: 0.0000 reg_loss: 0.0593 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3804 Test: 0.3804\n",
      "Epoch: 256, Loss: 0.0719 tsm_loss: 0.0000 reg_loss: 0.0719 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3852 Test: 0.3852\n",
      "Epoch: 257, Loss: 0.0614 tsm_loss: 0.0000 reg_loss: 0.0614 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3715 Test: 0.3715\n",
      "Epoch: 258, Loss: 0.0645 tsm_loss: 0.0000 reg_loss: 0.0645 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3782 Test: 0.3782\n",
      "Epoch: 259, Loss: 0.0597 tsm_loss: 0.0000 reg_loss: 0.0597 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3720 Test: 0.3720\n",
      "Epoch: 260, Loss: 0.0693 tsm_loss: 0.0000 reg_loss: 0.0693 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3825 Test: 0.3825\n",
      "Epoch: 261, Loss: 0.0606 tsm_loss: 0.0000 reg_loss: 0.0606 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3974 Test: 0.3974\n",
      "Epoch: 262, Loss: 0.0721 tsm_loss: 0.0000 reg_loss: 0.0721 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3869 Test: 0.3869\n",
      "Epoch: 263, Loss: 0.0610 tsm_loss: 0.0000 reg_loss: 0.0610 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3768 Test: 0.3768\n",
      "Epoch: 264, Loss: 0.0709 tsm_loss: 0.0000 reg_loss: 0.0709 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3840 Test: 0.3840\n",
      "Epoch: 265, Loss: 0.0771 tsm_loss: 0.0000 reg_loss: 0.0771 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3777 Test: 0.3777\n",
      "Epoch: 266, Loss: 0.0540 tsm_loss: 0.0000 reg_loss: 0.0540 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3967 Test: 0.3967\n",
      "Epoch: 267, Loss: 0.0554 tsm_loss: 0.0000 reg_loss: 0.0554 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3887 Test: 0.3887\n",
      "Epoch: 268, Loss: 0.0660 tsm_loss: 0.0000 reg_loss: 0.0660 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3659 Test: 0.3659\n",
      "Epoch: 269, Loss: 0.0518 tsm_loss: 0.0000 reg_loss: 0.0518 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3473 Test: 0.3473\n",
      "Epoch: 270, Loss: 0.0733 tsm_loss: 0.0000 reg_loss: 0.0733 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3534 Test: 0.3534\n",
      "Epoch: 271, Loss: 0.0711 tsm_loss: 0.0000 reg_loss: 0.0711 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3669 Test: 0.3669\n",
      "Epoch: 272, Loss: 0.0519 tsm_loss: 0.0000 reg_loss: 0.0519 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3952 Test: 0.3952\n",
      "Epoch: 273, Loss: 0.0486 tsm_loss: 0.0000 reg_loss: 0.0486 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4190 Test: 0.4190\n",
      "Epoch: 274, Loss: 0.0584 tsm_loss: 0.0000 reg_loss: 0.0584 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3881 Test: 0.3881\n",
      "Epoch: 275, Loss: 0.0488 tsm_loss: 0.0000 reg_loss: 0.0488 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3670 Test: 0.3670\n",
      "Epoch: 276, Loss: 0.0655 tsm_loss: 0.0000 reg_loss: 0.0655 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3754 Test: 0.3754\n",
      "Epoch: 277, Loss: 0.0519 tsm_loss: 0.0000 reg_loss: 0.0519 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3896 Test: 0.3896\n",
      "Epoch: 278, Loss: 0.0628 tsm_loss: 0.0000 reg_loss: 0.0628 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.4068 Test: 0.4068\n",
      "Epoch: 279, Loss: 0.0475 tsm_loss: 0.0000 reg_loss: 0.0475 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3823 Test: 0.3823\n",
      "Epoch: 280, Loss: 0.0713 tsm_loss: 0.0000 reg_loss: 0.0713 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3693 Test: 0.3693\n",
      "Epoch: 281, Loss: 0.0475 tsm_loss: 0.0000 reg_loss: 0.0475 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3673 Test: 0.3673\n",
      "Epoch: 282, Loss: 0.0789 tsm_loss: 0.0000 reg_loss: 0.0789 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3686 Test: 0.3686\n",
      "Epoch: 283, Loss: 0.0631 tsm_loss: 0.0000 reg_loss: 0.0631 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3845 Test: 0.3845\n",
      "Epoch: 284, Loss: 0.0726 tsm_loss: 0.0000 reg_loss: 0.0726 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3806 Test: 0.3806\n",
      "Epoch: 285, Loss: 0.0751 tsm_loss: 0.0000 reg_loss: 0.0751 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3743 Test: 0.3743\n",
      "Epoch: 286, Loss: 0.0502 tsm_loss: 0.0000 reg_loss: 0.0502 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3781 Test: 0.3781\n",
      "Epoch: 287, Loss: 0.0791 tsm_loss: 0.0000 reg_loss: 0.0791 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3862 Test: 0.3862\n",
      "Epoch: 288, Loss: 0.0617 tsm_loss: 0.0000 reg_loss: 0.0617 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3857 Test: 0.3857\n",
      "Epoch: 289, Loss: 0.0646 tsm_loss: 0.0000 reg_loss: 0.0646 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3796 Test: 0.3796\n",
      "Epoch: 290, Loss: 0.0610 tsm_loss: 0.0000 reg_loss: 0.0610 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3823 Test: 0.3823\n",
      "Epoch: 291, Loss: 0.0614 tsm_loss: 0.0000 reg_loss: 0.0614 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3848 Test: 0.3847\n",
      "Epoch: 292, Loss: 0.0679 tsm_loss: 0.0000 reg_loss: 0.0679 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3849 Test: 0.3849\n",
      "Epoch: 293, Loss: 0.0514 tsm_loss: 0.0000 reg_loss: 0.0514 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3711 Test: 0.3711\n",
      "Epoch: 294, Loss: 0.0597 tsm_loss: 0.0000 reg_loss: 0.0597 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3528 Test: 0.3528\n",
      "Epoch: 295, Loss: 0.0496 tsm_loss: 0.0000 reg_loss: 0.0496 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3520 Test: 0.3520\n",
      "Epoch: 296, Loss: 0.0550 tsm_loss: 0.0000 reg_loss: 0.0550 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3572 Test: 0.3572\n",
      "Epoch: 297, Loss: 0.0563 tsm_loss: 0.0000 reg_loss: 0.0563 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3805 Test: 0.3805\n",
      "Epoch: 298, Loss: 0.0378 tsm_loss: 0.0000 reg_loss: 0.0378 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3968 Test: 0.3968\n",
      "Epoch: 299, Loss: 0.0430 tsm_loss: 0.0000 reg_loss: 0.0430 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 0.3869 Test: 0.3869\n",
      "Epoch: 001, Loss: 6.7961 tsm_loss: 0.0000 reg_loss: 6.7961 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7450 Test: 6.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 6.5495 tsm_loss: 0.0000 reg_loss: 6.5495 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7441 Test: 6.7441\n",
      "Epoch: 003, Loss: 6.3316 tsm_loss: 0.0000 reg_loss: 6.3316 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7435 Test: 6.7435\n",
      "Epoch: 004, Loss: 6.1463 tsm_loss: 0.0000 reg_loss: 6.1463 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7433 Test: 6.7433\n",
      "Epoch: 005, Loss: 5.9804 tsm_loss: 0.0000 reg_loss: 5.9804 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7433 Test: 6.7433\n",
      "Epoch: 006, Loss: 5.8250 tsm_loss: 0.0000 reg_loss: 5.8250 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7433 Test: 6.7433\n",
      "Epoch: 007, Loss: 5.6725 tsm_loss: 0.0000 reg_loss: 5.6725 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7433 Test: 6.7433\n",
      "Epoch: 008, Loss: 5.5169 tsm_loss: 0.0000 reg_loss: 5.5169 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7432 Test: 6.7432\n",
      "Epoch: 009, Loss: 5.3570 tsm_loss: 0.0000 reg_loss: 5.3570 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7433 Test: 6.7433\n",
      "Epoch: 010, Loss: 5.1944 tsm_loss: 0.0000 reg_loss: 5.1944 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7435 Test: 6.7435\n",
      "Epoch: 011, Loss: 5.0341 tsm_loss: 0.0000 reg_loss: 5.0341 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7435 Test: 6.7435\n",
      "Epoch: 012, Loss: 4.8695 tsm_loss: 0.0000 reg_loss: 4.8695 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7431 Test: 6.7431\n",
      "Epoch: 013, Loss: 4.6988 tsm_loss: 0.0000 reg_loss: 4.6988 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7426 Test: 6.7426\n",
      "Epoch: 014, Loss: 4.5196 tsm_loss: 0.0000 reg_loss: 4.5196 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7420 Test: 6.7420\n",
      "Epoch: 015, Loss: 4.3318 tsm_loss: 0.0000 reg_loss: 4.3318 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7415 Test: 6.7415\n",
      "Epoch: 016, Loss: 4.1274 tsm_loss: 0.0000 reg_loss: 4.1274 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7409 Test: 6.7409\n",
      "Epoch: 017, Loss: 3.9125 tsm_loss: 0.0000 reg_loss: 3.9125 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7400 Test: 6.7400\n",
      "Epoch: 018, Loss: 3.6897 tsm_loss: 0.0000 reg_loss: 3.6897 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7390 Test: 6.7390\n",
      "Epoch: 019, Loss: 3.4530 tsm_loss: 0.0000 reg_loss: 3.4530 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7377 Test: 6.7377\n",
      "Epoch: 020, Loss: 3.2078 tsm_loss: 0.0000 reg_loss: 3.2078 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7361 Test: 6.7361\n",
      "Epoch: 021, Loss: 2.9423 tsm_loss: 0.0000 reg_loss: 2.9423 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7344 Test: 6.7344\n",
      "Epoch: 022, Loss: 2.6570 tsm_loss: 0.0000 reg_loss: 2.6570 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7324 Test: 6.7324\n",
      "Epoch: 023, Loss: 2.3515 tsm_loss: 0.0000 reg_loss: 2.3515 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7302 Test: 6.7302\n",
      "Epoch: 024, Loss: 2.0241 tsm_loss: 0.0000 reg_loss: 2.0241 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7277 Test: 6.7277\n",
      "Epoch: 025, Loss: 1.6753 tsm_loss: 0.0000 reg_loss: 1.6753 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7244 Test: 6.7244\n",
      "Epoch: 026, Loss: 1.3140 tsm_loss: 0.0000 reg_loss: 1.3140 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7202 Test: 6.7202\n",
      "Epoch: 027, Loss: 0.9752 tsm_loss: 0.0000 reg_loss: 0.9752 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7146 Test: 6.7146\n",
      "Epoch: 028, Loss: 0.7809 tsm_loss: 0.0000 reg_loss: 0.7809 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.7024 Test: 6.7024\n",
      "Epoch: 029, Loss: 0.6789 tsm_loss: 0.0000 reg_loss: 0.6789 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.6804 Test: 6.6804\n",
      "Epoch: 030, Loss: 0.5586 tsm_loss: 0.0000 reg_loss: 0.5586 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.6488 Test: 6.6488\n",
      "Epoch: 031, Loss: 0.4758 tsm_loss: 0.0000 reg_loss: 0.4758 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.6019 Test: 6.6019\n",
      "Epoch: 032, Loss: 0.4037 tsm_loss: 0.0000 reg_loss: 0.4037 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.5292 Test: 6.5292\n",
      "Epoch: 033, Loss: 0.3877 tsm_loss: 0.0000 reg_loss: 0.3877 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.4342 Test: 6.4342\n",
      "Epoch: 034, Loss: 0.3389 tsm_loss: 0.0000 reg_loss: 0.3389 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.3117 Test: 6.3117\n",
      "Epoch: 035, Loss: 0.3414 tsm_loss: 0.0000 reg_loss: 0.3414 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.1640 Test: 6.1640\n",
      "Epoch: 036, Loss: 0.2844 tsm_loss: 0.0000 reg_loss: 0.2844 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 6.0228 Test: 6.0228\n",
      "Epoch: 037, Loss: 0.2796 tsm_loss: 0.0000 reg_loss: 0.2796 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 5.8518 Test: 5.8518\n",
      "Epoch: 038, Loss: 0.2462 tsm_loss: 0.0000 reg_loss: 0.2462 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 5.6941 Test: 5.6941\n",
      "Epoch: 039, Loss: 0.2225 tsm_loss: 0.0000 reg_loss: 0.2225 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 5.5354 Test: 5.5354\n",
      "Epoch: 040, Loss: 0.2092 tsm_loss: 0.0000 reg_loss: 0.2092 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 5.3722 Test: 5.3722\n",
      "Epoch: 041, Loss: 0.2088 tsm_loss: 0.0000 reg_loss: 0.2088 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 5.2246 Test: 5.2246\n",
      "Epoch: 042, Loss: 0.2152 tsm_loss: 0.0000 reg_loss: 0.2152 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 5.0620 Test: 5.0620\n",
      "Epoch: 043, Loss: 0.1782 tsm_loss: 0.0000 reg_loss: 0.1782 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 4.9288 Test: 4.9288\n",
      "Epoch: 044, Loss: 0.2026 tsm_loss: 0.0000 reg_loss: 0.2026 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 4.7553 Test: 4.7553\n",
      "Epoch: 045, Loss: 0.1778 tsm_loss: 0.0000 reg_loss: 0.1778 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 4.5618 Test: 4.5618\n",
      "Epoch: 046, Loss: 0.1802 tsm_loss: 0.0000 reg_loss: 0.1802 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 4.3977 Test: 4.3977\n",
      "Epoch: 047, Loss: 0.1695 tsm_loss: 0.0000 reg_loss: 0.1695 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 4.2008 Test: 4.2008\n",
      "Epoch: 048, Loss: 0.1648 tsm_loss: 0.0000 reg_loss: 0.1648 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 4.0377 Test: 4.0377\n",
      "Epoch: 049, Loss: 0.1636 tsm_loss: 0.0000 reg_loss: 0.1636 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 3.8675 Test: 3.8675\n",
      "Epoch: 050, Loss: 0.1491 tsm_loss: 0.0000 reg_loss: 0.1491 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 3.7453 Test: 3.7453\n",
      "Epoch: 051, Loss: 0.1443 tsm_loss: 0.0000 reg_loss: 0.1443 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 3.6272 Test: 3.6272\n",
      "Epoch: 052, Loss: 0.1375 tsm_loss: 0.0000 reg_loss: 0.1375 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 3.4787 Test: 3.4787\n",
      "Epoch: 053, Loss: 0.1384 tsm_loss: 0.0000 reg_loss: 0.1384 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 3.3150 Test: 3.3150\n",
      "Epoch: 054, Loss: 0.1421 tsm_loss: 0.0000 reg_loss: 0.1421 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 3.2124 Test: 3.2124\n",
      "Epoch: 055, Loss: 0.1459 tsm_loss: 0.0000 reg_loss: 0.1459 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.9920 Test: 2.9920\n",
      "Epoch: 056, Loss: 0.1833 tsm_loss: 0.0000 reg_loss: 0.1833 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.9050 Test: 2.9050\n",
      "Epoch: 057, Loss: 0.1512 tsm_loss: 0.0000 reg_loss: 0.1512 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.7776 Test: 2.7776\n",
      "Epoch: 058, Loss: 0.1312 tsm_loss: 0.0000 reg_loss: 0.1312 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.6810 Test: 2.6810\n",
      "Epoch: 059, Loss: 0.1282 tsm_loss: 0.0000 reg_loss: 0.1282 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.6206 Test: 2.6206\n",
      "Epoch: 060, Loss: 0.1332 tsm_loss: 0.0000 reg_loss: 0.1332 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.3805 Test: 2.3805\n",
      "Epoch: 061, Loss: 0.1310 tsm_loss: 0.0000 reg_loss: 0.1310 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.2827 Test: 2.2827\n",
      "Epoch: 062, Loss: 0.1406 tsm_loss: 0.0000 reg_loss: 0.1406 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.0456 Test: 2.0456\n",
      "Epoch: 063, Loss: 0.1544 tsm_loss: 0.0000 reg_loss: 0.1544 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 2.0007 Test: 2.0007\n",
      "Epoch: 064, Loss: 0.1190 tsm_loss: 0.0000 reg_loss: 0.1190 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 1.9186 Test: 1.9186\n",
      "Epoch: 065, Loss: 0.1410 tsm_loss: 0.0000 reg_loss: 0.1410 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 1.6211 Test: 1.6211\n",
      "Epoch: 066, Loss: 0.1537 tsm_loss: 0.0000 reg_loss: 0.1537 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 1.4813 Test: 1.4813\n",
      "Epoch: 067, Loss: 0.1366 tsm_loss: 0.0000 reg_loss: 0.1366 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 1.4140 Test: 1.4140\n",
      "Epoch: 068, Loss: 0.1389 tsm_loss: 0.0000 reg_loss: 0.1389 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 1.2537 Test: 1.2537\n",
      "Epoch: 069, Loss: 0.1403 tsm_loss: 0.0000 reg_loss: 0.1403 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 1.1106 Test: 1.1106\n",
      "Epoch: 070, Loss: 0.1259 tsm_loss: 0.0000 reg_loss: 0.1259 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 1.0687 Test: 1.0687\n",
      "Epoch: 071, Loss: 0.1264 tsm_loss: 0.0000 reg_loss: 0.1264 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 1.0532 Test: 1.0532\n",
      "Epoch: 072, Loss: 0.1281 tsm_loss: 0.0000 reg_loss: 0.1281 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.9436 Test: 0.9436\n",
      "Epoch: 073, Loss: 0.1220 tsm_loss: 0.0000 reg_loss: 0.1220 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.7680 Test: 0.7680\n",
      "Epoch: 074, Loss: 0.1112 tsm_loss: 0.0000 reg_loss: 0.1112 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.7536 Test: 0.7536\n",
      "Epoch: 075, Loss: 0.1137 tsm_loss: 0.0000 reg_loss: 0.1137 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.7444 Test: 0.7444\n",
      "Epoch: 076, Loss: 0.1113 tsm_loss: 0.0000 reg_loss: 0.1113 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.6304 Test: 0.6304\n",
      "Epoch: 077, Loss: 0.1080 tsm_loss: 0.0000 reg_loss: 0.1080 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5227 Test: 0.5227\n",
      "Epoch: 078, Loss: 0.1024 tsm_loss: 0.0000 reg_loss: 0.1024 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5091 Test: 0.5091\n",
      "Epoch: 079, Loss: 0.1076 tsm_loss: 0.0000 reg_loss: 0.1076 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3932 Test: 0.3932\n",
      "Epoch: 080, Loss: 0.1310 tsm_loss: 0.0000 reg_loss: 0.1310 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5171 Test: 0.5171\n",
      "Epoch: 081, Loss: 0.1380 tsm_loss: 0.0000 reg_loss: 0.1380 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4810 Test: 0.4810\n",
      "Epoch: 082, Loss: 0.0966 tsm_loss: 0.0000 reg_loss: 0.0966 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3973 Test: 0.3973\n",
      "Epoch: 083, Loss: 0.1426 tsm_loss: 0.0000 reg_loss: 0.1426 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5340 Test: 0.5340\n",
      "Epoch: 084, Loss: 0.1219 tsm_loss: 0.0000 reg_loss: 0.1219 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5985 Test: 0.5985\n",
      "Epoch: 085, Loss: 0.1126 tsm_loss: 0.0000 reg_loss: 0.1126 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4328 Test: 0.4328\n",
      "Epoch: 086, Loss: 0.1409 tsm_loss: 0.0000 reg_loss: 0.1409 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4575 Test: 0.4575\n",
      "Epoch: 087, Loss: 0.1182 tsm_loss: 0.0000 reg_loss: 0.1182 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5591 Test: 0.5591\n",
      "Epoch: 088, Loss: 0.1501 tsm_loss: 0.0000 reg_loss: 0.1501 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4473 Test: 0.4473\n",
      "Epoch: 089, Loss: 0.1402 tsm_loss: 0.0000 reg_loss: 0.1402 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3836 Test: 0.3836\n",
      "Epoch: 090, Loss: 0.1399 tsm_loss: 0.0000 reg_loss: 0.1399 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4975 Test: 0.4975\n",
      "Epoch: 091, Loss: 0.1231 tsm_loss: 0.0000 reg_loss: 0.1231 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4655 Test: 0.4655\n",
      "Epoch: 092, Loss: 0.1191 tsm_loss: 0.0000 reg_loss: 0.1191 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3407 Test: 0.3407\n",
      "Epoch: 093, Loss: 0.1248 tsm_loss: 0.0000 reg_loss: 0.1248 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3868 Test: 0.3868\n",
      "Epoch: 094, Loss: 0.1197 tsm_loss: 0.0000 reg_loss: 0.1197 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5184 Test: 0.5184\n",
      "Epoch: 095, Loss: 0.1129 tsm_loss: 0.0000 reg_loss: 0.1129 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4719 Test: 0.4719\n",
      "Epoch: 096, Loss: 0.1213 tsm_loss: 0.0000 reg_loss: 0.1213 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3967 Test: 0.3967\n",
      "Epoch: 097, Loss: 0.1087 tsm_loss: 0.0000 reg_loss: 0.1087 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3721 Test: 0.3721\n",
      "Epoch: 098, Loss: 0.1191 tsm_loss: 0.0000 reg_loss: 0.1191 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3056 Test: 0.3056\n",
      "Epoch: 099, Loss: 0.1082 tsm_loss: 0.0000 reg_loss: 0.1082 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3071 Test: 0.3071\n",
      "Epoch: 100, Loss: 0.1003 tsm_loss: 0.0000 reg_loss: 0.1003 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3146 Test: 0.3146\n",
      "Epoch: 101, Loss: 0.1238 tsm_loss: 0.0000 reg_loss: 0.1238 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2873 Test: 0.2873\n",
      "Epoch: 102, Loss: 0.0901 tsm_loss: 0.0000 reg_loss: 0.0901 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2803 Test: 0.2803\n",
      "Epoch: 103, Loss: 0.1048 tsm_loss: 0.0000 reg_loss: 0.1048 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3469 Test: 0.3469\n",
      "Epoch: 104, Loss: 0.1013 tsm_loss: 0.0000 reg_loss: 0.1013 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4260 Test: 0.4260\n",
      "Epoch: 105, Loss: 0.0929 tsm_loss: 0.0000 reg_loss: 0.0929 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4588 Test: 0.4588\n",
      "Epoch: 106, Loss: 0.0972 tsm_loss: 0.0000 reg_loss: 0.0972 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5108 Test: 0.5108\n",
      "Epoch: 107, Loss: 0.0931 tsm_loss: 0.0000 reg_loss: 0.0931 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4018 Test: 0.4018\n",
      "Epoch: 108, Loss: 0.0979 tsm_loss: 0.0000 reg_loss: 0.0979 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4108 Test: 0.4108\n",
      "Epoch: 109, Loss: 0.0899 tsm_loss: 0.0000 reg_loss: 0.0899 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3746 Test: 0.3746\n",
      "Epoch: 110, Loss: 0.0992 tsm_loss: 0.0000 reg_loss: 0.0992 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2874 Test: 0.2874\n",
      "Epoch: 111, Loss: 0.1025 tsm_loss: 0.0000 reg_loss: 0.1025 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3075 Test: 0.3075\n",
      "Epoch: 112, Loss: 0.0930 tsm_loss: 0.0000 reg_loss: 0.0930 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3146 Test: 0.3146\n",
      "Epoch: 113, Loss: 0.0907 tsm_loss: 0.0000 reg_loss: 0.0907 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3032 Test: 0.3032\n",
      "Epoch: 114, Loss: 0.0928 tsm_loss: 0.0000 reg_loss: 0.0928 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3349 Test: 0.3349\n",
      "Epoch: 115, Loss: 0.1115 tsm_loss: 0.0000 reg_loss: 0.1115 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3102 Test: 0.3102\n",
      "Epoch: 116, Loss: 0.0860 tsm_loss: 0.0000 reg_loss: 0.0860 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3217 Test: 0.3217\n",
      "Epoch: 117, Loss: 0.1005 tsm_loss: 0.0000 reg_loss: 0.1005 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3044 Test: 0.3044\n",
      "Epoch: 118, Loss: 0.1130 tsm_loss: 0.0000 reg_loss: 0.1130 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2944 Test: 0.2944\n",
      "Epoch: 119, Loss: 0.0866 tsm_loss: 0.0000 reg_loss: 0.0866 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4467 Test: 0.4467\n",
      "Epoch: 120, Loss: 0.1209 tsm_loss: 0.0000 reg_loss: 0.1209 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4283 Test: 0.4283\n",
      "Epoch: 121, Loss: 0.0908 tsm_loss: 0.0000 reg_loss: 0.0908 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3202 Test: 0.3202\n",
      "Epoch: 122, Loss: 0.1275 tsm_loss: 0.0000 reg_loss: 0.1275 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3438 Test: 0.3438\n",
      "Epoch: 123, Loss: 0.0952 tsm_loss: 0.0000 reg_loss: 0.0952 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3762 Test: 0.3762\n",
      "Epoch: 124, Loss: 0.1041 tsm_loss: 0.0000 reg_loss: 0.1041 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3317 Test: 0.3317\n",
      "Epoch: 125, Loss: 0.1076 tsm_loss: 0.0000 reg_loss: 0.1076 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3600 Test: 0.3600\n",
      "Epoch: 126, Loss: 0.0910 tsm_loss: 0.0000 reg_loss: 0.0910 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3995 Test: 0.3995\n",
      "Epoch: 127, Loss: 0.1128 tsm_loss: 0.0000 reg_loss: 0.1128 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3235 Test: 0.3235\n",
      "Epoch: 128, Loss: 0.1066 tsm_loss: 0.0000 reg_loss: 0.1066 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3090 Test: 0.3090\n",
      "Epoch: 129, Loss: 0.0975 tsm_loss: 0.0000 reg_loss: 0.0975 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3783 Test: 0.3783\n",
      "Epoch: 130, Loss: 0.0955 tsm_loss: 0.0000 reg_loss: 0.0955 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3897 Test: 0.3897\n",
      "Epoch: 131, Loss: 0.0936 tsm_loss: 0.0000 reg_loss: 0.0936 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3427 Test: 0.3427\n",
      "Epoch: 132, Loss: 0.1009 tsm_loss: 0.0000 reg_loss: 0.1009 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3851 Test: 0.3851\n",
      "Epoch: 133, Loss: 0.0860 tsm_loss: 0.0000 reg_loss: 0.0860 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5370 Test: 0.5370\n",
      "Epoch: 134, Loss: 0.1136 tsm_loss: 0.0000 reg_loss: 0.1136 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.5164 Test: 0.5164\n",
      "Epoch: 135, Loss: 0.0956 tsm_loss: 0.0000 reg_loss: 0.0956 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3966 Test: 0.3966\n",
      "Epoch: 136, Loss: 0.1116 tsm_loss: 0.0000 reg_loss: 0.1116 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3780 Test: 0.3780\n",
      "Epoch: 137, Loss: 0.1054 tsm_loss: 0.0000 reg_loss: 0.1054 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3448 Test: 0.3447\n",
      "Epoch: 138, Loss: 0.1077 tsm_loss: 0.0000 reg_loss: 0.1077 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2988 Test: 0.2988\n",
      "Epoch: 139, Loss: 0.0911 tsm_loss: 0.0000 reg_loss: 0.0911 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3199 Test: 0.3199\n",
      "Epoch: 140, Loss: 0.0873 tsm_loss: 0.0000 reg_loss: 0.0873 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3914 Test: 0.3914\n",
      "Epoch: 141, Loss: 0.0943 tsm_loss: 0.0000 reg_loss: 0.0943 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3805 Test: 0.3805\n",
      "Epoch: 142, Loss: 0.1062 tsm_loss: 0.0000 reg_loss: 0.1062 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3287 Test: 0.3287\n",
      "Epoch: 143, Loss: 0.0860 tsm_loss: 0.0000 reg_loss: 0.0860 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3197 Test: 0.3197\n",
      "Epoch: 144, Loss: 0.0849 tsm_loss: 0.0000 reg_loss: 0.0849 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3471 Test: 0.3471\n",
      "Epoch: 145, Loss: 0.1013 tsm_loss: 0.0000 reg_loss: 0.1013 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3385 Test: 0.3385\n",
      "Epoch: 146, Loss: 0.0795 tsm_loss: 0.0000 reg_loss: 0.0795 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3162 Test: 0.3162\n",
      "Epoch: 147, Loss: 0.0855 tsm_loss: 0.0000 reg_loss: 0.0855 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3321 Test: 0.3321\n",
      "Epoch: 148, Loss: 0.0961 tsm_loss: 0.0000 reg_loss: 0.0961 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3109 Test: 0.3109\n",
      "Epoch: 149, Loss: 0.0864 tsm_loss: 0.0000 reg_loss: 0.0864 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2938 Test: 0.2938\n",
      "Epoch: 150, Loss: 0.0779 tsm_loss: 0.0000 reg_loss: 0.0779 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2955 Test: 0.2955\n",
      "Epoch: 151, Loss: 0.0820 tsm_loss: 0.0000 reg_loss: 0.0820 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2998 Test: 0.2998\n",
      "Epoch: 152, Loss: 0.0770 tsm_loss: 0.0000 reg_loss: 0.0770 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3019 Test: 0.3019\n",
      "Epoch: 153, Loss: 0.0895 tsm_loss: 0.0000 reg_loss: 0.0895 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3002 Test: 0.3002\n",
      "Epoch: 154, Loss: 0.0822 tsm_loss: 0.0000 reg_loss: 0.0822 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2936 Test: 0.2936\n",
      "Epoch: 155, Loss: 0.0839 tsm_loss: 0.0000 reg_loss: 0.0839 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3744 Test: 0.3744\n",
      "Epoch: 156, Loss: 0.0924 tsm_loss: 0.0000 reg_loss: 0.0924 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3801 Test: 0.3801\n",
      "Epoch: 157, Loss: 0.0776 tsm_loss: 0.0000 reg_loss: 0.0776 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3335 Test: 0.3335\n",
      "Epoch: 158, Loss: 0.0991 tsm_loss: 0.0000 reg_loss: 0.0991 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3487 Test: 0.3487\n",
      "Epoch: 159, Loss: 0.0836 tsm_loss: 0.0000 reg_loss: 0.0836 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3283 Test: 0.3283\n",
      "Epoch: 160, Loss: 0.0997 tsm_loss: 0.0000 reg_loss: 0.0997 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2978 Test: 0.2978\n",
      "Epoch: 161, Loss: 0.0898 tsm_loss: 0.0000 reg_loss: 0.0898 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3312 Test: 0.3312\n",
      "Epoch: 162, Loss: 0.0710 tsm_loss: 0.0000 reg_loss: 0.0710 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3723 Test: 0.3723\n",
      "Epoch: 163, Loss: 0.0819 tsm_loss: 0.0000 reg_loss: 0.0819 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3427 Test: 0.3427\n",
      "Epoch: 164, Loss: 0.0712 tsm_loss: 0.0000 reg_loss: 0.0712 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3770 Test: 0.3770\n",
      "Epoch: 165, Loss: 0.0682 tsm_loss: 0.0000 reg_loss: 0.0682 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4533 Test: 0.4533\n",
      "Epoch: 166, Loss: 0.0855 tsm_loss: 0.0000 reg_loss: 0.0855 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3946 Test: 0.3946\n",
      "Epoch: 167, Loss: 0.0722 tsm_loss: 0.0000 reg_loss: 0.0722 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3655 Test: 0.3655\n",
      "Epoch: 168, Loss: 0.0734 tsm_loss: 0.0000 reg_loss: 0.0734 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4035 Test: 0.4035\n",
      "Epoch: 169, Loss: 0.0875 tsm_loss: 0.0000 reg_loss: 0.0875 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3564 Test: 0.3564\n",
      "Epoch: 170, Loss: 0.0847 tsm_loss: 0.0000 reg_loss: 0.0847 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4096 Test: 0.4096\n",
      "Epoch: 171, Loss: 0.0692 tsm_loss: 0.0000 reg_loss: 0.0692 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4945 Test: 0.4945\n",
      "Epoch: 172, Loss: 0.0967 tsm_loss: 0.0000 reg_loss: 0.0967 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3616 Test: 0.3616\n",
      "Epoch: 173, Loss: 0.0866 tsm_loss: 0.0000 reg_loss: 0.0866 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2963 Test: 0.2963\n",
      "Epoch: 174, Loss: 0.0816 tsm_loss: 0.0000 reg_loss: 0.0816 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3011 Test: 0.3011\n",
      "Epoch: 175, Loss: 0.0795 tsm_loss: 0.0000 reg_loss: 0.0795 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3423 Test: 0.3423\n",
      "Epoch: 176, Loss: 0.0795 tsm_loss: 0.0000 reg_loss: 0.0795 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3365 Test: 0.3365\n",
      "Epoch: 177, Loss: 0.0643 tsm_loss: 0.0000 reg_loss: 0.0643 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3127 Test: 0.3127\n",
      "Epoch: 178, Loss: 0.0813 tsm_loss: 0.0000 reg_loss: 0.0813 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3034 Test: 0.3034\n",
      "Epoch: 179, Loss: 0.0748 tsm_loss: 0.0000 reg_loss: 0.0748 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3293 Test: 0.3293\n",
      "Epoch: 180, Loss: 0.0758 tsm_loss: 0.0000 reg_loss: 0.0758 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3536 Test: 0.3536\n",
      "Epoch: 181, Loss: 0.0955 tsm_loss: 0.0000 reg_loss: 0.0955 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4091 Test: 0.4091\n",
      "Epoch: 182, Loss: 0.0842 tsm_loss: 0.0000 reg_loss: 0.0842 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4040 Test: 0.4040\n",
      "Epoch: 183, Loss: 0.0850 tsm_loss: 0.0000 reg_loss: 0.0850 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3111 Test: 0.3111\n",
      "Epoch: 184, Loss: 0.0680 tsm_loss: 0.0000 reg_loss: 0.0680 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2971 Test: 0.2971\n",
      "Epoch: 185, Loss: 0.0772 tsm_loss: 0.0000 reg_loss: 0.0772 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3037 Test: 0.3037\n",
      "Epoch: 186, Loss: 0.0710 tsm_loss: 0.0000 reg_loss: 0.0710 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3120 Test: 0.3120\n",
      "Epoch: 187, Loss: 0.0623 tsm_loss: 0.0000 reg_loss: 0.0623 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3225 Test: 0.3225\n",
      "Epoch: 188, Loss: 0.0701 tsm_loss: 0.0000 reg_loss: 0.0701 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3193 Test: 0.3193\n",
      "Epoch: 189, Loss: 0.0703 tsm_loss: 0.0000 reg_loss: 0.0703 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2956 Test: 0.2956\n",
      "Epoch: 190, Loss: 0.0654 tsm_loss: 0.0000 reg_loss: 0.0654 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2929 Test: 0.2929\n",
      "Epoch: 191, Loss: 0.0636 tsm_loss: 0.0000 reg_loss: 0.0636 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3277 Test: 0.3277\n",
      "Epoch: 192, Loss: 0.0685 tsm_loss: 0.0000 reg_loss: 0.0685 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3194 Test: 0.3194\n",
      "Epoch: 193, Loss: 0.0686 tsm_loss: 0.0000 reg_loss: 0.0686 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3152 Test: 0.3152\n",
      "Epoch: 194, Loss: 0.0650 tsm_loss: 0.0000 reg_loss: 0.0650 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3048 Test: 0.3048\n",
      "Epoch: 195, Loss: 0.0648 tsm_loss: 0.0000 reg_loss: 0.0648 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3003 Test: 0.3003\n",
      "Epoch: 196, Loss: 0.0661 tsm_loss: 0.0000 reg_loss: 0.0661 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3257 Test: 0.3257\n",
      "Epoch: 197, Loss: 0.0786 tsm_loss: 0.0000 reg_loss: 0.0786 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3038 Test: 0.3038\n",
      "Epoch: 198, Loss: 0.0736 tsm_loss: 0.0000 reg_loss: 0.0736 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2925 Test: 0.2925\n",
      "Epoch: 199, Loss: 0.0694 tsm_loss: 0.0000 reg_loss: 0.0694 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3023 Test: 0.3023\n",
      "Epoch: 200, Loss: 0.0640 tsm_loss: 0.0000 reg_loss: 0.0640 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3107 Test: 0.3107\n",
      "Epoch: 201, Loss: 0.0722 tsm_loss: 0.0000 reg_loss: 0.0722 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3293 Test: 0.3293\n",
      "Epoch: 202, Loss: 0.0819 tsm_loss: 0.0000 reg_loss: 0.0819 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2908 Test: 0.2908\n",
      "Epoch: 203, Loss: 0.0623 tsm_loss: 0.0000 reg_loss: 0.0623 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3102 Test: 0.3102\n",
      "Epoch: 204, Loss: 0.0802 tsm_loss: 0.0000 reg_loss: 0.0802 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3053 Test: 0.3053\n",
      "Epoch: 205, Loss: 0.0849 tsm_loss: 0.0000 reg_loss: 0.0849 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2922 Test: 0.2922\n",
      "Epoch: 206, Loss: 0.0707 tsm_loss: 0.0000 reg_loss: 0.0707 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2947 Test: 0.2947\n",
      "Epoch: 207, Loss: 0.1239 tsm_loss: 0.0000 reg_loss: 0.1239 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2942 Test: 0.2942\n",
      "Epoch: 208, Loss: 0.0877 tsm_loss: 0.0000 reg_loss: 0.0877 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3202 Test: 0.3202\n",
      "Epoch: 209, Loss: 0.1172 tsm_loss: 0.0000 reg_loss: 0.1172 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3030 Test: 0.3030\n",
      "Epoch: 210, Loss: 0.1014 tsm_loss: 0.0000 reg_loss: 0.1014 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3430 Test: 0.3430\n",
      "Epoch: 211, Loss: 0.1076 tsm_loss: 0.0000 reg_loss: 0.1076 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3577 Test: 0.3577\n",
      "Epoch: 212, Loss: 0.0947 tsm_loss: 0.0000 reg_loss: 0.0947 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3117 Test: 0.3117\n",
      "Epoch: 213, Loss: 0.1046 tsm_loss: 0.0000 reg_loss: 0.1046 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3145 Test: 0.3145\n",
      "Epoch: 214, Loss: 0.1019 tsm_loss: 0.0000 reg_loss: 0.1019 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3757 Test: 0.3757\n",
      "Epoch: 215, Loss: 0.0993 tsm_loss: 0.0000 reg_loss: 0.0993 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3258 Test: 0.3258\n",
      "Epoch: 216, Loss: 0.0957 tsm_loss: 0.0000 reg_loss: 0.0957 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3429 Test: 0.3429\n",
      "Epoch: 217, Loss: 0.0909 tsm_loss: 0.0000 reg_loss: 0.0909 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3706 Test: 0.3706\n",
      "Epoch: 218, Loss: 0.0893 tsm_loss: 0.0000 reg_loss: 0.0893 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3058 Test: 0.3058\n",
      "Epoch: 219, Loss: 0.0858 tsm_loss: 0.0000 reg_loss: 0.0858 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3172 Test: 0.3172\n",
      "Epoch: 220, Loss: 0.0770 tsm_loss: 0.0000 reg_loss: 0.0770 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3856 Test: 0.3856\n",
      "Epoch: 221, Loss: 0.0813 tsm_loss: 0.0000 reg_loss: 0.0813 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3663 Test: 0.3663\n",
      "Epoch: 222, Loss: 0.0814 tsm_loss: 0.0000 reg_loss: 0.0814 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3041 Test: 0.3041\n",
      "Epoch: 223, Loss: 0.0616 tsm_loss: 0.0000 reg_loss: 0.0616 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2978 Test: 0.2978\n",
      "Epoch: 224, Loss: 0.0858 tsm_loss: 0.0000 reg_loss: 0.0858 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3145 Test: 0.3145\n",
      "Epoch: 225, Loss: 0.0603 tsm_loss: 0.0000 reg_loss: 0.0603 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3287 Test: 0.3287\n",
      "Epoch: 226, Loss: 0.0868 tsm_loss: 0.0000 reg_loss: 0.0868 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3434 Test: 0.3434\n",
      "Epoch: 227, Loss: 0.0728 tsm_loss: 0.0000 reg_loss: 0.0728 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3873 Test: 0.3873\n",
      "Epoch: 228, Loss: 0.0754 tsm_loss: 0.0000 reg_loss: 0.0754 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3787 Test: 0.3787\n",
      "Epoch: 229, Loss: 0.0905 tsm_loss: 0.0000 reg_loss: 0.0905 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4015 Test: 0.4015\n",
      "Epoch: 230, Loss: 0.0876 tsm_loss: 0.0000 reg_loss: 0.0876 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4767 Test: 0.4767\n",
      "Epoch: 231, Loss: 0.0912 tsm_loss: 0.0000 reg_loss: 0.0912 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4154 Test: 0.4154\n",
      "Epoch: 232, Loss: 0.0808 tsm_loss: 0.0000 reg_loss: 0.0808 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3175 Test: 0.3175\n",
      "Epoch: 233, Loss: 0.1013 tsm_loss: 0.0000 reg_loss: 0.1013 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3135 Test: 0.3135\n",
      "Epoch: 234, Loss: 0.0839 tsm_loss: 0.0000 reg_loss: 0.0839 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4106 Test: 0.4106\n",
      "Epoch: 235, Loss: 0.1001 tsm_loss: 0.0000 reg_loss: 0.1001 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4724 Test: 0.4724\n",
      "Epoch: 236, Loss: 0.0877 tsm_loss: 0.0000 reg_loss: 0.0877 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4240 Test: 0.4240\n",
      "Epoch: 237, Loss: 0.0903 tsm_loss: 0.0000 reg_loss: 0.0903 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4107 Test: 0.4107\n",
      "Epoch: 238, Loss: 0.0747 tsm_loss: 0.0000 reg_loss: 0.0747 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.4009 Test: 0.4009\n",
      "Epoch: 239, Loss: 0.0955 tsm_loss: 0.0000 reg_loss: 0.0955 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3234 Test: 0.3234\n",
      "Epoch: 240, Loss: 0.0714 tsm_loss: 0.0000 reg_loss: 0.0714 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2981 Test: 0.2981\n",
      "Epoch: 241, Loss: 0.1103 tsm_loss: 0.0000 reg_loss: 0.1103 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3067 Test: 0.3067\n",
      "Epoch: 242, Loss: 0.0908 tsm_loss: 0.0000 reg_loss: 0.0908 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2890 Test: 0.2890\n",
      "Epoch: 243, Loss: 0.0992 tsm_loss: 0.0000 reg_loss: 0.0992 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3020 Test: 0.3020\n",
      "Epoch: 244, Loss: 0.0912 tsm_loss: 0.0000 reg_loss: 0.0912 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2989 Test: 0.2989\n",
      "Epoch: 245, Loss: 0.0907 tsm_loss: 0.0000 reg_loss: 0.0907 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3034 Test: 0.3034\n",
      "Epoch: 246, Loss: 0.0983 tsm_loss: 0.0000 reg_loss: 0.0983 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3166 Test: 0.3166\n",
      "Epoch: 247, Loss: 0.0797 tsm_loss: 0.0000 reg_loss: 0.0797 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3062 Test: 0.3062\n",
      "Epoch: 248, Loss: 0.0905 tsm_loss: 0.0000 reg_loss: 0.0905 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3743 Test: 0.3743\n",
      "Epoch: 249, Loss: 0.0707 tsm_loss: 0.0000 reg_loss: 0.0707 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3688 Test: 0.3688\n",
      "Epoch: 250, Loss: 0.0704 tsm_loss: 0.0000 reg_loss: 0.0704 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3012 Test: 0.3012\n",
      "Epoch: 251, Loss: 0.0775 tsm_loss: 0.0000 reg_loss: 0.0775 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3047 Test: 0.3047\n",
      "Epoch: 252, Loss: 0.0653 tsm_loss: 0.0000 reg_loss: 0.0653 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3214 Test: 0.3214\n",
      "Epoch: 253, Loss: 0.0887 tsm_loss: 0.0000 reg_loss: 0.0887 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3187 Test: 0.3187\n",
      "Epoch: 254, Loss: 0.0668 tsm_loss: 0.0000 reg_loss: 0.0668 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3005 Test: 0.3005\n",
      "Epoch: 255, Loss: 0.0991 tsm_loss: 0.0000 reg_loss: 0.0991 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3005 Test: 0.3005\n",
      "Epoch: 256, Loss: 0.0899 tsm_loss: 0.0000 reg_loss: 0.0899 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3091 Test: 0.3091\n",
      "Epoch: 257, Loss: 0.0786 tsm_loss: 0.0000 reg_loss: 0.0786 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3286 Test: 0.3286\n",
      "Epoch: 258, Loss: 0.0933 tsm_loss: 0.0000 reg_loss: 0.0933 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3314 Test: 0.3314\n",
      "Epoch: 259, Loss: 0.0935 tsm_loss: 0.0000 reg_loss: 0.0935 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3469 Test: 0.3469\n",
      "Epoch: 260, Loss: 0.0977 tsm_loss: 0.0000 reg_loss: 0.0977 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3177 Test: 0.3177\n",
      "Epoch: 261, Loss: 0.0781 tsm_loss: 0.0000 reg_loss: 0.0781 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2907 Test: 0.2907\n",
      "Epoch: 262, Loss: 0.0861 tsm_loss: 0.0000 reg_loss: 0.0861 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3038 Test: 0.3038\n",
      "Epoch: 263, Loss: 0.0674 tsm_loss: 0.0000 reg_loss: 0.0674 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3078 Test: 0.3078\n",
      "Epoch: 264, Loss: 0.0883 tsm_loss: 0.0000 reg_loss: 0.0883 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3139 Test: 0.3139\n",
      "Epoch: 265, Loss: 0.0779 tsm_loss: 0.0000 reg_loss: 0.0779 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3412 Test: 0.3412\n",
      "Epoch: 266, Loss: 0.0763 tsm_loss: 0.0000 reg_loss: 0.0763 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3138 Test: 0.3138\n",
      "Epoch: 267, Loss: 0.0724 tsm_loss: 0.0000 reg_loss: 0.0724 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2865 Test: 0.2865\n",
      "Epoch: 268, Loss: 0.0641 tsm_loss: 0.0000 reg_loss: 0.0641 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2916 Test: 0.2916\n",
      "Epoch: 269, Loss: 0.0651 tsm_loss: 0.0000 reg_loss: 0.0651 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2920 Test: 0.2920\n",
      "Epoch: 270, Loss: 0.0646 tsm_loss: 0.0000 reg_loss: 0.0646 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2984 Test: 0.2984\n",
      "Epoch: 271, Loss: 0.0618 tsm_loss: 0.0000 reg_loss: 0.0618 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2984 Test: 0.2984\n",
      "Epoch: 272, Loss: 0.0584 tsm_loss: 0.0000 reg_loss: 0.0584 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.2989 Test: 0.2989\n",
      "Epoch: 273, Loss: 0.0589 tsm_loss: 0.0000 reg_loss: 0.0589 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3008 Test: 0.3008\n",
      "Epoch: 274, Loss: 0.0579 tsm_loss: 0.0000 reg_loss: 0.0579 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3054 Test: 0.3054\n",
      "Epoch: 275, Loss: 0.0591 tsm_loss: 0.0000 reg_loss: 0.0591 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3488 Test: 0.3488\n",
      "Epoch: 276, Loss: 0.0642 tsm_loss: 0.0000 reg_loss: 0.0642 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3403 Test: 0.3403\n",
      "Epoch: 277, Loss: 0.0545 tsm_loss: 0.0000 reg_loss: 0.0545 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3155 Test: 0.3155\n",
      "Epoch: 278, Loss: 0.0710 tsm_loss: 0.0000 reg_loss: 0.0710 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3341 Test: 0.3341\n",
      "Epoch: 279, Loss: 0.0638 tsm_loss: 0.0000 reg_loss: 0.0638 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3694 Test: 0.3694\n",
      "Epoch: 280, Loss: 0.0643 tsm_loss: 0.0000 reg_loss: 0.0643 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3398 Test: 0.3398\n",
      "Epoch: 281, Loss: 0.0655 tsm_loss: 0.0000 reg_loss: 0.0655 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3255 Test: 0.3255\n",
      "Epoch: 282, Loss: 0.0561 tsm_loss: 0.0000 reg_loss: 0.0561 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3189 Test: 0.3189\n",
      "Epoch: 283, Loss: 0.0626 tsm_loss: 0.0000 reg_loss: 0.0626 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3210 Test: 0.3210\n",
      "Epoch: 284, Loss: 0.0662 tsm_loss: 0.0000 reg_loss: 0.0662 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3115 Test: 0.3115\n",
      "Epoch: 285, Loss: 0.0536 tsm_loss: 0.0000 reg_loss: 0.0536 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3251 Test: 0.3251\n",
      "Epoch: 286, Loss: 0.0663 tsm_loss: 0.0000 reg_loss: 0.0663 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3071 Test: 0.3071\n",
      "Epoch: 287, Loss: 0.0559 tsm_loss: 0.0000 reg_loss: 0.0559 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3086 Test: 0.3086\n",
      "Epoch: 288, Loss: 0.0523 tsm_loss: 0.0000 reg_loss: 0.0523 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3328 Test: 0.3328\n",
      "Epoch: 289, Loss: 0.0663 tsm_loss: 0.0000 reg_loss: 0.0663 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3054 Test: 0.3054\n",
      "Epoch: 290, Loss: 0.0516 tsm_loss: 0.0000 reg_loss: 0.0516 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3024 Test: 0.3024\n",
      "Epoch: 291, Loss: 0.0590 tsm_loss: 0.0000 reg_loss: 0.0590 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3195 Test: 0.3195\n",
      "Epoch: 292, Loss: 0.0571 tsm_loss: 0.0000 reg_loss: 0.0571 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3120 Test: 0.3120\n",
      "Epoch: 293, Loss: 0.0491 tsm_loss: 0.0000 reg_loss: 0.0491 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3039 Test: 0.3039\n",
      "Epoch: 294, Loss: 0.0573 tsm_loss: 0.0000 reg_loss: 0.0573 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3239 Test: 0.3239\n",
      "Epoch: 295, Loss: 0.0579 tsm_loss: 0.0000 reg_loss: 0.0579 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3125 Test: 0.3125\n",
      "Epoch: 296, Loss: 0.0498 tsm_loss: 0.0000 reg_loss: 0.0498 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3184 Test: 0.3184\n",
      "Epoch: 297, Loss: 0.0487 tsm_loss: 0.0000 reg_loss: 0.0487 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3329 Test: 0.3329\n",
      "Epoch: 298, Loss: 0.0571 tsm_loss: 0.0000 reg_loss: 0.0571 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3221 Test: 0.3221\n",
      "Epoch: 299, Loss: 0.0650 tsm_loss: 0.0000 reg_loss: 0.0650 N_Y: 123252 N_S: 000 N: 000 N_HV: 000 Val: 0.3526 Test: 0.3526\n",
      "Epoch: 001, Loss: 6.7880 tsm_loss: 0.0000 reg_loss: 6.7880 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7841 Test: 6.7841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 6.5470 tsm_loss: 0.0000 reg_loss: 6.5470 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7831 Test: 6.7831\n",
      "Epoch: 003, Loss: 6.3339 tsm_loss: 0.0000 reg_loss: 6.3339 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7822 Test: 6.7822\n",
      "Epoch: 004, Loss: 6.1516 tsm_loss: 0.0000 reg_loss: 6.1516 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7817 Test: 6.7817\n",
      "Epoch: 005, Loss: 5.9879 tsm_loss: 0.0000 reg_loss: 5.9879 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7814 Test: 6.7814\n",
      "Epoch: 006, Loss: 5.8330 tsm_loss: 0.0000 reg_loss: 5.8330 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7812 Test: 6.7812\n",
      "Epoch: 007, Loss: 5.6845 tsm_loss: 0.0000 reg_loss: 5.6845 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7812 Test: 6.7812\n",
      "Epoch: 008, Loss: 5.5361 tsm_loss: 0.0000 reg_loss: 5.5361 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7814 Test: 6.7814\n",
      "Epoch: 009, Loss: 5.3849 tsm_loss: 0.0000 reg_loss: 5.3849 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7816 Test: 6.7816\n",
      "Epoch: 010, Loss: 5.2317 tsm_loss: 0.0000 reg_loss: 5.2317 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7815 Test: 6.7815\n",
      "Epoch: 011, Loss: 5.0762 tsm_loss: 0.0000 reg_loss: 5.0762 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7814 Test: 6.7814\n",
      "Epoch: 012, Loss: 4.9122 tsm_loss: 0.0000 reg_loss: 4.9122 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7816 Test: 6.7816\n",
      "Epoch: 013, Loss: 4.7341 tsm_loss: 0.0000 reg_loss: 4.7341 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7817 Test: 6.7817\n",
      "Epoch: 014, Loss: 4.5521 tsm_loss: 0.0000 reg_loss: 4.5521 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7814 Test: 6.7814\n",
      "Epoch: 015, Loss: 4.3659 tsm_loss: 0.0000 reg_loss: 4.3659 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7812 Test: 6.7812\n",
      "Epoch: 016, Loss: 4.1673 tsm_loss: 0.0000 reg_loss: 4.1673 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7811 Test: 6.7811\n",
      "Epoch: 017, Loss: 3.9622 tsm_loss: 0.0000 reg_loss: 3.9622 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7810 Test: 6.7810\n",
      "Epoch: 018, Loss: 3.7446 tsm_loss: 0.0000 reg_loss: 3.7446 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7807 Test: 6.7807\n",
      "Epoch: 019, Loss: 3.5154 tsm_loss: 0.0000 reg_loss: 3.5154 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7798 Test: 6.7798\n",
      "Epoch: 020, Loss: 3.2695 tsm_loss: 0.0000 reg_loss: 3.2695 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7788 Test: 6.7788\n",
      "Epoch: 021, Loss: 3.0065 tsm_loss: 0.0000 reg_loss: 3.0065 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7778 Test: 6.7778\n",
      "Epoch: 022, Loss: 2.7286 tsm_loss: 0.0000 reg_loss: 2.7286 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7765 Test: 6.7765\n",
      "Epoch: 023, Loss: 2.4342 tsm_loss: 0.0000 reg_loss: 2.4342 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7755 Test: 6.7755\n",
      "Epoch: 024, Loss: 2.1171 tsm_loss: 0.0000 reg_loss: 2.1171 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7742 Test: 6.7742\n",
      "Epoch: 025, Loss: 1.7835 tsm_loss: 0.0000 reg_loss: 1.7835 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7722 Test: 6.7722\n",
      "Epoch: 026, Loss: 1.4374 tsm_loss: 0.0000 reg_loss: 1.4374 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7696 Test: 6.7696\n",
      "Epoch: 027, Loss: 1.1085 tsm_loss: 0.0000 reg_loss: 1.1085 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7661 Test: 6.7661\n",
      "Epoch: 028, Loss: 0.8205 tsm_loss: 0.0000 reg_loss: 0.8205 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7595 Test: 6.7595\n",
      "Epoch: 029, Loss: 0.5800 tsm_loss: 0.0000 reg_loss: 0.5800 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7477 Test: 6.7477\n",
      "Epoch: 030, Loss: 0.5084 tsm_loss: 0.0000 reg_loss: 0.5084 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.7247 Test: 6.7247\n",
      "Epoch: 031, Loss: 0.5167 tsm_loss: 0.0000 reg_loss: 0.5167 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.6890 Test: 6.6890\n",
      "Epoch: 032, Loss: 0.4733 tsm_loss: 0.0000 reg_loss: 0.4733 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.6398 Test: 6.6398\n",
      "Epoch: 033, Loss: 0.3820 tsm_loss: 0.0000 reg_loss: 0.3820 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.5745 Test: 6.5745\n",
      "Epoch: 034, Loss: 0.3344 tsm_loss: 0.0000 reg_loss: 0.3344 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.4873 Test: 6.4873\n",
      "Epoch: 035, Loss: 0.3423 tsm_loss: 0.0000 reg_loss: 0.3423 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.3862 Test: 6.3862\n",
      "Epoch: 036, Loss: 0.2617 tsm_loss: 0.0000 reg_loss: 0.2617 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.2704 Test: 6.2704\n",
      "Epoch: 037, Loss: 0.2535 tsm_loss: 0.0000 reg_loss: 0.2535 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.1421 Test: 6.1421\n",
      "Epoch: 038, Loss: 0.2358 tsm_loss: 0.0000 reg_loss: 0.2358 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 6.0126 Test: 6.0126\n",
      "Epoch: 039, Loss: 0.2698 tsm_loss: 0.0000 reg_loss: 0.2698 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 5.8629 Test: 5.8629\n",
      "Epoch: 040, Loss: 0.2162 tsm_loss: 0.0000 reg_loss: 0.2162 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 5.7185 Test: 5.7185\n",
      "Epoch: 041, Loss: 0.1931 tsm_loss: 0.0000 reg_loss: 0.1931 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 5.5847 Test: 5.5847\n",
      "Epoch: 042, Loss: 0.2157 tsm_loss: 0.0000 reg_loss: 0.2157 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 5.4142 Test: 5.4142\n",
      "Epoch: 043, Loss: 0.2300 tsm_loss: 0.0000 reg_loss: 0.2300 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 5.2257 Test: 5.2257\n",
      "Epoch: 044, Loss: 0.1895 tsm_loss: 0.0000 reg_loss: 0.1895 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 5.0200 Test: 5.0200\n",
      "Epoch: 045, Loss: 0.1853 tsm_loss: 0.0000 reg_loss: 0.1853 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 4.7961 Test: 4.7961\n",
      "Epoch: 046, Loss: 0.1986 tsm_loss: 0.0000 reg_loss: 0.1986 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 4.5777 Test: 4.5777\n",
      "Epoch: 047, Loss: 0.1847 tsm_loss: 0.0000 reg_loss: 0.1847 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 4.3718 Test: 4.3718\n",
      "Epoch: 048, Loss: 0.1507 tsm_loss: 0.0000 reg_loss: 0.1507 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 4.1764 Test: 4.1764\n",
      "Epoch: 049, Loss: 0.1524 tsm_loss: 0.0000 reg_loss: 0.1524 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 3.9864 Test: 3.9864\n",
      "Epoch: 050, Loss: 0.1498 tsm_loss: 0.0000 reg_loss: 0.1498 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 3.7793 Test: 3.7793\n",
      "Epoch: 051, Loss: 0.1572 tsm_loss: 0.0000 reg_loss: 0.1572 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 3.6303 Test: 3.6303\n",
      "Epoch: 052, Loss: 0.1397 tsm_loss: 0.0000 reg_loss: 0.1397 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 3.4773 Test: 3.4773\n",
      "Epoch: 053, Loss: 0.1287 tsm_loss: 0.0000 reg_loss: 0.1287 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 3.3558 Test: 3.3558\n",
      "Epoch: 054, Loss: 0.1294 tsm_loss: 0.0000 reg_loss: 0.1294 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 3.1286 Test: 3.1286\n",
      "Epoch: 055, Loss: 0.1768 tsm_loss: 0.0000 reg_loss: 0.1768 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 3.0190 Test: 3.0190\n",
      "Epoch: 056, Loss: 0.1539 tsm_loss: 0.0000 reg_loss: 0.1539 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 2.7659 Test: 2.7659\n",
      "Epoch: 057, Loss: 0.1380 tsm_loss: 0.0000 reg_loss: 0.1380 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 2.4615 Test: 2.4615\n",
      "Epoch: 058, Loss: 0.1627 tsm_loss: 0.0000 reg_loss: 0.1627 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 2.3016 Test: 2.3016\n",
      "Epoch: 059, Loss: 0.1279 tsm_loss: 0.0000 reg_loss: 0.1279 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 2.2154 Test: 2.2154\n",
      "Epoch: 060, Loss: 0.1563 tsm_loss: 0.0000 reg_loss: 0.1563 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 2.0241 Test: 2.0241\n",
      "Epoch: 061, Loss: 0.1348 tsm_loss: 0.0000 reg_loss: 0.1348 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 1.8622 Test: 1.8622\n",
      "Epoch: 062, Loss: 0.1381 tsm_loss: 0.0000 reg_loss: 0.1381 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 1.6792 Test: 1.6792\n",
      "Epoch: 063, Loss: 0.1321 tsm_loss: 0.0000 reg_loss: 0.1321 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 1.4569 Test: 1.4569\n",
      "Epoch: 064, Loss: 0.1328 tsm_loss: 0.0000 reg_loss: 0.1328 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 1.2538 Test: 1.2538\n",
      "Epoch: 065, Loss: 0.1234 tsm_loss: 0.0000 reg_loss: 0.1234 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 1.1553 Test: 1.1553\n",
      "Epoch: 066, Loss: 0.1163 tsm_loss: 0.0000 reg_loss: 0.1163 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 1.0540 Test: 1.0540\n",
      "Epoch: 067, Loss: 0.1078 tsm_loss: 0.0000 reg_loss: 0.1078 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.9666 Test: 0.9666\n",
      "Epoch: 068, Loss: 0.1174 tsm_loss: 0.0000 reg_loss: 0.1174 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.9484 Test: 0.9484\n",
      "Epoch: 069, Loss: 0.1298 tsm_loss: 0.0000 reg_loss: 0.1298 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.8072 Test: 0.8072\n",
      "Epoch: 070, Loss: 0.1045 tsm_loss: 0.0000 reg_loss: 0.1045 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.7580 Test: 0.7580\n",
      "Epoch: 071, Loss: 0.1106 tsm_loss: 0.0000 reg_loss: 0.1106 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.8020 Test: 0.8020\n",
      "Epoch: 072, Loss: 0.1130 tsm_loss: 0.0000 reg_loss: 0.1130 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.7547 Test: 0.7547\n",
      "Epoch: 073, Loss: 0.0992 tsm_loss: 0.0000 reg_loss: 0.0992 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.7172 Test: 0.7172\n",
      "Epoch: 074, Loss: 0.1138 tsm_loss: 0.0000 reg_loss: 0.1138 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.7590 Test: 0.7590\n",
      "Epoch: 075, Loss: 0.1140 tsm_loss: 0.0000 reg_loss: 0.1140 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.7294 Test: 0.7294\n",
      "Epoch: 076, Loss: 0.0942 tsm_loss: 0.0000 reg_loss: 0.0942 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.6639 Test: 0.6639\n",
      "Epoch: 077, Loss: 0.1292 tsm_loss: 0.0000 reg_loss: 0.1292 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.6905 Test: 0.6905\n",
      "Epoch: 078, Loss: 0.0942 tsm_loss: 0.0000 reg_loss: 0.0942 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.7150 Test: 0.7150\n",
      "Epoch: 079, Loss: 0.1099 tsm_loss: 0.0000 reg_loss: 0.1099 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.6206 Test: 0.6206\n",
      "Epoch: 080, Loss: 0.1155 tsm_loss: 0.0000 reg_loss: 0.1155 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.6326 Test: 0.6326\n",
      "Epoch: 081, Loss: 0.1005 tsm_loss: 0.0000 reg_loss: 0.1005 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.6358 Test: 0.6358\n",
      "Epoch: 082, Loss: 0.1241 tsm_loss: 0.0000 reg_loss: 0.1241 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4607 Test: 0.4607\n",
      "Epoch: 083, Loss: 0.0880 tsm_loss: 0.0000 reg_loss: 0.0880 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4093 Test: 0.4093\n",
      "Epoch: 084, Loss: 0.1029 tsm_loss: 0.0000 reg_loss: 0.1029 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4306 Test: 0.4306\n",
      "Epoch: 085, Loss: 0.1162 tsm_loss: 0.0000 reg_loss: 0.1162 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3886 Test: 0.3886\n",
      "Epoch: 086, Loss: 0.0873 tsm_loss: 0.0000 reg_loss: 0.0873 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3672 Test: 0.3672\n",
      "Epoch: 087, Loss: 0.1075 tsm_loss: 0.0000 reg_loss: 0.1075 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3606 Test: 0.3606\n",
      "Epoch: 088, Loss: 0.1070 tsm_loss: 0.0000 reg_loss: 0.1070 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3850 Test: 0.3850\n",
      "Epoch: 089, Loss: 0.1093 tsm_loss: 0.0000 reg_loss: 0.1093 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4102 Test: 0.4102\n",
      "Epoch: 090, Loss: 0.1072 tsm_loss: 0.0000 reg_loss: 0.1072 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4176 Test: 0.4176\n",
      "Epoch: 091, Loss: 0.0926 tsm_loss: 0.0000 reg_loss: 0.0926 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4113 Test: 0.4113\n",
      "Epoch: 092, Loss: 0.1240 tsm_loss: 0.0000 reg_loss: 0.1240 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4011 Test: 0.4011\n",
      "Epoch: 093, Loss: 0.0992 tsm_loss: 0.0000 reg_loss: 0.0992 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4627 Test: 0.4627\n",
      "Epoch: 094, Loss: 0.1308 tsm_loss: 0.0000 reg_loss: 0.1308 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4590 Test: 0.4590\n",
      "Epoch: 095, Loss: 0.1137 tsm_loss: 0.0000 reg_loss: 0.1137 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4370 Test: 0.4370\n",
      "Epoch: 096, Loss: 0.1194 tsm_loss: 0.0000 reg_loss: 0.1194 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4092 Test: 0.4092\n",
      "Epoch: 097, Loss: 0.1062 tsm_loss: 0.0000 reg_loss: 0.1062 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3979 Test: 0.3979\n",
      "Epoch: 098, Loss: 0.1043 tsm_loss: 0.0000 reg_loss: 0.1043 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4302 Test: 0.4302\n",
      "Epoch: 099, Loss: 0.1087 tsm_loss: 0.0000 reg_loss: 0.1087 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4344 Test: 0.4344\n",
      "Epoch: 100, Loss: 0.0954 tsm_loss: 0.0000 reg_loss: 0.0954 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4410 Test: 0.4410\n",
      "Epoch: 101, Loss: 0.0956 tsm_loss: 0.0000 reg_loss: 0.0956 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4421 Test: 0.4421\n",
      "Epoch: 102, Loss: 0.0942 tsm_loss: 0.0000 reg_loss: 0.0942 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4183 Test: 0.4183\n",
      "Epoch: 103, Loss: 0.0990 tsm_loss: 0.0000 reg_loss: 0.0990 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3805 Test: 0.3805\n",
      "Epoch: 104, Loss: 0.0880 tsm_loss: 0.0000 reg_loss: 0.0880 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3873 Test: 0.3873\n",
      "Epoch: 105, Loss: 0.1078 tsm_loss: 0.0000 reg_loss: 0.1078 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4184 Test: 0.4184\n",
      "Epoch: 106, Loss: 0.0694 tsm_loss: 0.0000 reg_loss: 0.0694 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4570 Test: 0.4570\n",
      "Epoch: 107, Loss: 0.0900 tsm_loss: 0.0000 reg_loss: 0.0900 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4396 Test: 0.4396\n",
      "Epoch: 108, Loss: 0.0849 tsm_loss: 0.0000 reg_loss: 0.0849 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4293 Test: 0.4293\n",
      "Epoch: 109, Loss: 0.0919 tsm_loss: 0.0000 reg_loss: 0.0919 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4425 Test: 0.4425\n",
      "Epoch: 110, Loss: 0.0799 tsm_loss: 0.0000 reg_loss: 0.0799 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4246 Test: 0.4246\n",
      "Epoch: 111, Loss: 0.0849 tsm_loss: 0.0000 reg_loss: 0.0849 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3997 Test: 0.3997\n",
      "Epoch: 112, Loss: 0.0836 tsm_loss: 0.0000 reg_loss: 0.0836 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.3893 Test: 0.3893\n",
      "Epoch: 113, Loss: 0.0753 tsm_loss: 0.0000 reg_loss: 0.0753 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4211 Test: 0.4211\n",
      "Epoch: 114, Loss: 0.0809 tsm_loss: 0.0000 reg_loss: 0.0809 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4512 Test: 0.4512\n",
      "Epoch: 115, Loss: 0.0739 tsm_loss: 0.0000 reg_loss: 0.0739 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4340 Test: 0.4340\n",
      "Epoch: 116, Loss: 0.0733 tsm_loss: 0.0000 reg_loss: 0.0733 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4219 Test: 0.4219\n",
      "Epoch: 117, Loss: 0.0719 tsm_loss: 0.0000 reg_loss: 0.0719 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4159 Test: 0.4159\n",
      "Epoch: 118, Loss: 0.0692 tsm_loss: 0.0000 reg_loss: 0.0692 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4409 Test: 0.4409\n",
      "Epoch: 119, Loss: 0.0663 tsm_loss: 0.0000 reg_loss: 0.0663 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4729 Test: 0.4729\n",
      "Epoch: 120, Loss: 0.0657 tsm_loss: 0.0000 reg_loss: 0.0657 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4581 Test: 0.4581\n",
      "Epoch: 121, Loss: 0.0711 tsm_loss: 0.0000 reg_loss: 0.0711 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4639 Test: 0.4639\n",
      "Epoch: 122, Loss: 0.0582 tsm_loss: 0.0000 reg_loss: 0.0582 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5477 Test: 0.5477\n",
      "Epoch: 123, Loss: 0.0682 tsm_loss: 0.0000 reg_loss: 0.0682 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5300 Test: 0.5300\n",
      "Epoch: 124, Loss: 0.0716 tsm_loss: 0.0000 reg_loss: 0.0716 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5182 Test: 0.5182\n",
      "Epoch: 125, Loss: 0.0675 tsm_loss: 0.0000 reg_loss: 0.0675 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4941 Test: 0.4941\n",
      "Epoch: 126, Loss: 0.0533 tsm_loss: 0.0000 reg_loss: 0.0533 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4724 Test: 0.4724\n",
      "Epoch: 127, Loss: 0.0603 tsm_loss: 0.0000 reg_loss: 0.0603 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4841 Test: 0.4841\n",
      "Epoch: 128, Loss: 0.0635 tsm_loss: 0.0000 reg_loss: 0.0635 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4569 Test: 0.4569\n",
      "Epoch: 129, Loss: 0.0566 tsm_loss: 0.0000 reg_loss: 0.0566 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4457 Test: 0.4457\n",
      "Epoch: 130, Loss: 0.0597 tsm_loss: 0.0000 reg_loss: 0.0597 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4473 Test: 0.4473\n",
      "Epoch: 131, Loss: 0.0637 tsm_loss: 0.0000 reg_loss: 0.0637 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5234 Test: 0.5234\n",
      "Epoch: 132, Loss: 0.0594 tsm_loss: 0.0000 reg_loss: 0.0594 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5382 Test: 0.5382\n",
      "Epoch: 133, Loss: 0.0557 tsm_loss: 0.0000 reg_loss: 0.0557 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5447 Test: 0.5447\n",
      "Epoch: 134, Loss: 0.0501 tsm_loss: 0.0000 reg_loss: 0.0501 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5660 Test: 0.5660\n",
      "Epoch: 135, Loss: 0.0474 tsm_loss: 0.0000 reg_loss: 0.0474 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5055 Test: 0.5055\n",
      "Epoch: 136, Loss: 0.0584 tsm_loss: 0.0000 reg_loss: 0.0584 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5069 Test: 0.5069\n",
      "Epoch: 137, Loss: 0.0588 tsm_loss: 0.0000 reg_loss: 0.0588 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4719 Test: 0.4719\n",
      "Epoch: 138, Loss: 0.0552 tsm_loss: 0.0000 reg_loss: 0.0552 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4849 Test: 0.4849\n",
      "Epoch: 139, Loss: 0.0653 tsm_loss: 0.0000 reg_loss: 0.0653 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5143 Test: 0.5143\n",
      "Epoch: 140, Loss: 0.0581 tsm_loss: 0.0000 reg_loss: 0.0581 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4926 Test: 0.4926\n",
      "Epoch: 141, Loss: 0.0673 tsm_loss: 0.0000 reg_loss: 0.0673 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4941 Test: 0.4941\n",
      "Epoch: 142, Loss: 0.0526 tsm_loss: 0.0000 reg_loss: 0.0526 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5369 Test: 0.5369\n",
      "Epoch: 143, Loss: 0.0643 tsm_loss: 0.0000 reg_loss: 0.0643 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4841 Test: 0.4841\n",
      "Epoch: 144, Loss: 0.0562 tsm_loss: 0.0000 reg_loss: 0.0562 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4877 Test: 0.4877\n",
      "Epoch: 145, Loss: 0.0540 tsm_loss: 0.0000 reg_loss: 0.0540 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4706 Test: 0.4706\n",
      "Epoch: 146, Loss: 0.0469 tsm_loss: 0.0000 reg_loss: 0.0469 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4862 Test: 0.4862\n",
      "Epoch: 147, Loss: 0.0718 tsm_loss: 0.0000 reg_loss: 0.0718 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4913 Test: 0.4913\n",
      "Epoch: 148, Loss: 0.0532 tsm_loss: 0.0000 reg_loss: 0.0532 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4696 Test: 0.4696\n",
      "Epoch: 149, Loss: 0.0651 tsm_loss: 0.0000 reg_loss: 0.0651 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4458 Test: 0.4458\n",
      "Epoch: 150, Loss: 0.0731 tsm_loss: 0.0000 reg_loss: 0.0731 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4251 Test: 0.4251\n",
      "Epoch: 151, Loss: 0.0759 tsm_loss: 0.0000 reg_loss: 0.0759 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4368 Test: 0.4368\n",
      "Epoch: 152, Loss: 0.0653 tsm_loss: 0.0000 reg_loss: 0.0653 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5081 Test: 0.5081\n",
      "Epoch: 153, Loss: 0.0594 tsm_loss: 0.0000 reg_loss: 0.0594 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5281 Test: 0.5281\n",
      "Epoch: 154, Loss: 0.0673 tsm_loss: 0.0000 reg_loss: 0.0673 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4682 Test: 0.4682\n",
      "Epoch: 155, Loss: 0.0602 tsm_loss: 0.0000 reg_loss: 0.0602 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4279 Test: 0.4279\n",
      "Epoch: 156, Loss: 0.0711 tsm_loss: 0.0000 reg_loss: 0.0711 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4365 Test: 0.4365\n",
      "Epoch: 157, Loss: 0.0507 tsm_loss: 0.0000 reg_loss: 0.0507 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5158 Test: 0.5158\n",
      "Epoch: 158, Loss: 0.0638 tsm_loss: 0.0000 reg_loss: 0.0638 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5243 Test: 0.5243\n",
      "Epoch: 159, Loss: 0.0567 tsm_loss: 0.0000 reg_loss: 0.0567 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4587 Test: 0.4587\n",
      "Epoch: 160, Loss: 0.0461 tsm_loss: 0.0000 reg_loss: 0.0461 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4593 Test: 0.4593\n",
      "Epoch: 161, Loss: 0.0561 tsm_loss: 0.0000 reg_loss: 0.0561 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4475 Test: 0.4475\n",
      "Epoch: 162, Loss: 0.0559 tsm_loss: 0.0000 reg_loss: 0.0559 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4938 Test: 0.4938\n",
      "Epoch: 163, Loss: 0.0462 tsm_loss: 0.0000 reg_loss: 0.0462 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5644 Test: 0.5644\n",
      "Epoch: 164, Loss: 0.0560 tsm_loss: 0.0000 reg_loss: 0.0560 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4988 Test: 0.4988\n",
      "Epoch: 165, Loss: 0.0523 tsm_loss: 0.0000 reg_loss: 0.0523 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4636 Test: 0.4636\n",
      "Epoch: 166, Loss: 0.0554 tsm_loss: 0.0000 reg_loss: 0.0554 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4634 Test: 0.4634\n",
      "Epoch: 167, Loss: 0.0606 tsm_loss: 0.0000 reg_loss: 0.0606 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4384 Test: 0.4384\n",
      "Epoch: 168, Loss: 0.0717 tsm_loss: 0.0000 reg_loss: 0.0717 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4774 Test: 0.4774\n",
      "Epoch: 169, Loss: 0.0582 tsm_loss: 0.0000 reg_loss: 0.0582 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4972 Test: 0.4972\n",
      "Epoch: 170, Loss: 0.0574 tsm_loss: 0.0000 reg_loss: 0.0574 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4612 Test: 0.4612\n",
      "Epoch: 171, Loss: 0.0473 tsm_loss: 0.0000 reg_loss: 0.0473 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4597 Test: 0.4597\n",
      "Epoch: 172, Loss: 0.0623 tsm_loss: 0.0000 reg_loss: 0.0623 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4538 Test: 0.4538\n",
      "Epoch: 173, Loss: 0.0404 tsm_loss: 0.0000 reg_loss: 0.0404 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4707 Test: 0.4707\n",
      "Epoch: 174, Loss: 0.0518 tsm_loss: 0.0000 reg_loss: 0.0518 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4652 Test: 0.4652\n",
      "Epoch: 175, Loss: 0.0468 tsm_loss: 0.0000 reg_loss: 0.0468 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4539 Test: 0.4539\n",
      "Epoch: 176, Loss: 0.0495 tsm_loss: 0.0000 reg_loss: 0.0495 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4611 Test: 0.4611\n",
      "Epoch: 177, Loss: 0.0490 tsm_loss: 0.0000 reg_loss: 0.0490 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4515 Test: 0.4515\n",
      "Epoch: 178, Loss: 0.0604 tsm_loss: 0.0000 reg_loss: 0.0604 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4631 Test: 0.4631\n",
      "Epoch: 179, Loss: 0.0353 tsm_loss: 0.0000 reg_loss: 0.0353 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4693 Test: 0.4693\n",
      "Epoch: 180, Loss: 0.0688 tsm_loss: 0.0000 reg_loss: 0.0688 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4551 Test: 0.4551\n",
      "Epoch: 181, Loss: 0.0420 tsm_loss: 0.0000 reg_loss: 0.0420 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4597 Test: 0.4597\n",
      "Epoch: 182, Loss: 0.0670 tsm_loss: 0.0000 reg_loss: 0.0670 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4607 Test: 0.4607\n",
      "Epoch: 183, Loss: 0.0444 tsm_loss: 0.0000 reg_loss: 0.0444 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4815 Test: 0.4815\n",
      "Epoch: 184, Loss: 0.0728 tsm_loss: 0.0000 reg_loss: 0.0728 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5350 Test: 0.5350\n",
      "Epoch: 185, Loss: 0.0599 tsm_loss: 0.0000 reg_loss: 0.0599 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5569 Test: 0.5569\n",
      "Epoch: 186, Loss: 0.0619 tsm_loss: 0.0000 reg_loss: 0.0619 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5616 Test: 0.5616\n",
      "Epoch: 187, Loss: 0.0697 tsm_loss: 0.0000 reg_loss: 0.0697 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5348 Test: 0.5348\n",
      "Epoch: 188, Loss: 0.0420 tsm_loss: 0.0000 reg_loss: 0.0420 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5326 Test: 0.5326\n",
      "Epoch: 189, Loss: 0.0638 tsm_loss: 0.0000 reg_loss: 0.0638 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5070 Test: 0.5070\n",
      "Epoch: 190, Loss: 0.0382 tsm_loss: 0.0000 reg_loss: 0.0382 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4682 Test: 0.4682\n",
      "Epoch: 191, Loss: 0.0648 tsm_loss: 0.0000 reg_loss: 0.0648 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4857 Test: 0.4857\n",
      "Epoch: 192, Loss: 0.0676 tsm_loss: 0.0000 reg_loss: 0.0676 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4596 Test: 0.4596\n",
      "Epoch: 193, Loss: 0.0543 tsm_loss: 0.0000 reg_loss: 0.0543 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4191 Test: 0.4191\n",
      "Epoch: 194, Loss: 0.0822 tsm_loss: 0.0000 reg_loss: 0.0822 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4278 Test: 0.4278\n",
      "Epoch: 195, Loss: 0.0589 tsm_loss: 0.0000 reg_loss: 0.0589 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4535 Test: 0.4535\n",
      "Epoch: 196, Loss: 0.0688 tsm_loss: 0.0000 reg_loss: 0.0688 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4433 Test: 0.4433\n",
      "Epoch: 197, Loss: 0.0649 tsm_loss: 0.0000 reg_loss: 0.0649 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4853 Test: 0.4853\n",
      "Epoch: 198, Loss: 0.0624 tsm_loss: 0.0000 reg_loss: 0.0624 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5406 Test: 0.5406\n",
      "Epoch: 199, Loss: 0.0924 tsm_loss: 0.0000 reg_loss: 0.0924 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5040 Test: 0.5040\n",
      "Epoch: 200, Loss: 0.0387 tsm_loss: 0.0000 reg_loss: 0.0387 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4759 Test: 0.4759\n",
      "Epoch: 201, Loss: 0.0867 tsm_loss: 0.0000 reg_loss: 0.0867 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5590 Test: 0.5590\n",
      "Epoch: 202, Loss: 0.0557 tsm_loss: 0.0000 reg_loss: 0.0557 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.6262 Test: 0.6262\n",
      "Epoch: 203, Loss: 0.0755 tsm_loss: 0.0000 reg_loss: 0.0755 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5776 Test: 0.5776\n",
      "Epoch: 204, Loss: 0.0451 tsm_loss: 0.0000 reg_loss: 0.0451 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5241 Test: 0.5241\n",
      "Epoch: 205, Loss: 0.0725 tsm_loss: 0.0000 reg_loss: 0.0725 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5173 Test: 0.5173\n",
      "Epoch: 206, Loss: 0.0365 tsm_loss: 0.0000 reg_loss: 0.0365 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5075 Test: 0.5075\n",
      "Epoch: 207, Loss: 0.0681 tsm_loss: 0.0000 reg_loss: 0.0681 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4586 Test: 0.4586\n",
      "Epoch: 208, Loss: 0.0642 tsm_loss: 0.0000 reg_loss: 0.0642 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4841 Test: 0.4841\n",
      "Epoch: 209, Loss: 0.0496 tsm_loss: 0.0000 reg_loss: 0.0496 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5416 Test: 0.5416\n",
      "Epoch: 210, Loss: 0.0571 tsm_loss: 0.0000 reg_loss: 0.0571 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5208 Test: 0.5208\n",
      "Epoch: 211, Loss: 0.0561 tsm_loss: 0.0000 reg_loss: 0.0561 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4737 Test: 0.4737\n",
      "Epoch: 212, Loss: 0.0650 tsm_loss: 0.0000 reg_loss: 0.0650 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5036 Test: 0.5036\n",
      "Epoch: 213, Loss: 0.0416 tsm_loss: 0.0000 reg_loss: 0.0416 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5047 Test: 0.5047\n",
      "Epoch: 214, Loss: 0.0474 tsm_loss: 0.0000 reg_loss: 0.0474 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4863 Test: 0.4863\n",
      "Epoch: 215, Loss: 0.0413 tsm_loss: 0.0000 reg_loss: 0.0413 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4908 Test: 0.4908\n",
      "Epoch: 216, Loss: 0.0377 tsm_loss: 0.0000 reg_loss: 0.0377 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4889 Test: 0.4889\n",
      "Epoch: 217, Loss: 0.0370 tsm_loss: 0.0000 reg_loss: 0.0370 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4691 Test: 0.4691\n",
      "Epoch: 218, Loss: 0.0418 tsm_loss: 0.0000 reg_loss: 0.0418 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5146 Test: 0.5146\n",
      "Epoch: 219, Loss: 0.0481 tsm_loss: 0.0000 reg_loss: 0.0481 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4926 Test: 0.4926\n",
      "Epoch: 220, Loss: 0.0378 tsm_loss: 0.0000 reg_loss: 0.0378 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4741 Test: 0.4741\n",
      "Epoch: 221, Loss: 0.0537 tsm_loss: 0.0000 reg_loss: 0.0537 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4807 Test: 0.4807\n",
      "Epoch: 222, Loss: 0.0519 tsm_loss: 0.0000 reg_loss: 0.0519 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4638 Test: 0.4638\n",
      "Epoch: 223, Loss: 0.0400 tsm_loss: 0.0000 reg_loss: 0.0400 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4639 Test: 0.4639\n",
      "Epoch: 224, Loss: 0.0397 tsm_loss: 0.0000 reg_loss: 0.0397 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5034 Test: 0.5034\n",
      "Epoch: 225, Loss: 0.0521 tsm_loss: 0.0000 reg_loss: 0.0521 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4663 Test: 0.4663\n",
      "Epoch: 226, Loss: 0.0348 tsm_loss: 0.0000 reg_loss: 0.0348 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4479 Test: 0.4479\n",
      "Epoch: 227, Loss: 0.0319 tsm_loss: 0.0000 reg_loss: 0.0319 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4523 Test: 0.4523\n",
      "Epoch: 228, Loss: 0.0342 tsm_loss: 0.0000 reg_loss: 0.0342 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4522 Test: 0.4522\n",
      "Epoch: 229, Loss: 0.0424 tsm_loss: 0.0000 reg_loss: 0.0424 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4981 Test: 0.4981\n",
      "Epoch: 230, Loss: 0.0576 tsm_loss: 0.0000 reg_loss: 0.0576 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4793 Test: 0.4793\n",
      "Epoch: 231, Loss: 0.0372 tsm_loss: 0.0000 reg_loss: 0.0372 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4626 Test: 0.4626\n",
      "Epoch: 232, Loss: 0.0599 tsm_loss: 0.0000 reg_loss: 0.0599 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4568 Test: 0.4568\n",
      "Epoch: 233, Loss: 0.0506 tsm_loss: 0.0000 reg_loss: 0.0506 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4544 Test: 0.4544\n",
      "Epoch: 234, Loss: 0.0608 tsm_loss: 0.0000 reg_loss: 0.0608 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4515 Test: 0.4515\n",
      "Epoch: 235, Loss: 0.0422 tsm_loss: 0.0000 reg_loss: 0.0422 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4596 Test: 0.4596\n",
      "Epoch: 236, Loss: 0.0414 tsm_loss: 0.0000 reg_loss: 0.0414 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4463 Test: 0.4463\n",
      "Epoch: 237, Loss: 0.0395 tsm_loss: 0.0000 reg_loss: 0.0395 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4372 Test: 0.4372\n",
      "Epoch: 238, Loss: 0.0510 tsm_loss: 0.0000 reg_loss: 0.0510 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4582 Test: 0.4582\n",
      "Epoch: 239, Loss: 0.0498 tsm_loss: 0.0000 reg_loss: 0.0498 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4780 Test: 0.4780\n",
      "Epoch: 240, Loss: 0.0547 tsm_loss: 0.0000 reg_loss: 0.0547 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4795 Test: 0.4795\n",
      "Epoch: 241, Loss: 0.0493 tsm_loss: 0.0000 reg_loss: 0.0493 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4563 Test: 0.4563\n",
      "Epoch: 242, Loss: 0.0540 tsm_loss: 0.0000 reg_loss: 0.0540 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4539 Test: 0.4539\n",
      "Epoch: 243, Loss: 0.0552 tsm_loss: 0.0000 reg_loss: 0.0552 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4631 Test: 0.4631\n",
      "Epoch: 244, Loss: 0.0314 tsm_loss: 0.0000 reg_loss: 0.0314 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4537 Test: 0.4537\n",
      "Epoch: 245, Loss: 0.0689 tsm_loss: 0.0000 reg_loss: 0.0689 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4670 Test: 0.4670\n",
      "Epoch: 246, Loss: 0.0554 tsm_loss: 0.0000 reg_loss: 0.0554 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4745 Test: 0.4745\n",
      "Epoch: 247, Loss: 0.0595 tsm_loss: 0.0000 reg_loss: 0.0595 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4559 Test: 0.4559\n",
      "Epoch: 248, Loss: 0.0435 tsm_loss: 0.0000 reg_loss: 0.0435 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4738 Test: 0.4738\n",
      "Epoch: 249, Loss: 0.0512 tsm_loss: 0.0000 reg_loss: 0.0512 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5182 Test: 0.5182\n",
      "Epoch: 250, Loss: 0.0516 tsm_loss: 0.0000 reg_loss: 0.0516 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4813 Test: 0.4813\n",
      "Epoch: 251, Loss: 0.0353 tsm_loss: 0.0000 reg_loss: 0.0353 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4505 Test: 0.4505\n",
      "Epoch: 252, Loss: 0.0481 tsm_loss: 0.0000 reg_loss: 0.0481 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4483 Test: 0.4483\n",
      "Epoch: 253, Loss: 0.0539 tsm_loss: 0.0000 reg_loss: 0.0539 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4707 Test: 0.4707\n",
      "Epoch: 254, Loss: 0.0414 tsm_loss: 0.0000 reg_loss: 0.0414 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4750 Test: 0.4750\n",
      "Epoch: 255, Loss: 0.0510 tsm_loss: 0.0000 reg_loss: 0.0510 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4956 Test: 0.4956\n",
      "Epoch: 256, Loss: 0.0453 tsm_loss: 0.0000 reg_loss: 0.0453 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5052 Test: 0.5052\n",
      "Epoch: 257, Loss: 0.0574 tsm_loss: 0.0000 reg_loss: 0.0574 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4805 Test: 0.4805\n",
      "Epoch: 258, Loss: 0.0500 tsm_loss: 0.0000 reg_loss: 0.0500 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4689 Test: 0.4689\n",
      "Epoch: 259, Loss: 0.0606 tsm_loss: 0.0000 reg_loss: 0.0606 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5026 Test: 0.5026\n",
      "Epoch: 260, Loss: 0.0554 tsm_loss: 0.0000 reg_loss: 0.0554 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5481 Test: 0.5481\n",
      "Epoch: 261, Loss: 0.0294 tsm_loss: 0.0000 reg_loss: 0.0294 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5815 Test: 0.5815\n",
      "Epoch: 262, Loss: 0.0695 tsm_loss: 0.0000 reg_loss: 0.0695 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.6334 Test: 0.6334\n",
      "Epoch: 263, Loss: 0.0538 tsm_loss: 0.0000 reg_loss: 0.0538 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.6193 Test: 0.6193\n",
      "Epoch: 264, Loss: 0.0611 tsm_loss: 0.0000 reg_loss: 0.0611 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4932 Test: 0.4932\n",
      "Epoch: 265, Loss: 0.0402 tsm_loss: 0.0000 reg_loss: 0.0402 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4490 Test: 0.4490\n",
      "Epoch: 266, Loss: 0.0421 tsm_loss: 0.0000 reg_loss: 0.0421 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4567 Test: 0.4567\n",
      "Epoch: 267, Loss: 0.0505 tsm_loss: 0.0000 reg_loss: 0.0505 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4620 Test: 0.4620\n",
      "Epoch: 268, Loss: 0.0467 tsm_loss: 0.0000 reg_loss: 0.0467 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4815 Test: 0.4815\n",
      "Epoch: 269, Loss: 0.0405 tsm_loss: 0.0000 reg_loss: 0.0405 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4917 Test: 0.4917\n",
      "Epoch: 270, Loss: 0.0578 tsm_loss: 0.0000 reg_loss: 0.0578 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4799 Test: 0.4799\n",
      "Epoch: 271, Loss: 0.0382 tsm_loss: 0.0000 reg_loss: 0.0382 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4594 Test: 0.4594\n",
      "Epoch: 272, Loss: 0.0650 tsm_loss: 0.0000 reg_loss: 0.0650 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4481 Test: 0.4481\n",
      "Epoch: 273, Loss: 0.0487 tsm_loss: 0.0000 reg_loss: 0.0487 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4694 Test: 0.4694\n",
      "Epoch: 274, Loss: 0.0605 tsm_loss: 0.0000 reg_loss: 0.0605 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4642 Test: 0.4642\n",
      "Epoch: 275, Loss: 0.0466 tsm_loss: 0.0000 reg_loss: 0.0466 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4550 Test: 0.4550\n",
      "Epoch: 276, Loss: 0.0320 tsm_loss: 0.0000 reg_loss: 0.0320 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4813 Test: 0.4813\n",
      "Epoch: 277, Loss: 0.0620 tsm_loss: 0.0000 reg_loss: 0.0620 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4515 Test: 0.4515\n",
      "Epoch: 278, Loss: 0.0354 tsm_loss: 0.0000 reg_loss: 0.0354 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4337 Test: 0.4337\n",
      "Epoch: 279, Loss: 0.0506 tsm_loss: 0.0000 reg_loss: 0.0506 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4578 Test: 0.4578\n",
      "Epoch: 280, Loss: 0.0563 tsm_loss: 0.0000 reg_loss: 0.0563 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4628 Test: 0.4628\n",
      "Epoch: 281, Loss: 0.0428 tsm_loss: 0.0000 reg_loss: 0.0428 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4336 Test: 0.4336\n",
      "Epoch: 282, Loss: 0.0560 tsm_loss: 0.0000 reg_loss: 0.0560 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4358 Test: 0.4358\n",
      "Epoch: 283, Loss: 0.0320 tsm_loss: 0.0000 reg_loss: 0.0320 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4685 Test: 0.4685\n",
      "Epoch: 284, Loss: 0.0551 tsm_loss: 0.0000 reg_loss: 0.0551 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4781 Test: 0.4781\n",
      "Epoch: 285, Loss: 0.0446 tsm_loss: 0.0000 reg_loss: 0.0446 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4961 Test: 0.4961\n",
      "Epoch: 286, Loss: 0.0419 tsm_loss: 0.0000 reg_loss: 0.0419 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4832 Test: 0.4832\n",
      "Epoch: 287, Loss: 0.0498 tsm_loss: 0.0000 reg_loss: 0.0498 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4510 Test: 0.4510\n",
      "Epoch: 288, Loss: 0.0321 tsm_loss: 0.0000 reg_loss: 0.0321 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4625 Test: 0.4625\n",
      "Epoch: 289, Loss: 0.0342 tsm_loss: 0.0000 reg_loss: 0.0342 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4987 Test: 0.4987\n",
      "Epoch: 290, Loss: 0.0628 tsm_loss: 0.0000 reg_loss: 0.0628 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.5025 Test: 0.5025\n",
      "Epoch: 291, Loss: 0.0403 tsm_loss: 0.0000 reg_loss: 0.0403 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4553 Test: 0.4553\n",
      "Epoch: 292, Loss: 0.0612 tsm_loss: 0.0000 reg_loss: 0.0612 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4394 Test: 0.4394\n",
      "Epoch: 293, Loss: 0.0386 tsm_loss: 0.0000 reg_loss: 0.0386 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4679 Test: 0.4679\n",
      "Epoch: 294, Loss: 0.0754 tsm_loss: 0.0000 reg_loss: 0.0754 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4736 Test: 0.4736\n",
      "Epoch: 295, Loss: 0.0498 tsm_loss: 0.0000 reg_loss: 0.0498 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4743 Test: 0.4743\n",
      "Epoch: 296, Loss: 0.0724 tsm_loss: 0.0000 reg_loss: 0.0724 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4921 Test: 0.4921\n",
      "Epoch: 297, Loss: 0.0519 tsm_loss: 0.0000 reg_loss: 0.0519 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4810 Test: 0.4810\n",
      "Epoch: 298, Loss: 0.0468 tsm_loss: 0.0000 reg_loss: 0.0468 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4672 Test: 0.4672\n",
      "Epoch: 299, Loss: 0.0538 tsm_loss: 0.0000 reg_loss: 0.0538 N_Y: 109356 N_S: 000 N: 000 N_HV: 000 Val: 0.4650 Test: 0.4650\n",
      "Epoch: 001, Loss: 6.7748 tsm_loss: 0.0000 reg_loss: 6.7748 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8267 Test: 6.8267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 6.5364 tsm_loss: 0.0000 reg_loss: 6.5364 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8259 Test: 6.8259\n",
      "Epoch: 003, Loss: 6.3145 tsm_loss: 0.0000 reg_loss: 6.3145 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8254 Test: 6.8254\n",
      "Epoch: 004, Loss: 6.1314 tsm_loss: 0.0000 reg_loss: 6.1314 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8252 Test: 6.8252\n",
      "Epoch: 005, Loss: 5.9581 tsm_loss: 0.0000 reg_loss: 5.9581 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8252 Test: 6.8252\n",
      "Epoch: 006, Loss: 5.7984 tsm_loss: 0.0000 reg_loss: 5.7984 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8252 Test: 6.8252\n",
      "Epoch: 007, Loss: 5.6437 tsm_loss: 0.0000 reg_loss: 5.6437 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8249 Test: 6.8249\n",
      "Epoch: 008, Loss: 5.4913 tsm_loss: 0.0000 reg_loss: 5.4913 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8248 Test: 6.8248\n",
      "Epoch: 009, Loss: 5.3407 tsm_loss: 0.0000 reg_loss: 5.3407 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8251 Test: 6.8251\n",
      "Epoch: 010, Loss: 5.1855 tsm_loss: 0.0000 reg_loss: 5.1855 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8254 Test: 6.8254\n",
      "Epoch: 011, Loss: 5.0232 tsm_loss: 0.0000 reg_loss: 5.0232 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8256 Test: 6.8256\n",
      "Epoch: 012, Loss: 4.8583 tsm_loss: 0.0000 reg_loss: 4.8583 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8257 Test: 6.8257\n",
      "Epoch: 013, Loss: 4.6930 tsm_loss: 0.0000 reg_loss: 4.6930 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8254 Test: 6.8254\n",
      "Epoch: 014, Loss: 4.5189 tsm_loss: 0.0000 reg_loss: 4.5189 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8254 Test: 6.8254\n",
      "Epoch: 015, Loss: 4.3355 tsm_loss: 0.0000 reg_loss: 4.3355 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8252 Test: 6.8252\n",
      "Epoch: 016, Loss: 4.1415 tsm_loss: 0.0000 reg_loss: 4.1415 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8247 Test: 6.8247\n",
      "Epoch: 017, Loss: 3.9358 tsm_loss: 0.0000 reg_loss: 3.9358 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8239 Test: 6.8239\n",
      "Epoch: 018, Loss: 3.7168 tsm_loss: 0.0000 reg_loss: 3.7168 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8230 Test: 6.8230\n",
      "Epoch: 019, Loss: 3.4824 tsm_loss: 0.0000 reg_loss: 3.4824 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8222 Test: 6.8222\n",
      "Epoch: 020, Loss: 3.2334 tsm_loss: 0.0000 reg_loss: 3.2334 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8213 Test: 6.8213\n",
      "Epoch: 021, Loss: 2.9677 tsm_loss: 0.0000 reg_loss: 2.9677 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8200 Test: 6.8200\n",
      "Epoch: 022, Loss: 2.6874 tsm_loss: 0.0000 reg_loss: 2.6874 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8183 Test: 6.8183\n",
      "Epoch: 023, Loss: 2.3867 tsm_loss: 0.0000 reg_loss: 2.3867 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8160 Test: 6.8160\n",
      "Epoch: 024, Loss: 2.0694 tsm_loss: 0.0000 reg_loss: 2.0694 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8140 Test: 6.8140\n",
      "Epoch: 025, Loss: 1.7316 tsm_loss: 0.0000 reg_loss: 1.7316 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8120 Test: 6.8120\n",
      "Epoch: 026, Loss: 1.3857 tsm_loss: 0.0000 reg_loss: 1.3857 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8093 Test: 6.8093\n",
      "Epoch: 027, Loss: 1.0490 tsm_loss: 0.0000 reg_loss: 1.0490 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.8052 Test: 6.8052\n",
      "Epoch: 028, Loss: 0.7932 tsm_loss: 0.0000 reg_loss: 0.7932 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.7988 Test: 6.7988\n",
      "Epoch: 029, Loss: 0.6920 tsm_loss: 0.0000 reg_loss: 0.6920 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.7849 Test: 6.7849\n",
      "Epoch: 030, Loss: 0.5545 tsm_loss: 0.0000 reg_loss: 0.5545 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.7633 Test: 6.7633\n",
      "Epoch: 031, Loss: 0.5141 tsm_loss: 0.0000 reg_loss: 0.5141 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.7239 Test: 6.7239\n",
      "Epoch: 032, Loss: 0.4549 tsm_loss: 0.0000 reg_loss: 0.4549 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.6643 Test: 6.6643\n",
      "Epoch: 033, Loss: 0.3749 tsm_loss: 0.0000 reg_loss: 0.3749 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.5823 Test: 6.5823\n",
      "Epoch: 034, Loss: 0.3144 tsm_loss: 0.0000 reg_loss: 0.3144 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.4715 Test: 6.4715\n",
      "Epoch: 035, Loss: 0.2892 tsm_loss: 0.0000 reg_loss: 0.2892 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.3483 Test: 6.3483\n",
      "Epoch: 036, Loss: 0.2946 tsm_loss: 0.0000 reg_loss: 0.2946 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.2218 Test: 6.2218\n",
      "Epoch: 037, Loss: 0.2518 tsm_loss: 0.0000 reg_loss: 0.2518 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 6.0727 Test: 6.0727\n",
      "Epoch: 038, Loss: 0.2260 tsm_loss: 0.0000 reg_loss: 0.2260 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 5.9094 Test: 5.9094\n",
      "Epoch: 039, Loss: 0.2114 tsm_loss: 0.0000 reg_loss: 0.2114 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 5.7266 Test: 5.7266\n",
      "Epoch: 040, Loss: 0.2091 tsm_loss: 0.0000 reg_loss: 0.2091 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 5.5486 Test: 5.5486\n",
      "Epoch: 041, Loss: 0.2021 tsm_loss: 0.0000 reg_loss: 0.2021 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 5.3566 Test: 5.3566\n",
      "Epoch: 042, Loss: 0.1791 tsm_loss: 0.0000 reg_loss: 0.1791 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 5.1844 Test: 5.1844\n",
      "Epoch: 043, Loss: 0.1666 tsm_loss: 0.0000 reg_loss: 0.1666 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 5.0187 Test: 5.0187\n",
      "Epoch: 044, Loss: 0.1580 tsm_loss: 0.0000 reg_loss: 0.1580 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 4.8713 Test: 4.8713\n",
      "Epoch: 045, Loss: 0.1582 tsm_loss: 0.0000 reg_loss: 0.1582 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 4.7374 Test: 4.7374\n",
      "Epoch: 046, Loss: 0.1469 tsm_loss: 0.0000 reg_loss: 0.1469 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 4.5926 Test: 4.5926\n",
      "Epoch: 047, Loss: 0.1460 tsm_loss: 0.0000 reg_loss: 0.1460 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 4.4443 Test: 4.4443\n",
      "Epoch: 048, Loss: 0.2005 tsm_loss: 0.0000 reg_loss: 0.2005 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 4.2939 Test: 4.2939\n",
      "Epoch: 049, Loss: 0.1439 tsm_loss: 0.0000 reg_loss: 0.1439 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 4.1169 Test: 4.1169\n",
      "Epoch: 050, Loss: 0.1630 tsm_loss: 0.0000 reg_loss: 0.1630 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 3.9997 Test: 3.9997\n",
      "Epoch: 051, Loss: 0.1426 tsm_loss: 0.0000 reg_loss: 0.1426 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 3.8815 Test: 3.8815\n",
      "Epoch: 052, Loss: 0.1707 tsm_loss: 0.0000 reg_loss: 0.1707 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 3.6546 Test: 3.6546\n",
      "Epoch: 053, Loss: 0.1470 tsm_loss: 0.0000 reg_loss: 0.1470 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 3.4608 Test: 3.4608\n",
      "Epoch: 054, Loss: 0.1745 tsm_loss: 0.0000 reg_loss: 0.1745 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 3.2980 Test: 3.2980\n",
      "Epoch: 055, Loss: 0.1410 tsm_loss: 0.0000 reg_loss: 0.1410 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 3.1969 Test: 3.1969\n",
      "Epoch: 056, Loss: 0.1459 tsm_loss: 0.0000 reg_loss: 0.1459 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 3.0547 Test: 3.0547\n",
      "Epoch: 057, Loss: 0.1389 tsm_loss: 0.0000 reg_loss: 0.1389 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 2.8556 Test: 2.8556\n",
      "Epoch: 058, Loss: 0.1336 tsm_loss: 0.0000 reg_loss: 0.1336 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 2.6961 Test: 2.6961\n",
      "Epoch: 059, Loss: 0.1232 tsm_loss: 0.0000 reg_loss: 0.1232 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 2.6041 Test: 2.6041\n",
      "Epoch: 060, Loss: 0.1309 tsm_loss: 0.0000 reg_loss: 0.1309 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 2.4687 Test: 2.4687\n",
      "Epoch: 061, Loss: 0.1149 tsm_loss: 0.0000 reg_loss: 0.1149 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 2.2869 Test: 2.2869\n",
      "Epoch: 062, Loss: 0.1210 tsm_loss: 0.0000 reg_loss: 0.1210 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 2.1796 Test: 2.1796\n",
      "Epoch: 063, Loss: 0.1113 tsm_loss: 0.0000 reg_loss: 0.1113 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 2.0531 Test: 2.0531\n",
      "Epoch: 064, Loss: 0.1137 tsm_loss: 0.0000 reg_loss: 0.1137 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 2.0220 Test: 2.0220\n",
      "Epoch: 065, Loss: 0.1351 tsm_loss: 0.0000 reg_loss: 0.1351 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 1.8786 Test: 1.8786\n",
      "Epoch: 066, Loss: 0.1057 tsm_loss: 0.0000 reg_loss: 0.1057 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 1.7058 Test: 1.7058\n",
      "Epoch: 067, Loss: 0.1430 tsm_loss: 0.0000 reg_loss: 0.1430 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 1.6624 Test: 1.6624\n",
      "Epoch: 068, Loss: 0.1090 tsm_loss: 0.0000 reg_loss: 0.1090 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 1.6085 Test: 1.6085\n",
      "Epoch: 069, Loss: 0.1340 tsm_loss: 0.0000 reg_loss: 0.1340 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 1.4544 Test: 1.4544\n",
      "Epoch: 070, Loss: 0.1318 tsm_loss: 0.0000 reg_loss: 0.1318 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 1.2820 Test: 1.2820\n",
      "Epoch: 071, Loss: 0.1292 tsm_loss: 0.0000 reg_loss: 0.1292 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 1.2374 Test: 1.2374\n",
      "Epoch: 072, Loss: 0.1335 tsm_loss: 0.0000 reg_loss: 0.1335 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 1.1129 Test: 1.1129\n",
      "Epoch: 073, Loss: 0.1241 tsm_loss: 0.0000 reg_loss: 0.1241 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.9074 Test: 0.9074\n",
      "Epoch: 074, Loss: 0.1310 tsm_loss: 0.0000 reg_loss: 0.1310 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.8563 Test: 0.8563\n",
      "Epoch: 075, Loss: 0.1056 tsm_loss: 0.0000 reg_loss: 0.1056 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.7675 Test: 0.7675\n",
      "Epoch: 076, Loss: 0.1229 tsm_loss: 0.0000 reg_loss: 0.1229 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.6010 Test: 0.6010\n",
      "Epoch: 077, Loss: 0.1279 tsm_loss: 0.0000 reg_loss: 0.1279 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.6159 Test: 0.6159\n",
      "Epoch: 078, Loss: 0.1110 tsm_loss: 0.0000 reg_loss: 0.1110 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.7258 Test: 0.7258\n",
      "Epoch: 079, Loss: 0.1317 tsm_loss: 0.0000 reg_loss: 0.1317 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.6685 Test: 0.6685\n",
      "Epoch: 080, Loss: 0.1024 tsm_loss: 0.0000 reg_loss: 0.1024 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5378 Test: 0.5378\n",
      "Epoch: 081, Loss: 0.1411 tsm_loss: 0.0000 reg_loss: 0.1411 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5461 Test: 0.5461\n",
      "Epoch: 082, Loss: 0.1289 tsm_loss: 0.0000 reg_loss: 0.1289 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5376 Test: 0.5376\n",
      "Epoch: 083, Loss: 0.1163 tsm_loss: 0.0000 reg_loss: 0.1163 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4942 Test: 0.4942\n",
      "Epoch: 084, Loss: 0.1291 tsm_loss: 0.0000 reg_loss: 0.1291 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4227 Test: 0.4227\n",
      "Epoch: 085, Loss: 0.1277 tsm_loss: 0.0000 reg_loss: 0.1277 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4141 Test: 0.4141\n",
      "Epoch: 086, Loss: 0.1232 tsm_loss: 0.0000 reg_loss: 0.1232 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4015 Test: 0.4015\n",
      "Epoch: 087, Loss: 0.1302 tsm_loss: 0.0000 reg_loss: 0.1302 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3833 Test: 0.3833\n",
      "Epoch: 088, Loss: 0.0948 tsm_loss: 0.0000 reg_loss: 0.0948 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3790 Test: 0.3790\n",
      "Epoch: 089, Loss: 0.1219 tsm_loss: 0.0000 reg_loss: 0.1219 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3772 Test: 0.3772\n",
      "Epoch: 090, Loss: 0.1006 tsm_loss: 0.0000 reg_loss: 0.1006 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3801 Test: 0.3801\n",
      "Epoch: 091, Loss: 0.1026 tsm_loss: 0.0000 reg_loss: 0.1026 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4094 Test: 0.4094\n",
      "Epoch: 092, Loss: 0.1078 tsm_loss: 0.0000 reg_loss: 0.1078 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4287 Test: 0.4287\n",
      "Epoch: 093, Loss: 0.0979 tsm_loss: 0.0000 reg_loss: 0.0979 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3986 Test: 0.3986\n",
      "Epoch: 094, Loss: 0.1084 tsm_loss: 0.0000 reg_loss: 0.1084 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3862 Test: 0.3862\n",
      "Epoch: 095, Loss: 0.0998 tsm_loss: 0.0000 reg_loss: 0.0998 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3897 Test: 0.3897\n",
      "Epoch: 096, Loss: 0.0971 tsm_loss: 0.0000 reg_loss: 0.0971 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3756 Test: 0.3756\n",
      "Epoch: 097, Loss: 0.1034 tsm_loss: 0.0000 reg_loss: 0.1034 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3835 Test: 0.3835\n",
      "Epoch: 098, Loss: 0.0893 tsm_loss: 0.0000 reg_loss: 0.0893 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4191 Test: 0.4191\n",
      "Epoch: 099, Loss: 0.0961 tsm_loss: 0.0000 reg_loss: 0.0961 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4141 Test: 0.4141\n",
      "Epoch: 100, Loss: 0.0861 tsm_loss: 0.0000 reg_loss: 0.0861 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3849 Test: 0.3849\n",
      "Epoch: 101, Loss: 0.0829 tsm_loss: 0.0000 reg_loss: 0.0829 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3703 Test: 0.3703\n",
      "Epoch: 102, Loss: 0.0896 tsm_loss: 0.0000 reg_loss: 0.0896 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3709 Test: 0.3709\n",
      "Epoch: 103, Loss: 0.0896 tsm_loss: 0.0000 reg_loss: 0.0896 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3830 Test: 0.3830\n",
      "Epoch: 104, Loss: 0.0947 tsm_loss: 0.0000 reg_loss: 0.0947 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4007 Test: 0.4007\n",
      "Epoch: 105, Loss: 0.0863 tsm_loss: 0.0000 reg_loss: 0.0863 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3882 Test: 0.3882\n",
      "Epoch: 106, Loss: 0.0844 tsm_loss: 0.0000 reg_loss: 0.0844 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3845 Test: 0.3845\n",
      "Epoch: 107, Loss: 0.0986 tsm_loss: 0.0000 reg_loss: 0.0986 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3797 Test: 0.3797\n",
      "Epoch: 108, Loss: 0.0864 tsm_loss: 0.0000 reg_loss: 0.0864 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3918 Test: 0.3918\n",
      "Epoch: 109, Loss: 0.0872 tsm_loss: 0.0000 reg_loss: 0.0872 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3991 Test: 0.3991\n",
      "Epoch: 110, Loss: 0.0848 tsm_loss: 0.0000 reg_loss: 0.0848 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4039 Test: 0.4039\n",
      "Epoch: 111, Loss: 0.0820 tsm_loss: 0.0000 reg_loss: 0.0820 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4072 Test: 0.4072\n",
      "Epoch: 112, Loss: 0.0778 tsm_loss: 0.0000 reg_loss: 0.0778 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4041 Test: 0.4041\n",
      "Epoch: 113, Loss: 0.0718 tsm_loss: 0.0000 reg_loss: 0.0718 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4035 Test: 0.4035\n",
      "Epoch: 114, Loss: 0.0675 tsm_loss: 0.0000 reg_loss: 0.0675 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3871 Test: 0.3871\n",
      "Epoch: 115, Loss: 0.0767 tsm_loss: 0.0000 reg_loss: 0.0767 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3880 Test: 0.3880\n",
      "Epoch: 116, Loss: 0.0710 tsm_loss: 0.0000 reg_loss: 0.0710 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3824 Test: 0.3824\n",
      "Epoch: 117, Loss: 0.0670 tsm_loss: 0.0000 reg_loss: 0.0670 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3945 Test: 0.3945\n",
      "Epoch: 118, Loss: 0.0688 tsm_loss: 0.0000 reg_loss: 0.0688 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4422 Test: 0.4422\n",
      "Epoch: 119, Loss: 0.0834 tsm_loss: 0.0000 reg_loss: 0.0834 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4470 Test: 0.4470\n",
      "Epoch: 120, Loss: 0.0747 tsm_loss: 0.0000 reg_loss: 0.0747 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4504 Test: 0.4504\n",
      "Epoch: 121, Loss: 0.0668 tsm_loss: 0.0000 reg_loss: 0.0668 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4772 Test: 0.4772\n",
      "Epoch: 122, Loss: 0.0655 tsm_loss: 0.0000 reg_loss: 0.0655 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5269 Test: 0.5269\n",
      "Epoch: 123, Loss: 0.0660 tsm_loss: 0.0000 reg_loss: 0.0660 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5164 Test: 0.5164\n",
      "Epoch: 124, Loss: 0.0677 tsm_loss: 0.0000 reg_loss: 0.0677 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5052 Test: 0.5052\n",
      "Epoch: 125, Loss: 0.0633 tsm_loss: 0.0000 reg_loss: 0.0633 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4881 Test: 0.4881\n",
      "Epoch: 126, Loss: 0.0607 tsm_loss: 0.0000 reg_loss: 0.0607 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4836 Test: 0.4836\n",
      "Epoch: 127, Loss: 0.0626 tsm_loss: 0.0000 reg_loss: 0.0626 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4374 Test: 0.4374\n",
      "Epoch: 128, Loss: 0.0654 tsm_loss: 0.0000 reg_loss: 0.0654 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4233 Test: 0.4234\n",
      "Epoch: 129, Loss: 0.0582 tsm_loss: 0.0000 reg_loss: 0.0582 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4266 Test: 0.4266\n",
      "Epoch: 130, Loss: 0.0625 tsm_loss: 0.0000 reg_loss: 0.0625 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4169 Test: 0.4169\n",
      "Epoch: 131, Loss: 0.0607 tsm_loss: 0.0000 reg_loss: 0.0607 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4218 Test: 0.4218\n",
      "Epoch: 132, Loss: 0.0714 tsm_loss: 0.0000 reg_loss: 0.0714 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3995 Test: 0.3995\n",
      "Epoch: 133, Loss: 0.0650 tsm_loss: 0.0000 reg_loss: 0.0650 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4080 Test: 0.4080\n",
      "Epoch: 134, Loss: 0.0587 tsm_loss: 0.0000 reg_loss: 0.0587 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4161 Test: 0.4161\n",
      "Epoch: 135, Loss: 0.0660 tsm_loss: 0.0000 reg_loss: 0.0660 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3969 Test: 0.3969\n",
      "Epoch: 136, Loss: 0.0674 tsm_loss: 0.0000 reg_loss: 0.0674 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3979 Test: 0.3979\n",
      "Epoch: 137, Loss: 0.0724 tsm_loss: 0.0000 reg_loss: 0.0724 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4110 Test: 0.4110\n",
      "Epoch: 138, Loss: 0.0606 tsm_loss: 0.0000 reg_loss: 0.0606 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4133 Test: 0.4133\n",
      "Epoch: 139, Loss: 0.0603 tsm_loss: 0.0000 reg_loss: 0.0603 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4172 Test: 0.4172\n",
      "Epoch: 140, Loss: 0.0810 tsm_loss: 0.0000 reg_loss: 0.0810 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4123 Test: 0.4123\n",
      "Epoch: 141, Loss: 0.0576 tsm_loss: 0.0000 reg_loss: 0.0576 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4040 Test: 0.4040\n",
      "Epoch: 142, Loss: 0.0867 tsm_loss: 0.0000 reg_loss: 0.0867 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4180 Test: 0.4180\n",
      "Epoch: 143, Loss: 0.0681 tsm_loss: 0.0000 reg_loss: 0.0681 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4362 Test: 0.4362\n",
      "Epoch: 144, Loss: 0.0783 tsm_loss: 0.0000 reg_loss: 0.0783 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4228 Test: 0.4228\n",
      "Epoch: 145, Loss: 0.0894 tsm_loss: 0.0000 reg_loss: 0.0894 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4357 Test: 0.4357\n",
      "Epoch: 146, Loss: 0.0781 tsm_loss: 0.0000 reg_loss: 0.0781 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4674 Test: 0.4674\n",
      "Epoch: 147, Loss: 0.0976 tsm_loss: 0.0000 reg_loss: 0.0976 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4496 Test: 0.4496\n",
      "Epoch: 148, Loss: 0.0877 tsm_loss: 0.0000 reg_loss: 0.0877 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4100 Test: 0.4100\n",
      "Epoch: 149, Loss: 0.0812 tsm_loss: 0.0000 reg_loss: 0.0812 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4090 Test: 0.4090\n",
      "Epoch: 150, Loss: 0.0699 tsm_loss: 0.0000 reg_loss: 0.0699 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4188 Test: 0.4188\n",
      "Epoch: 151, Loss: 0.0746 tsm_loss: 0.0000 reg_loss: 0.0746 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4275 Test: 0.4275\n",
      "Epoch: 152, Loss: 0.0653 tsm_loss: 0.0000 reg_loss: 0.0653 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4176 Test: 0.4176\n",
      "Epoch: 153, Loss: 0.0575 tsm_loss: 0.0000 reg_loss: 0.0575 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4017 Test: 0.4017\n",
      "Epoch: 154, Loss: 0.0725 tsm_loss: 0.0000 reg_loss: 0.0725 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4160 Test: 0.4160\n",
      "Epoch: 155, Loss: 0.0545 tsm_loss: 0.0000 reg_loss: 0.0545 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4493 Test: 0.4493\n",
      "Epoch: 156, Loss: 0.0902 tsm_loss: 0.0000 reg_loss: 0.0902 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4311 Test: 0.4311\n",
      "Epoch: 157, Loss: 0.0618 tsm_loss: 0.0000 reg_loss: 0.0618 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3912 Test: 0.3912\n",
      "Epoch: 158, Loss: 0.0803 tsm_loss: 0.0000 reg_loss: 0.0803 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4000 Test: 0.4000\n",
      "Epoch: 159, Loss: 0.0862 tsm_loss: 0.0000 reg_loss: 0.0862 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4165 Test: 0.4165\n",
      "Epoch: 160, Loss: 0.0715 tsm_loss: 0.0000 reg_loss: 0.0715 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4184 Test: 0.4184\n",
      "Epoch: 161, Loss: 0.0892 tsm_loss: 0.0000 reg_loss: 0.0892 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4050 Test: 0.4050\n",
      "Epoch: 162, Loss: 0.0928 tsm_loss: 0.0000 reg_loss: 0.0928 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3884 Test: 0.3884\n",
      "Epoch: 163, Loss: 0.0550 tsm_loss: 0.0000 reg_loss: 0.0550 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3925 Test: 0.3925\n",
      "Epoch: 164, Loss: 0.0842 tsm_loss: 0.0000 reg_loss: 0.0842 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3926 Test: 0.3926\n",
      "Epoch: 165, Loss: 0.0602 tsm_loss: 0.0000 reg_loss: 0.0602 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4042 Test: 0.4042\n",
      "Epoch: 166, Loss: 0.0792 tsm_loss: 0.0000 reg_loss: 0.0792 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3999 Test: 0.3999\n",
      "Epoch: 167, Loss: 0.0746 tsm_loss: 0.0000 reg_loss: 0.0746 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4010 Test: 0.4010\n",
      "Epoch: 168, Loss: 0.0751 tsm_loss: 0.0000 reg_loss: 0.0751 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3943 Test: 0.3943\n",
      "Epoch: 169, Loss: 0.0774 tsm_loss: 0.0000 reg_loss: 0.0774 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4231 Test: 0.4231\n",
      "Epoch: 170, Loss: 0.0843 tsm_loss: 0.0000 reg_loss: 0.0843 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4186 Test: 0.4186\n",
      "Epoch: 171, Loss: 0.0656 tsm_loss: 0.0000 reg_loss: 0.0656 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4098 Test: 0.4098\n",
      "Epoch: 172, Loss: 0.0818 tsm_loss: 0.0000 reg_loss: 0.0818 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3958 Test: 0.3958\n",
      "Epoch: 173, Loss: 0.0545 tsm_loss: 0.0000 reg_loss: 0.0545 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3857 Test: 0.3857\n",
      "Epoch: 174, Loss: 0.0770 tsm_loss: 0.0000 reg_loss: 0.0770 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3935 Test: 0.3935\n",
      "Epoch: 175, Loss: 0.0676 tsm_loss: 0.0000 reg_loss: 0.0676 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4380 Test: 0.4380\n",
      "Epoch: 176, Loss: 0.0646 tsm_loss: 0.0000 reg_loss: 0.0646 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4470 Test: 0.4470\n",
      "Epoch: 177, Loss: 0.0650 tsm_loss: 0.0000 reg_loss: 0.0650 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4198 Test: 0.4198\n",
      "Epoch: 178, Loss: 0.0613 tsm_loss: 0.0000 reg_loss: 0.0613 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4095 Test: 0.4095\n",
      "Epoch: 179, Loss: 0.0653 tsm_loss: 0.0000 reg_loss: 0.0653 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3962 Test: 0.3962\n",
      "Epoch: 180, Loss: 0.0529 tsm_loss: 0.0000 reg_loss: 0.0529 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3951 Test: 0.3951\n",
      "Epoch: 181, Loss: 0.0618 tsm_loss: 0.0000 reg_loss: 0.0618 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4124 Test: 0.4124\n",
      "Epoch: 182, Loss: 0.0510 tsm_loss: 0.0000 reg_loss: 0.0510 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4369 Test: 0.4369\n",
      "Epoch: 183, Loss: 0.0623 tsm_loss: 0.0000 reg_loss: 0.0623 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4205 Test: 0.4205\n",
      "Epoch: 184, Loss: 0.0548 tsm_loss: 0.0000 reg_loss: 0.0548 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4241 Test: 0.4241\n",
      "Epoch: 185, Loss: 0.0614 tsm_loss: 0.0000 reg_loss: 0.0614 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4283 Test: 0.4283\n",
      "Epoch: 186, Loss: 0.0513 tsm_loss: 0.0000 reg_loss: 0.0513 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4311 Test: 0.4311\n",
      "Epoch: 187, Loss: 0.0569 tsm_loss: 0.0000 reg_loss: 0.0569 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4309 Test: 0.4309\n",
      "Epoch: 188, Loss: 0.0545 tsm_loss: 0.0000 reg_loss: 0.0545 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4203 Test: 0.4203\n",
      "Epoch: 189, Loss: 0.0503 tsm_loss: 0.0000 reg_loss: 0.0503 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4058 Test: 0.4058\n",
      "Epoch: 190, Loss: 0.0539 tsm_loss: 0.0000 reg_loss: 0.0539 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4039 Test: 0.4039\n",
      "Epoch: 191, Loss: 0.0455 tsm_loss: 0.0000 reg_loss: 0.0455 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4125 Test: 0.4125\n",
      "Epoch: 192, Loss: 0.0419 tsm_loss: 0.0000 reg_loss: 0.0419 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4139 Test: 0.4139\n",
      "Epoch: 193, Loss: 0.0468 tsm_loss: 0.0000 reg_loss: 0.0468 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4242 Test: 0.4242\n",
      "Epoch: 194, Loss: 0.0370 tsm_loss: 0.0000 reg_loss: 0.0370 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4182 Test: 0.4182\n",
      "Epoch: 195, Loss: 0.0475 tsm_loss: 0.0000 reg_loss: 0.0475 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4067 Test: 0.4067\n",
      "Epoch: 196, Loss: 0.0403 tsm_loss: 0.0000 reg_loss: 0.0403 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4114 Test: 0.4114\n",
      "Epoch: 197, Loss: 0.0467 tsm_loss: 0.0000 reg_loss: 0.0467 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4124 Test: 0.4124\n",
      "Epoch: 198, Loss: 0.0445 tsm_loss: 0.0000 reg_loss: 0.0445 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4178 Test: 0.4178\n",
      "Epoch: 199, Loss: 0.0475 tsm_loss: 0.0000 reg_loss: 0.0475 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4145 Test: 0.4145\n",
      "Epoch: 200, Loss: 0.0401 tsm_loss: 0.0000 reg_loss: 0.0401 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3914 Test: 0.3914\n",
      "Epoch: 201, Loss: 0.0489 tsm_loss: 0.0000 reg_loss: 0.0489 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3909 Test: 0.3909\n",
      "Epoch: 202, Loss: 0.0509 tsm_loss: 0.0000 reg_loss: 0.0509 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3921 Test: 0.3921\n",
      "Epoch: 203, Loss: 0.0404 tsm_loss: 0.0000 reg_loss: 0.0404 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4240 Test: 0.4240\n",
      "Epoch: 204, Loss: 0.0404 tsm_loss: 0.0000 reg_loss: 0.0404 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4261 Test: 0.4261\n",
      "Epoch: 205, Loss: 0.0376 tsm_loss: 0.0000 reg_loss: 0.0376 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4069 Test: 0.4069\n",
      "Epoch: 206, Loss: 0.0448 tsm_loss: 0.0000 reg_loss: 0.0448 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4119 Test: 0.4119\n",
      "Epoch: 207, Loss: 0.0382 tsm_loss: 0.0000 reg_loss: 0.0382 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4448 Test: 0.4448\n",
      "Epoch: 208, Loss: 0.0497 tsm_loss: 0.0000 reg_loss: 0.0497 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4368 Test: 0.4368\n",
      "Epoch: 209, Loss: 0.0388 tsm_loss: 0.0000 reg_loss: 0.0388 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4170 Test: 0.4170\n",
      "Epoch: 210, Loss: 0.0464 tsm_loss: 0.0000 reg_loss: 0.0464 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4153 Test: 0.4153\n",
      "Epoch: 211, Loss: 0.0450 tsm_loss: 0.0000 reg_loss: 0.0450 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4047 Test: 0.4047\n",
      "Epoch: 212, Loss: 0.0539 tsm_loss: 0.0000 reg_loss: 0.0539 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4041 Test: 0.4041\n",
      "Epoch: 213, Loss: 0.0379 tsm_loss: 0.0000 reg_loss: 0.0379 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3972 Test: 0.3972\n",
      "Epoch: 214, Loss: 0.0439 tsm_loss: 0.0000 reg_loss: 0.0439 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4114 Test: 0.4114\n",
      "Epoch: 215, Loss: 0.0457 tsm_loss: 0.0000 reg_loss: 0.0457 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4220 Test: 0.4220\n",
      "Epoch: 216, Loss: 0.0344 tsm_loss: 0.0000 reg_loss: 0.0344 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4598 Test: 0.4598\n",
      "Epoch: 217, Loss: 0.0485 tsm_loss: 0.0000 reg_loss: 0.0485 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4494 Test: 0.4494\n",
      "Epoch: 218, Loss: 0.0392 tsm_loss: 0.0000 reg_loss: 0.0392 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4366 Test: 0.4366\n",
      "Epoch: 219, Loss: 0.0484 tsm_loss: 0.0000 reg_loss: 0.0484 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4151 Test: 0.4151\n",
      "Epoch: 220, Loss: 0.0589 tsm_loss: 0.0000 reg_loss: 0.0589 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4567 Test: 0.4567\n",
      "Epoch: 221, Loss: 0.0472 tsm_loss: 0.0000 reg_loss: 0.0472 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4577 Test: 0.4577\n",
      "Epoch: 222, Loss: 0.0394 tsm_loss: 0.0000 reg_loss: 0.0394 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4452 Test: 0.4452\n",
      "Epoch: 223, Loss: 0.0357 tsm_loss: 0.0000 reg_loss: 0.0357 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4421 Test: 0.4421\n",
      "Epoch: 224, Loss: 0.0329 tsm_loss: 0.0000 reg_loss: 0.0329 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4490 Test: 0.4490\n",
      "Epoch: 225, Loss: 0.0432 tsm_loss: 0.0000 reg_loss: 0.0432 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4796 Test: 0.4796\n",
      "Epoch: 226, Loss: 0.0433 tsm_loss: 0.0000 reg_loss: 0.0433 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4560 Test: 0.4560\n",
      "Epoch: 227, Loss: 0.0498 tsm_loss: 0.0000 reg_loss: 0.0498 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4620 Test: 0.4620\n",
      "Epoch: 228, Loss: 0.0522 tsm_loss: 0.0000 reg_loss: 0.0522 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4206 Test: 0.4206\n",
      "Epoch: 229, Loss: 0.0415 tsm_loss: 0.0000 reg_loss: 0.0415 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4065 Test: 0.4065\n",
      "Epoch: 230, Loss: 0.0537 tsm_loss: 0.0000 reg_loss: 0.0537 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4409 Test: 0.4409\n",
      "Epoch: 231, Loss: 0.0541 tsm_loss: 0.0000 reg_loss: 0.0541 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4266 Test: 0.4266\n",
      "Epoch: 232, Loss: 0.0387 tsm_loss: 0.0000 reg_loss: 0.0387 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3997 Test: 0.3997\n",
      "Epoch: 233, Loss: 0.0490 tsm_loss: 0.0000 reg_loss: 0.0490 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4090 Test: 0.4090\n",
      "Epoch: 234, Loss: 0.0692 tsm_loss: 0.0000 reg_loss: 0.0692 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3959 Test: 0.3959\n",
      "Epoch: 235, Loss: 0.0352 tsm_loss: 0.0000 reg_loss: 0.0352 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4069 Test: 0.4069\n",
      "Epoch: 236, Loss: 0.0400 tsm_loss: 0.0000 reg_loss: 0.0400 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4379 Test: 0.4379\n",
      "Epoch: 237, Loss: 0.0714 tsm_loss: 0.0000 reg_loss: 0.0714 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4241 Test: 0.4241\n",
      "Epoch: 238, Loss: 0.0403 tsm_loss: 0.0000 reg_loss: 0.0403 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4173 Test: 0.4173\n",
      "Epoch: 239, Loss: 0.0862 tsm_loss: 0.0000 reg_loss: 0.0862 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4134 Test: 0.4134\n",
      "Epoch: 240, Loss: 0.0617 tsm_loss: 0.0000 reg_loss: 0.0617 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4311 Test: 0.4311\n",
      "Epoch: 241, Loss: 0.1065 tsm_loss: 0.0000 reg_loss: 0.1065 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4474 Test: 0.4474\n",
      "Epoch: 242, Loss: 0.0547 tsm_loss: 0.0000 reg_loss: 0.0547 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4385 Test: 0.4385\n",
      "Epoch: 243, Loss: 0.1022 tsm_loss: 0.0000 reg_loss: 0.1022 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4628 Test: 0.4628\n",
      "Epoch: 244, Loss: 0.0716 tsm_loss: 0.0000 reg_loss: 0.0716 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5288 Test: 0.5288\n",
      "Epoch: 245, Loss: 0.0882 tsm_loss: 0.0000 reg_loss: 0.0882 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5387 Test: 0.5387\n",
      "Epoch: 246, Loss: 0.0868 tsm_loss: 0.0000 reg_loss: 0.0868 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4850 Test: 0.4850\n",
      "Epoch: 247, Loss: 0.0565 tsm_loss: 0.0000 reg_loss: 0.0565 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4854 Test: 0.4854\n",
      "Epoch: 248, Loss: 0.0756 tsm_loss: 0.0000 reg_loss: 0.0756 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5205 Test: 0.5205\n",
      "Epoch: 249, Loss: 0.0605 tsm_loss: 0.0000 reg_loss: 0.0605 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4862 Test: 0.4862\n",
      "Epoch: 250, Loss: 0.0554 tsm_loss: 0.0000 reg_loss: 0.0554 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4178 Test: 0.4178\n",
      "Epoch: 251, Loss: 0.0722 tsm_loss: 0.0000 reg_loss: 0.0722 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4154 Test: 0.4154\n",
      "Epoch: 252, Loss: 0.0721 tsm_loss: 0.0000 reg_loss: 0.0721 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4296 Test: 0.4296\n",
      "Epoch: 253, Loss: 0.0516 tsm_loss: 0.0000 reg_loss: 0.0516 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4318 Test: 0.4318\n",
      "Epoch: 254, Loss: 0.0590 tsm_loss: 0.0000 reg_loss: 0.0590 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4110 Test: 0.4110\n",
      "Epoch: 255, Loss: 0.0569 tsm_loss: 0.0000 reg_loss: 0.0569 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3987 Test: 0.3987\n",
      "Epoch: 256, Loss: 0.0447 tsm_loss: 0.0000 reg_loss: 0.0447 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4029 Test: 0.4029\n",
      "Epoch: 257, Loss: 0.0583 tsm_loss: 0.0000 reg_loss: 0.0583 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4128 Test: 0.4128\n",
      "Epoch: 258, Loss: 0.0385 tsm_loss: 0.0000 reg_loss: 0.0385 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4258 Test: 0.4258\n",
      "Epoch: 259, Loss: 0.0582 tsm_loss: 0.0000 reg_loss: 0.0582 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4310 Test: 0.4310\n",
      "Epoch: 260, Loss: 0.0415 tsm_loss: 0.0000 reg_loss: 0.0415 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4131 Test: 0.4131\n",
      "Epoch: 261, Loss: 0.0555 tsm_loss: 0.0000 reg_loss: 0.0555 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4016 Test: 0.4016\n",
      "Epoch: 262, Loss: 0.0530 tsm_loss: 0.0000 reg_loss: 0.0530 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4042 Test: 0.4042\n",
      "Epoch: 263, Loss: 0.0370 tsm_loss: 0.0000 reg_loss: 0.0370 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4244 Test: 0.4244\n",
      "Epoch: 264, Loss: 0.0504 tsm_loss: 0.0000 reg_loss: 0.0504 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4130 Test: 0.4130\n",
      "Epoch: 265, Loss: 0.0317 tsm_loss: 0.0000 reg_loss: 0.0317 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4035 Test: 0.4035\n",
      "Epoch: 266, Loss: 0.0563 tsm_loss: 0.0000 reg_loss: 0.0563 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4025 Test: 0.4025\n",
      "Epoch: 267, Loss: 0.0401 tsm_loss: 0.0000 reg_loss: 0.0401 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4128 Test: 0.4128\n",
      "Epoch: 268, Loss: 0.0624 tsm_loss: 0.0000 reg_loss: 0.0624 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4200 Test: 0.4200\n",
      "Epoch: 269, Loss: 0.0572 tsm_loss: 0.0000 reg_loss: 0.0572 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4142 Test: 0.4142\n",
      "Epoch: 270, Loss: 0.0761 tsm_loss: 0.0000 reg_loss: 0.0761 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4259 Test: 0.4259\n",
      "Epoch: 271, Loss: 0.0689 tsm_loss: 0.0000 reg_loss: 0.0689 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4112 Test: 0.4112\n",
      "Epoch: 272, Loss: 0.0773 tsm_loss: 0.0000 reg_loss: 0.0773 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3940 Test: 0.3940\n",
      "Epoch: 273, Loss: 0.0528 tsm_loss: 0.0000 reg_loss: 0.0528 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4090 Test: 0.4090\n",
      "Epoch: 274, Loss: 0.0673 tsm_loss: 0.0000 reg_loss: 0.0673 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4088 Test: 0.4088\n",
      "Epoch: 275, Loss: 0.0532 tsm_loss: 0.0000 reg_loss: 0.0532 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4128 Test: 0.4128\n",
      "Epoch: 276, Loss: 0.0672 tsm_loss: 0.0000 reg_loss: 0.0672 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4086 Test: 0.4086\n",
      "Epoch: 277, Loss: 0.0484 tsm_loss: 0.0000 reg_loss: 0.0484 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4086 Test: 0.4086\n",
      "Epoch: 278, Loss: 0.0740 tsm_loss: 0.0000 reg_loss: 0.0740 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4043 Test: 0.4043\n",
      "Epoch: 279, Loss: 0.0627 tsm_loss: 0.0000 reg_loss: 0.0627 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4055 Test: 0.4055\n",
      "Epoch: 280, Loss: 0.0648 tsm_loss: 0.0000 reg_loss: 0.0648 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4110 Test: 0.4110\n",
      "Epoch: 281, Loss: 0.0599 tsm_loss: 0.0000 reg_loss: 0.0599 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4000 Test: 0.4000\n",
      "Epoch: 282, Loss: 0.0567 tsm_loss: 0.0000 reg_loss: 0.0567 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3928 Test: 0.3928\n",
      "Epoch: 283, Loss: 0.0534 tsm_loss: 0.0000 reg_loss: 0.0534 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3929 Test: 0.3929\n",
      "Epoch: 284, Loss: 0.0553 tsm_loss: 0.0000 reg_loss: 0.0553 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4005 Test: 0.4005\n",
      "Epoch: 285, Loss: 0.0544 tsm_loss: 0.0000 reg_loss: 0.0544 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4108 Test: 0.4108\n",
      "Epoch: 286, Loss: 0.0544 tsm_loss: 0.0000 reg_loss: 0.0544 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4244 Test: 0.4244\n",
      "Epoch: 287, Loss: 0.0484 tsm_loss: 0.0000 reg_loss: 0.0484 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4358 Test: 0.4358\n",
      "Epoch: 288, Loss: 0.0549 tsm_loss: 0.0000 reg_loss: 0.0549 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4292 Test: 0.4292\n",
      "Epoch: 289, Loss: 0.0413 tsm_loss: 0.0000 reg_loss: 0.0413 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4058 Test: 0.4058\n",
      "Epoch: 290, Loss: 0.0535 tsm_loss: 0.0000 reg_loss: 0.0535 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.3981 Test: 0.3981\n",
      "Epoch: 291, Loss: 0.0383 tsm_loss: 0.0000 reg_loss: 0.0383 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4220 Test: 0.4220\n",
      "Epoch: 292, Loss: 0.0671 tsm_loss: 0.0000 reg_loss: 0.0671 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4382 Test: 0.4382\n",
      "Epoch: 293, Loss: 0.0422 tsm_loss: 0.0000 reg_loss: 0.0422 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4461 Test: 0.4461\n",
      "Epoch: 294, Loss: 0.0610 tsm_loss: 0.0000 reg_loss: 0.0610 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4624 Test: 0.4624\n",
      "Epoch: 295, Loss: 0.0616 tsm_loss: 0.0000 reg_loss: 0.0616 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4660 Test: 0.4660\n",
      "Epoch: 296, Loss: 0.0424 tsm_loss: 0.0000 reg_loss: 0.0424 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4419 Test: 0.4419\n",
      "Epoch: 297, Loss: 0.0622 tsm_loss: 0.0000 reg_loss: 0.0622 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4210 Test: 0.4210\n",
      "Epoch: 298, Loss: 0.0581 tsm_loss: 0.0000 reg_loss: 0.0581 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.4464 Test: 0.4464\n",
      "Epoch: 299, Loss: 0.0475 tsm_loss: 0.0000 reg_loss: 0.0475 N_Y: 125162 N_S: 000 N: 000 N_HV: 000 Val: 0.5000 Test: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 6.7588 tsm_loss: 0.0000 reg_loss: 6.7588 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9041 Test: 6.9041\n",
      "Epoch: 002, Loss: 6.5140 tsm_loss: 0.0000 reg_loss: 6.5140 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9031 Test: 6.9031\n",
      "Epoch: 003, Loss: 6.3043 tsm_loss: 0.0000 reg_loss: 6.3043 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9025 Test: 6.9025\n",
      "Epoch: 004, Loss: 6.1232 tsm_loss: 0.0000 reg_loss: 6.1232 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9024 Test: 6.9024\n",
      "Epoch: 005, Loss: 5.9599 tsm_loss: 0.0000 reg_loss: 5.9599 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9023 Test: 6.9023\n",
      "Epoch: 006, Loss: 5.8028 tsm_loss: 0.0000 reg_loss: 5.8028 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9022 Test: 6.9022\n",
      "Epoch: 007, Loss: 5.6459 tsm_loss: 0.0000 reg_loss: 5.6459 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9021 Test: 6.9021\n",
      "Epoch: 008, Loss: 5.4908 tsm_loss: 0.0000 reg_loss: 5.4908 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9020 Test: 6.9020\n",
      "Epoch: 009, Loss: 5.3301 tsm_loss: 0.0000 reg_loss: 5.3301 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9019 Test: 6.9019\n",
      "Epoch: 010, Loss: 5.1671 tsm_loss: 0.0000 reg_loss: 5.1671 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9018 Test: 6.9018\n",
      "Epoch: 011, Loss: 5.0016 tsm_loss: 0.0000 reg_loss: 5.0016 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9019 Test: 6.9019\n",
      "Epoch: 012, Loss: 4.8300 tsm_loss: 0.0000 reg_loss: 4.8300 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9017 Test: 6.9017\n",
      "Epoch: 013, Loss: 4.6527 tsm_loss: 0.0000 reg_loss: 4.6527 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9014 Test: 6.9014\n",
      "Epoch: 014, Loss: 4.4676 tsm_loss: 0.0000 reg_loss: 4.4676 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9008 Test: 6.9008\n",
      "Epoch: 015, Loss: 4.2781 tsm_loss: 0.0000 reg_loss: 4.2781 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9004 Test: 6.9004\n",
      "Epoch: 016, Loss: 4.0796 tsm_loss: 0.0000 reg_loss: 4.0796 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.9000 Test: 6.9000\n",
      "Epoch: 017, Loss: 3.8689 tsm_loss: 0.0000 reg_loss: 3.8689 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8993 Test: 6.8993\n",
      "Epoch: 018, Loss: 3.6481 tsm_loss: 0.0000 reg_loss: 3.6481 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8986 Test: 6.8986\n",
      "Epoch: 019, Loss: 3.4140 tsm_loss: 0.0000 reg_loss: 3.4140 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8981 Test: 6.8981\n",
      "Epoch: 020, Loss: 3.1599 tsm_loss: 0.0000 reg_loss: 3.1599 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8975 Test: 6.8975\n",
      "Epoch: 021, Loss: 2.8878 tsm_loss: 0.0000 reg_loss: 2.8878 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8971 Test: 6.8971\n",
      "Epoch: 022, Loss: 2.5942 tsm_loss: 0.0000 reg_loss: 2.5942 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8964 Test: 6.8964\n",
      "Epoch: 023, Loss: 2.2778 tsm_loss: 0.0000 reg_loss: 2.2778 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8956 Test: 6.8956\n",
      "Epoch: 024, Loss: 1.9387 tsm_loss: 0.0000 reg_loss: 1.9387 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8945 Test: 6.8945\n",
      "Epoch: 025, Loss: 1.5860 tsm_loss: 0.0000 reg_loss: 1.5860 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8929 Test: 6.8929\n",
      "Epoch: 026, Loss: 1.2246 tsm_loss: 0.0000 reg_loss: 1.2246 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8910 Test: 6.8910\n",
      "Epoch: 027, Loss: 0.8979 tsm_loss: 0.0000 reg_loss: 0.8979 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8887 Test: 6.8887\n",
      "Epoch: 028, Loss: 0.7612 tsm_loss: 0.0000 reg_loss: 0.7612 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8847 Test: 6.8847\n",
      "Epoch: 029, Loss: 0.6837 tsm_loss: 0.0000 reg_loss: 0.6837 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8743 Test: 6.8743\n",
      "Epoch: 030, Loss: 0.6517 tsm_loss: 0.0000 reg_loss: 0.6517 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8472 Test: 6.8472\n",
      "Epoch: 031, Loss: 0.6205 tsm_loss: 0.0000 reg_loss: 0.6205 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.8007 Test: 6.8007\n",
      "Epoch: 032, Loss: 0.5280 tsm_loss: 0.0000 reg_loss: 0.5280 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.7325 Test: 6.7325\n",
      "Epoch: 033, Loss: 0.4048 tsm_loss: 0.0000 reg_loss: 0.4048 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.6368 Test: 6.6368\n",
      "Epoch: 034, Loss: 0.3318 tsm_loss: 0.0000 reg_loss: 0.3318 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.5267 Test: 6.5267\n",
      "Epoch: 035, Loss: 0.2904 tsm_loss: 0.0000 reg_loss: 0.2904 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.4245 Test: 6.4245\n",
      "Epoch: 036, Loss: 0.3082 tsm_loss: 0.0000 reg_loss: 0.3082 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.3026 Test: 6.3026\n",
      "Epoch: 037, Loss: 0.2621 tsm_loss: 0.0000 reg_loss: 0.2621 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.1526 Test: 6.1526\n",
      "Epoch: 038, Loss: 0.2525 tsm_loss: 0.0000 reg_loss: 0.2525 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 6.0192 Test: 6.0192\n",
      "Epoch: 039, Loss: 0.2330 tsm_loss: 0.0000 reg_loss: 0.2330 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 5.9036 Test: 5.9036\n",
      "Epoch: 040, Loss: 0.2125 tsm_loss: 0.0000 reg_loss: 0.2125 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 5.7648 Test: 5.7648\n",
      "Epoch: 041, Loss: 0.2085 tsm_loss: 0.0000 reg_loss: 0.2085 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 5.5882 Test: 5.5882\n",
      "Epoch: 042, Loss: 0.2124 tsm_loss: 0.0000 reg_loss: 0.2124 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 5.4451 Test: 5.4451\n",
      "Epoch: 043, Loss: 0.2040 tsm_loss: 0.0000 reg_loss: 0.2040 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 5.2962 Test: 5.2962\n",
      "Epoch: 044, Loss: 0.1901 tsm_loss: 0.0000 reg_loss: 0.1901 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 5.1284 Test: 5.1284\n",
      "Epoch: 045, Loss: 0.2002 tsm_loss: 0.0000 reg_loss: 0.2002 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 5.0161 Test: 5.0161\n",
      "Epoch: 046, Loss: 0.1639 tsm_loss: 0.0000 reg_loss: 0.1639 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 4.8897 Test: 4.8897\n",
      "Epoch: 047, Loss: 0.1694 tsm_loss: 0.0000 reg_loss: 0.1694 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 4.6945 Test: 4.6945\n",
      "Epoch: 048, Loss: 0.1674 tsm_loss: 0.0000 reg_loss: 0.1674 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 4.5715 Test: 4.5715\n",
      "Epoch: 049, Loss: 0.1580 tsm_loss: 0.0000 reg_loss: 0.1580 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 4.3938 Test: 4.3938\n",
      "Epoch: 050, Loss: 0.1635 tsm_loss: 0.0000 reg_loss: 0.1635 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 4.1812 Test: 4.1812\n",
      "Epoch: 051, Loss: 0.1677 tsm_loss: 0.0000 reg_loss: 0.1677 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 4.0290 Test: 4.0290\n",
      "Epoch: 052, Loss: 0.1411 tsm_loss: 0.0000 reg_loss: 0.1411 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 3.8457 Test: 3.8457\n",
      "Epoch: 053, Loss: 0.1739 tsm_loss: 0.0000 reg_loss: 0.1739 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 3.6145 Test: 3.6145\n",
      "Epoch: 054, Loss: 0.1449 tsm_loss: 0.0000 reg_loss: 0.1449 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 3.4803 Test: 3.4803\n",
      "Epoch: 055, Loss: 0.1587 tsm_loss: 0.0000 reg_loss: 0.1587 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 3.3640 Test: 3.3640\n",
      "Epoch: 056, Loss: 0.1283 tsm_loss: 0.0000 reg_loss: 0.1283 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 3.2718 Test: 3.2718\n",
      "Epoch: 057, Loss: 0.1636 tsm_loss: 0.0000 reg_loss: 0.1636 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 3.1575 Test: 3.1575\n",
      "Epoch: 058, Loss: 0.1406 tsm_loss: 0.0000 reg_loss: 0.1406 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 2.9055 Test: 2.9055\n",
      "Epoch: 059, Loss: 0.1478 tsm_loss: 0.0000 reg_loss: 0.1478 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 2.6569 Test: 2.6569\n",
      "Epoch: 060, Loss: 0.1440 tsm_loss: 0.0000 reg_loss: 0.1440 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 2.5774 Test: 2.5774\n",
      "Epoch: 061, Loss: 0.1566 tsm_loss: 0.0000 reg_loss: 0.1566 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 2.3513 Test: 2.3513\n",
      "Epoch: 062, Loss: 0.1229 tsm_loss: 0.0000 reg_loss: 0.1229 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 2.1506 Test: 2.1506\n",
      "Epoch: 063, Loss: 0.1357 tsm_loss: 0.0000 reg_loss: 0.1357 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.9798 Test: 1.9798\n",
      "Epoch: 064, Loss: 0.1223 tsm_loss: 0.0000 reg_loss: 0.1223 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.8434 Test: 1.8434\n",
      "Epoch: 065, Loss: 0.1212 tsm_loss: 0.0000 reg_loss: 0.1212 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.6837 Test: 1.6837\n",
      "Epoch: 066, Loss: 0.1190 tsm_loss: 0.0000 reg_loss: 0.1190 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.4568 Test: 1.4568\n",
      "Epoch: 067, Loss: 0.1158 tsm_loss: 0.0000 reg_loss: 0.1158 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.3299 Test: 1.3299\n",
      "Epoch: 068, Loss: 0.1167 tsm_loss: 0.0000 reg_loss: 0.1167 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.2835 Test: 1.2835\n",
      "Epoch: 069, Loss: 0.1140 tsm_loss: 0.0000 reg_loss: 0.1140 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.1529 Test: 1.1529\n",
      "Epoch: 070, Loss: 0.1225 tsm_loss: 0.0000 reg_loss: 0.1225 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.1581 Test: 1.1581\n",
      "Epoch: 071, Loss: 0.1113 tsm_loss: 0.0000 reg_loss: 0.1113 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.0924 Test: 1.0924\n",
      "Epoch: 072, Loss: 0.1043 tsm_loss: 0.0000 reg_loss: 0.1043 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 1.0113 Test: 1.0113\n",
      "Epoch: 073, Loss: 0.1061 tsm_loss: 0.0000 reg_loss: 0.1061 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.9447 Test: 0.9447\n",
      "Epoch: 074, Loss: 0.1174 tsm_loss: 0.0000 reg_loss: 0.1174 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.7912 Test: 0.7912\n",
      "Epoch: 075, Loss: 0.1337 tsm_loss: 0.0000 reg_loss: 0.1337 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.8173 Test: 0.8173\n",
      "Epoch: 076, Loss: 0.1067 tsm_loss: 0.0000 reg_loss: 0.1067 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.8593 Test: 0.8593\n",
      "Epoch: 077, Loss: 0.1371 tsm_loss: 0.0000 reg_loss: 0.1371 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.6917 Test: 0.6917\n",
      "Epoch: 078, Loss: 0.1083 tsm_loss: 0.0000 reg_loss: 0.1083 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.5845 Test: 0.5845\n",
      "Epoch: 079, Loss: 0.1235 tsm_loss: 0.0000 reg_loss: 0.1235 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.6412 Test: 0.6412\n",
      "Epoch: 080, Loss: 0.1279 tsm_loss: 0.0000 reg_loss: 0.1279 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.5861 Test: 0.5861\n",
      "Epoch: 081, Loss: 0.0975 tsm_loss: 0.0000 reg_loss: 0.0975 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4724 Test: 0.4724\n",
      "Epoch: 082, Loss: 0.1331 tsm_loss: 0.0000 reg_loss: 0.1331 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4891 Test: 0.4891\n",
      "Epoch: 083, Loss: 0.1089 tsm_loss: 0.0000 reg_loss: 0.1089 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4451 Test: 0.4451\n",
      "Epoch: 084, Loss: 0.1099 tsm_loss: 0.0000 reg_loss: 0.1099 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4140 Test: 0.4140\n",
      "Epoch: 085, Loss: 0.1011 tsm_loss: 0.0000 reg_loss: 0.1011 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4619 Test: 0.4619\n",
      "Epoch: 086, Loss: 0.0980 tsm_loss: 0.0000 reg_loss: 0.0980 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4567 Test: 0.4567\n",
      "Epoch: 087, Loss: 0.0929 tsm_loss: 0.0000 reg_loss: 0.0929 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3858 Test: 0.3858\n",
      "Epoch: 088, Loss: 0.1033 tsm_loss: 0.0000 reg_loss: 0.1033 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4248 Test: 0.4248\n",
      "Epoch: 089, Loss: 0.1076 tsm_loss: 0.0000 reg_loss: 0.1076 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3492 Test: 0.3492\n",
      "Epoch: 090, Loss: 0.0922 tsm_loss: 0.0000 reg_loss: 0.0922 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3458 Test: 0.3458\n",
      "Epoch: 091, Loss: 0.1085 tsm_loss: 0.0000 reg_loss: 0.1085 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3760 Test: 0.3760\n",
      "Epoch: 092, Loss: 0.0814 tsm_loss: 0.0000 reg_loss: 0.0814 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4044 Test: 0.4044\n",
      "Epoch: 093, Loss: 0.0956 tsm_loss: 0.0000 reg_loss: 0.0956 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3671 Test: 0.3671\n",
      "Epoch: 094, Loss: 0.0920 tsm_loss: 0.0000 reg_loss: 0.0920 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3752 Test: 0.3752\n",
      "Epoch: 095, Loss: 0.1013 tsm_loss: 0.0000 reg_loss: 0.1013 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3363 Test: 0.3363\n",
      "Epoch: 096, Loss: 0.0873 tsm_loss: 0.0000 reg_loss: 0.0873 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3193 Test: 0.3193\n",
      "Epoch: 097, Loss: 0.0853 tsm_loss: 0.0000 reg_loss: 0.0853 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3649 Test: 0.3649\n",
      "Epoch: 098, Loss: 0.0863 tsm_loss: 0.0000 reg_loss: 0.0863 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3710 Test: 0.3710\n",
      "Epoch: 099, Loss: 0.0997 tsm_loss: 0.0000 reg_loss: 0.0997 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3334 Test: 0.3334\n",
      "Epoch: 100, Loss: 0.0823 tsm_loss: 0.0000 reg_loss: 0.0823 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3421 Test: 0.3421\n",
      "Epoch: 101, Loss: 0.1115 tsm_loss: 0.0000 reg_loss: 0.1115 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3275 Test: 0.3275\n",
      "Epoch: 102, Loss: 0.0851 tsm_loss: 0.0000 reg_loss: 0.0851 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3927 Test: 0.3927\n",
      "Epoch: 103, Loss: 0.1125 tsm_loss: 0.0000 reg_loss: 0.1125 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3969 Test: 0.3969\n",
      "Epoch: 104, Loss: 0.0995 tsm_loss: 0.0000 reg_loss: 0.0995 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3316 Test: 0.3316\n",
      "Epoch: 105, Loss: 0.0927 tsm_loss: 0.0000 reg_loss: 0.0927 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3226 Test: 0.3226\n",
      "Epoch: 106, Loss: 0.1054 tsm_loss: 0.0000 reg_loss: 0.1054 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3502 Test: 0.3502\n",
      "Epoch: 107, Loss: 0.0929 tsm_loss: 0.0000 reg_loss: 0.0929 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3201 Test: 0.3201\n",
      "Epoch: 108, Loss: 0.0805 tsm_loss: 0.0000 reg_loss: 0.0805 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3206 Test: 0.3206\n",
      "Epoch: 109, Loss: 0.0876 tsm_loss: 0.0000 reg_loss: 0.0876 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3764 Test: 0.3764\n",
      "Epoch: 110, Loss: 0.0848 tsm_loss: 0.0000 reg_loss: 0.0848 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3707 Test: 0.3707\n",
      "Epoch: 111, Loss: 0.0760 tsm_loss: 0.0000 reg_loss: 0.0760 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.2977 Test: 0.2977\n",
      "Epoch: 112, Loss: 0.0766 tsm_loss: 0.0000 reg_loss: 0.0766 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3093 Test: 0.3093\n",
      "Epoch: 113, Loss: 0.0768 tsm_loss: 0.0000 reg_loss: 0.0768 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3283 Test: 0.3283\n",
      "Epoch: 114, Loss: 0.0827 tsm_loss: 0.0000 reg_loss: 0.0827 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3218 Test: 0.3218\n",
      "Epoch: 115, Loss: 0.0697 tsm_loss: 0.0000 reg_loss: 0.0697 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3162 Test: 0.3162\n",
      "Epoch: 116, Loss: 0.0690 tsm_loss: 0.0000 reg_loss: 0.0690 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4007 Test: 0.4007\n",
      "Epoch: 117, Loss: 0.0886 tsm_loss: 0.0000 reg_loss: 0.0886 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3726 Test: 0.3726\n",
      "Epoch: 118, Loss: 0.0742 tsm_loss: 0.0000 reg_loss: 0.0742 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3210 Test: 0.3210\n",
      "Epoch: 119, Loss: 0.0835 tsm_loss: 0.0000 reg_loss: 0.0835 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3274 Test: 0.3274\n",
      "Epoch: 120, Loss: 0.0741 tsm_loss: 0.0000 reg_loss: 0.0741 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3781 Test: 0.3781\n",
      "Epoch: 121, Loss: 0.0813 tsm_loss: 0.0000 reg_loss: 0.0813 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3611 Test: 0.3611\n",
      "Epoch: 122, Loss: 0.0732 tsm_loss: 0.0000 reg_loss: 0.0732 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3016 Test: 0.3016\n",
      "Epoch: 123, Loss: 0.0779 tsm_loss: 0.0000 reg_loss: 0.0779 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3122 Test: 0.3122\n",
      "Epoch: 124, Loss: 0.0783 tsm_loss: 0.0000 reg_loss: 0.0783 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3767 Test: 0.3767\n",
      "Epoch: 125, Loss: 0.0659 tsm_loss: 0.0000 reg_loss: 0.0659 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3974 Test: 0.3974\n",
      "Epoch: 126, Loss: 0.0721 tsm_loss: 0.0000 reg_loss: 0.0721 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3357 Test: 0.3357\n",
      "Epoch: 127, Loss: 0.0755 tsm_loss: 0.0000 reg_loss: 0.0755 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3387 Test: 0.3387\n",
      "Epoch: 128, Loss: 0.0781 tsm_loss: 0.0000 reg_loss: 0.0781 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3630 Test: 0.3630\n",
      "Epoch: 129, Loss: 0.0981 tsm_loss: 0.0000 reg_loss: 0.0981 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3695 Test: 0.3695\n",
      "Epoch: 130, Loss: 0.0782 tsm_loss: 0.0000 reg_loss: 0.0782 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3367 Test: 0.3367\n",
      "Epoch: 131, Loss: 0.0836 tsm_loss: 0.0000 reg_loss: 0.0836 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3238 Test: 0.3238\n",
      "Epoch: 132, Loss: 0.0872 tsm_loss: 0.0000 reg_loss: 0.0872 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3659 Test: 0.3659\n",
      "Epoch: 133, Loss: 0.0828 tsm_loss: 0.0000 reg_loss: 0.0828 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3832 Test: 0.3832\n",
      "Epoch: 134, Loss: 0.0884 tsm_loss: 0.0000 reg_loss: 0.0884 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3981 Test: 0.3981\n",
      "Epoch: 135, Loss: 0.0759 tsm_loss: 0.0000 reg_loss: 0.0759 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3849 Test: 0.3849\n",
      "Epoch: 136, Loss: 0.0967 tsm_loss: 0.0000 reg_loss: 0.0967 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3285 Test: 0.3285\n",
      "Epoch: 137, Loss: 0.0853 tsm_loss: 0.0000 reg_loss: 0.0853 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3544 Test: 0.3544\n",
      "Epoch: 138, Loss: 0.0882 tsm_loss: 0.0000 reg_loss: 0.0882 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3833 Test: 0.3833\n",
      "Epoch: 139, Loss: 0.0712 tsm_loss: 0.0000 reg_loss: 0.0712 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3799 Test: 0.3799\n",
      "Epoch: 140, Loss: 0.0834 tsm_loss: 0.0000 reg_loss: 0.0834 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3427 Test: 0.3427\n",
      "Epoch: 141, Loss: 0.0787 tsm_loss: 0.0000 reg_loss: 0.0787 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3117 Test: 0.3117\n",
      "Epoch: 142, Loss: 0.0631 tsm_loss: 0.0000 reg_loss: 0.0631 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3109 Test: 0.3109\n",
      "Epoch: 143, Loss: 0.0790 tsm_loss: 0.0000 reg_loss: 0.0790 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3590 Test: 0.3590\n",
      "Epoch: 144, Loss: 0.0779 tsm_loss: 0.0000 reg_loss: 0.0779 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3749 Test: 0.3749\n",
      "Epoch: 145, Loss: 0.0649 tsm_loss: 0.0000 reg_loss: 0.0649 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3338 Test: 0.3338\n",
      "Epoch: 146, Loss: 0.0822 tsm_loss: 0.0000 reg_loss: 0.0822 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3485 Test: 0.3485\n",
      "Epoch: 147, Loss: 0.0797 tsm_loss: 0.0000 reg_loss: 0.0797 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3752 Test: 0.3752\n",
      "Epoch: 148, Loss: 0.0869 tsm_loss: 0.0000 reg_loss: 0.0869 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3743 Test: 0.3743\n",
      "Epoch: 149, Loss: 0.0837 tsm_loss: 0.0000 reg_loss: 0.0837 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3499 Test: 0.3499\n",
      "Epoch: 150, Loss: 0.0757 tsm_loss: 0.0000 reg_loss: 0.0757 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3328 Test: 0.3328\n",
      "Epoch: 151, Loss: 0.0868 tsm_loss: 0.0000 reg_loss: 0.0868 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3247 Test: 0.3247\n",
      "Epoch: 152, Loss: 0.0698 tsm_loss: 0.0000 reg_loss: 0.0698 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3568 Test: 0.3568\n",
      "Epoch: 153, Loss: 0.0865 tsm_loss: 0.0000 reg_loss: 0.0865 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3957 Test: 0.3957\n",
      "Epoch: 154, Loss: 0.0666 tsm_loss: 0.0000 reg_loss: 0.0666 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3572 Test: 0.3572\n",
      "Epoch: 155, Loss: 0.0756 tsm_loss: 0.0000 reg_loss: 0.0756 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3381 Test: 0.3381\n",
      "Epoch: 156, Loss: 0.0794 tsm_loss: 0.0000 reg_loss: 0.0794 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3892 Test: 0.3892\n",
      "Epoch: 157, Loss: 0.0832 tsm_loss: 0.0000 reg_loss: 0.0832 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3957 Test: 0.3957\n",
      "Epoch: 158, Loss: 0.0707 tsm_loss: 0.0000 reg_loss: 0.0707 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3779 Test: 0.3779\n",
      "Epoch: 159, Loss: 0.0754 tsm_loss: 0.0000 reg_loss: 0.0754 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3857 Test: 0.3857\n",
      "Epoch: 160, Loss: 0.0805 tsm_loss: 0.0000 reg_loss: 0.0805 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3494 Test: 0.3494\n",
      "Epoch: 161, Loss: 0.0705 tsm_loss: 0.0000 reg_loss: 0.0705 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3451 Test: 0.3451\n",
      "Epoch: 162, Loss: 0.0724 tsm_loss: 0.0000 reg_loss: 0.0724 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4104 Test: 0.4104\n",
      "Epoch: 163, Loss: 0.0572 tsm_loss: 0.0000 reg_loss: 0.0572 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4750 Test: 0.4750\n",
      "Epoch: 164, Loss: 0.0848 tsm_loss: 0.0000 reg_loss: 0.0848 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3943 Test: 0.3943\n",
      "Epoch: 165, Loss: 0.0597 tsm_loss: 0.0000 reg_loss: 0.0597 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3790 Test: 0.3790\n",
      "Epoch: 166, Loss: 0.0588 tsm_loss: 0.0000 reg_loss: 0.0588 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4320 Test: 0.4320\n",
      "Epoch: 167, Loss: 0.0579 tsm_loss: 0.0000 reg_loss: 0.0579 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4002 Test: 0.4002\n",
      "Epoch: 168, Loss: 0.0611 tsm_loss: 0.0000 reg_loss: 0.0611 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3568 Test: 0.3568\n",
      "Epoch: 169, Loss: 0.0584 tsm_loss: 0.0000 reg_loss: 0.0584 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3868 Test: 0.3868\n",
      "Epoch: 170, Loss: 0.0624 tsm_loss: 0.0000 reg_loss: 0.0624 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4174 Test: 0.4174\n",
      "Epoch: 171, Loss: 0.0502 tsm_loss: 0.0000 reg_loss: 0.0502 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4436 Test: 0.4436\n",
      "Epoch: 172, Loss: 0.0582 tsm_loss: 0.0000 reg_loss: 0.0582 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4647 Test: 0.4647\n",
      "Epoch: 173, Loss: 0.0603 tsm_loss: 0.0000 reg_loss: 0.0603 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4098 Test: 0.4098\n",
      "Epoch: 174, Loss: 0.0469 tsm_loss: 0.0000 reg_loss: 0.0469 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3926 Test: 0.3926\n",
      "Epoch: 175, Loss: 0.0494 tsm_loss: 0.0000 reg_loss: 0.0494 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4201 Test: 0.4201\n",
      "Epoch: 176, Loss: 0.0579 tsm_loss: 0.0000 reg_loss: 0.0579 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3655 Test: 0.3655\n",
      "Epoch: 177, Loss: 0.0497 tsm_loss: 0.0000 reg_loss: 0.0497 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3455 Test: 0.3455\n",
      "Epoch: 178, Loss: 0.0465 tsm_loss: 0.0000 reg_loss: 0.0465 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3539 Test: 0.3539\n",
      "Epoch: 179, Loss: 0.0610 tsm_loss: 0.0000 reg_loss: 0.0610 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3669 Test: 0.3669\n",
      "Epoch: 180, Loss: 0.0501 tsm_loss: 0.0000 reg_loss: 0.0501 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3489 Test: 0.3489\n",
      "Epoch: 181, Loss: 0.0445 tsm_loss: 0.0000 reg_loss: 0.0445 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3432 Test: 0.3432\n",
      "Epoch: 182, Loss: 0.0558 tsm_loss: 0.0000 reg_loss: 0.0558 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3817 Test: 0.3817\n",
      "Epoch: 183, Loss: 0.0485 tsm_loss: 0.0000 reg_loss: 0.0485 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3653 Test: 0.3653\n",
      "Epoch: 184, Loss: 0.0464 tsm_loss: 0.0000 reg_loss: 0.0464 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3509 Test: 0.3509\n",
      "Epoch: 185, Loss: 0.0567 tsm_loss: 0.0000 reg_loss: 0.0567 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3768 Test: 0.3768\n",
      "Epoch: 186, Loss: 0.0519 tsm_loss: 0.0000 reg_loss: 0.0519 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3638 Test: 0.3638\n",
      "Epoch: 187, Loss: 0.0502 tsm_loss: 0.0000 reg_loss: 0.0502 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3720 Test: 0.3720\n",
      "Epoch: 188, Loss: 0.0478 tsm_loss: 0.0000 reg_loss: 0.0478 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3641 Test: 0.3641\n",
      "Epoch: 189, Loss: 0.0431 tsm_loss: 0.0000 reg_loss: 0.0431 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3629 Test: 0.3629\n",
      "Epoch: 190, Loss: 0.0412 tsm_loss: 0.0000 reg_loss: 0.0412 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3833 Test: 0.3833\n",
      "Epoch: 191, Loss: 0.0412 tsm_loss: 0.0000 reg_loss: 0.0412 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3460 Test: 0.3460\n",
      "Epoch: 192, Loss: 0.0582 tsm_loss: 0.0000 reg_loss: 0.0582 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3922 Test: 0.3922\n",
      "Epoch: 193, Loss: 0.0438 tsm_loss: 0.0000 reg_loss: 0.0438 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3961 Test: 0.3961\n",
      "Epoch: 194, Loss: 0.0701 tsm_loss: 0.0000 reg_loss: 0.0701 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3995 Test: 0.3995\n",
      "Epoch: 195, Loss: 0.0465 tsm_loss: 0.0000 reg_loss: 0.0465 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4028 Test: 0.4028\n",
      "Epoch: 196, Loss: 0.0660 tsm_loss: 0.0000 reg_loss: 0.0660 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3833 Test: 0.3833\n",
      "Epoch: 197, Loss: 0.0610 tsm_loss: 0.0000 reg_loss: 0.0610 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4075 Test: 0.4075\n",
      "Epoch: 198, Loss: 0.0670 tsm_loss: 0.0000 reg_loss: 0.0670 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4467 Test: 0.4467\n",
      "Epoch: 199, Loss: 0.0739 tsm_loss: 0.0000 reg_loss: 0.0739 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4318 Test: 0.4318\n",
      "Epoch: 200, Loss: 0.0768 tsm_loss: 0.0000 reg_loss: 0.0768 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3738 Test: 0.3738\n",
      "Epoch: 201, Loss: 0.0857 tsm_loss: 0.0000 reg_loss: 0.0857 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3874 Test: 0.3874\n",
      "Epoch: 202, Loss: 0.0707 tsm_loss: 0.0000 reg_loss: 0.0707 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4522 Test: 0.4522\n",
      "Epoch: 203, Loss: 0.0731 tsm_loss: 0.0000 reg_loss: 0.0731 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4354 Test: 0.4354\n",
      "Epoch: 204, Loss: 0.0780 tsm_loss: 0.0000 reg_loss: 0.0780 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3760 Test: 0.3760\n",
      "Epoch: 205, Loss: 0.0579 tsm_loss: 0.0000 reg_loss: 0.0579 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3714 Test: 0.3714\n",
      "Epoch: 206, Loss: 0.0561 tsm_loss: 0.0000 reg_loss: 0.0561 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4023 Test: 0.4023\n",
      "Epoch: 207, Loss: 0.0624 tsm_loss: 0.0000 reg_loss: 0.0624 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4023 Test: 0.4023\n",
      "Epoch: 208, Loss: 0.0490 tsm_loss: 0.0000 reg_loss: 0.0490 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3824 Test: 0.3824\n",
      "Epoch: 209, Loss: 0.0452 tsm_loss: 0.0000 reg_loss: 0.0452 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3785 Test: 0.3785\n",
      "Epoch: 210, Loss: 0.0494 tsm_loss: 0.0000 reg_loss: 0.0494 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4039 Test: 0.4039\n",
      "Epoch: 211, Loss: 0.0371 tsm_loss: 0.0000 reg_loss: 0.0371 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4150 Test: 0.4150\n",
      "Epoch: 212, Loss: 0.0439 tsm_loss: 0.0000 reg_loss: 0.0439 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3767 Test: 0.3767\n",
      "Epoch: 213, Loss: 0.0368 tsm_loss: 0.0000 reg_loss: 0.0368 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3611 Test: 0.3611\n",
      "Epoch: 214, Loss: 0.0371 tsm_loss: 0.0000 reg_loss: 0.0371 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3694 Test: 0.3694\n",
      "Epoch: 215, Loss: 0.0393 tsm_loss: 0.0000 reg_loss: 0.0393 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3804 Test: 0.3804\n",
      "Epoch: 216, Loss: 0.0466 tsm_loss: 0.0000 reg_loss: 0.0466 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3652 Test: 0.3652\n",
      "Epoch: 217, Loss: 0.0447 tsm_loss: 0.0000 reg_loss: 0.0447 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3678 Test: 0.3678\n",
      "Epoch: 218, Loss: 0.0516 tsm_loss: 0.0000 reg_loss: 0.0516 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3592 Test: 0.3592\n",
      "Epoch: 219, Loss: 0.0380 tsm_loss: 0.0000 reg_loss: 0.0380 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3640 Test: 0.3640\n",
      "Epoch: 220, Loss: 0.0381 tsm_loss: 0.0000 reg_loss: 0.0381 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3553 Test: 0.3553\n",
      "Epoch: 221, Loss: 0.0355 tsm_loss: 0.0000 reg_loss: 0.0355 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3663 Test: 0.3663\n",
      "Epoch: 222, Loss: 0.0453 tsm_loss: 0.0000 reg_loss: 0.0453 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3563 Test: 0.3563\n",
      "Epoch: 223, Loss: 0.0525 tsm_loss: 0.0000 reg_loss: 0.0525 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3627 Test: 0.3627\n",
      "Epoch: 224, Loss: 0.0427 tsm_loss: 0.0000 reg_loss: 0.0427 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3682 Test: 0.3682\n",
      "Epoch: 225, Loss: 0.0381 tsm_loss: 0.0000 reg_loss: 0.0381 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3570 Test: 0.3570\n",
      "Epoch: 226, Loss: 0.0562 tsm_loss: 0.0000 reg_loss: 0.0562 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3455 Test: 0.3455\n",
      "Epoch: 227, Loss: 0.0458 tsm_loss: 0.0000 reg_loss: 0.0458 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3504 Test: 0.3504\n",
      "Epoch: 228, Loss: 0.0408 tsm_loss: 0.0000 reg_loss: 0.0408 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3695 Test: 0.3695\n",
      "Epoch: 229, Loss: 0.0546 tsm_loss: 0.0000 reg_loss: 0.0546 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3578 Test: 0.3578\n",
      "Epoch: 230, Loss: 0.0370 tsm_loss: 0.0000 reg_loss: 0.0370 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3399 Test: 0.3399\n",
      "Epoch: 231, Loss: 0.0430 tsm_loss: 0.0000 reg_loss: 0.0430 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3562 Test: 0.3562\n",
      "Epoch: 232, Loss: 0.0471 tsm_loss: 0.0000 reg_loss: 0.0471 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4110 Test: 0.4110\n",
      "Epoch: 233, Loss: 0.0554 tsm_loss: 0.0000 reg_loss: 0.0554 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3949 Test: 0.3949\n",
      "Epoch: 234, Loss: 0.0450 tsm_loss: 0.0000 reg_loss: 0.0450 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3450 Test: 0.3450\n",
      "Epoch: 235, Loss: 0.0646 tsm_loss: 0.0000 reg_loss: 0.0646 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3489 Test: 0.3489\n",
      "Epoch: 236, Loss: 0.0403 tsm_loss: 0.0000 reg_loss: 0.0403 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4106 Test: 0.4106\n",
      "Epoch: 237, Loss: 0.0623 tsm_loss: 0.0000 reg_loss: 0.0623 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3996 Test: 0.3996\n",
      "Epoch: 238, Loss: 0.0441 tsm_loss: 0.0000 reg_loss: 0.0441 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3452 Test: 0.3452\n",
      "Epoch: 239, Loss: 0.0689 tsm_loss: 0.0000 reg_loss: 0.0689 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3707 Test: 0.3707\n",
      "Epoch: 240, Loss: 0.0694 tsm_loss: 0.0000 reg_loss: 0.0694 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4785 Test: 0.4785\n",
      "Epoch: 241, Loss: 0.0686 tsm_loss: 0.0000 reg_loss: 0.0686 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4947 Test: 0.4947\n",
      "Epoch: 242, Loss: 0.0683 tsm_loss: 0.0000 reg_loss: 0.0683 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4659 Test: 0.4659\n",
      "Epoch: 243, Loss: 0.0446 tsm_loss: 0.0000 reg_loss: 0.0446 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4475 Test: 0.4475\n",
      "Epoch: 244, Loss: 0.0685 tsm_loss: 0.0000 reg_loss: 0.0685 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4664 Test: 0.4664\n",
      "Epoch: 245, Loss: 0.0560 tsm_loss: 0.0000 reg_loss: 0.0560 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.5185 Test: 0.5185\n",
      "Epoch: 246, Loss: 0.0591 tsm_loss: 0.0000 reg_loss: 0.0591 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4994 Test: 0.4994\n",
      "Epoch: 247, Loss: 0.0540 tsm_loss: 0.0000 reg_loss: 0.0540 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3881 Test: 0.3881\n",
      "Epoch: 248, Loss: 0.0552 tsm_loss: 0.0000 reg_loss: 0.0552 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3802 Test: 0.3802\n",
      "Epoch: 249, Loss: 0.0506 tsm_loss: 0.0000 reg_loss: 0.0506 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4559 Test: 0.4559\n",
      "Epoch: 250, Loss: 0.0422 tsm_loss: 0.0000 reg_loss: 0.0422 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4585 Test: 0.4585\n",
      "Epoch: 251, Loss: 0.0506 tsm_loss: 0.0000 reg_loss: 0.0506 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3910 Test: 0.3910\n",
      "Epoch: 252, Loss: 0.0380 tsm_loss: 0.0000 reg_loss: 0.0380 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3703 Test: 0.3703\n",
      "Epoch: 253, Loss: 0.0454 tsm_loss: 0.0000 reg_loss: 0.0454 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4039 Test: 0.4039\n",
      "Epoch: 254, Loss: 0.0374 tsm_loss: 0.0000 reg_loss: 0.0374 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4012 Test: 0.4012\n",
      "Epoch: 255, Loss: 0.0399 tsm_loss: 0.0000 reg_loss: 0.0399 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3733 Test: 0.3733\n",
      "Epoch: 256, Loss: 0.0421 tsm_loss: 0.0000 reg_loss: 0.0421 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3826 Test: 0.3826\n",
      "Epoch: 257, Loss: 0.0459 tsm_loss: 0.0000 reg_loss: 0.0459 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3729 Test: 0.3729\n",
      "Epoch: 258, Loss: 0.0358 tsm_loss: 0.0000 reg_loss: 0.0358 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3795 Test: 0.3795\n",
      "Epoch: 259, Loss: 0.0393 tsm_loss: 0.0000 reg_loss: 0.0393 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3804 Test: 0.3804\n",
      "Epoch: 260, Loss: 0.0349 tsm_loss: 0.0000 reg_loss: 0.0349 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3823 Test: 0.3823\n",
      "Epoch: 261, Loss: 0.0342 tsm_loss: 0.0000 reg_loss: 0.0342 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3823 Test: 0.3823\n",
      "Epoch: 262, Loss: 0.0417 tsm_loss: 0.0000 reg_loss: 0.0417 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3651 Test: 0.3651\n",
      "Epoch: 263, Loss: 0.0366 tsm_loss: 0.0000 reg_loss: 0.0366 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3892 Test: 0.3892\n",
      "Epoch: 264, Loss: 0.0447 tsm_loss: 0.0000 reg_loss: 0.0447 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3691 Test: 0.3691\n",
      "Epoch: 265, Loss: 0.0555 tsm_loss: 0.0000 reg_loss: 0.0555 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3951 Test: 0.3951\n",
      "Epoch: 266, Loss: 0.0318 tsm_loss: 0.0000 reg_loss: 0.0318 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4055 Test: 0.4055\n",
      "Epoch: 267, Loss: 0.0496 tsm_loss: 0.0000 reg_loss: 0.0496 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3832 Test: 0.3832\n",
      "Epoch: 268, Loss: 0.0385 tsm_loss: 0.0000 reg_loss: 0.0385 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3720 Test: 0.3720\n",
      "Epoch: 269, Loss: 0.0355 tsm_loss: 0.0000 reg_loss: 0.0355 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3801 Test: 0.3801\n",
      "Epoch: 270, Loss: 0.0386 tsm_loss: 0.0000 reg_loss: 0.0386 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4488 Test: 0.4488\n",
      "Epoch: 271, Loss: 0.0518 tsm_loss: 0.0000 reg_loss: 0.0518 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4450 Test: 0.4450\n",
      "Epoch: 272, Loss: 0.0472 tsm_loss: 0.0000 reg_loss: 0.0472 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4026 Test: 0.4026\n",
      "Epoch: 273, Loss: 0.0410 tsm_loss: 0.0000 reg_loss: 0.0410 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3548 Test: 0.3548\n",
      "Epoch: 274, Loss: 0.0332 tsm_loss: 0.0000 reg_loss: 0.0332 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3711 Test: 0.3711\n",
      "Epoch: 275, Loss: 0.0439 tsm_loss: 0.0000 reg_loss: 0.0439 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3703 Test: 0.3703\n",
      "Epoch: 276, Loss: 0.0393 tsm_loss: 0.0000 reg_loss: 0.0393 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3662 Test: 0.3662\n",
      "Epoch: 277, Loss: 0.0377 tsm_loss: 0.0000 reg_loss: 0.0377 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3559 Test: 0.3559\n",
      "Epoch: 278, Loss: 0.0598 tsm_loss: 0.0000 reg_loss: 0.0598 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3701 Test: 0.3701\n",
      "Epoch: 279, Loss: 0.0407 tsm_loss: 0.0000 reg_loss: 0.0407 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3960 Test: 0.3960\n",
      "Epoch: 280, Loss: 0.0461 tsm_loss: 0.0000 reg_loss: 0.0461 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4072 Test: 0.4072\n",
      "Epoch: 281, Loss: 0.0698 tsm_loss: 0.0000 reg_loss: 0.0698 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3986 Test: 0.3986\n",
      "Epoch: 282, Loss: 0.0456 tsm_loss: 0.0000 reg_loss: 0.0456 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3644 Test: 0.3644\n",
      "Epoch: 283, Loss: 0.0750 tsm_loss: 0.0000 reg_loss: 0.0750 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3594 Test: 0.3594\n",
      "Epoch: 284, Loss: 0.0524 tsm_loss: 0.0000 reg_loss: 0.0524 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4311 Test: 0.4311\n",
      "Epoch: 285, Loss: 0.0865 tsm_loss: 0.0000 reg_loss: 0.0865 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4452 Test: 0.4452\n",
      "Epoch: 286, Loss: 0.0609 tsm_loss: 0.0000 reg_loss: 0.0609 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.4020 Test: 0.4020\n",
      "Epoch: 287, Loss: 0.0768 tsm_loss: 0.0000 reg_loss: 0.0768 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3856 Test: 0.3856\n",
      "Epoch: 288, Loss: 0.0555 tsm_loss: 0.0000 reg_loss: 0.0555 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3860 Test: 0.3860\n",
      "Epoch: 289, Loss: 0.0872 tsm_loss: 0.0000 reg_loss: 0.0872 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3866 Test: 0.3866\n",
      "Epoch: 290, Loss: 0.0695 tsm_loss: 0.0000 reg_loss: 0.0695 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3712 Test: 0.3712\n",
      "Epoch: 291, Loss: 0.0784 tsm_loss: 0.0000 reg_loss: 0.0784 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3727 Test: 0.3727\n",
      "Epoch: 292, Loss: 0.0731 tsm_loss: 0.0000 reg_loss: 0.0731 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3935 Test: 0.3935\n",
      "Epoch: 293, Loss: 0.0704 tsm_loss: 0.0000 reg_loss: 0.0704 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3807 Test: 0.3807\n",
      "Epoch: 294, Loss: 0.0784 tsm_loss: 0.0000 reg_loss: 0.0784 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3771 Test: 0.3771\n",
      "Epoch: 295, Loss: 0.0452 tsm_loss: 0.0000 reg_loss: 0.0452 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3940 Test: 0.3940\n",
      "Epoch: 296, Loss: 0.0560 tsm_loss: 0.0000 reg_loss: 0.0560 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3787 Test: 0.3787\n",
      "Epoch: 297, Loss: 0.0551 tsm_loss: 0.0000 reg_loss: 0.0551 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3698 Test: 0.3698\n",
      "Epoch: 298, Loss: 0.0472 tsm_loss: 0.0000 reg_loss: 0.0472 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3922 Test: 0.3922\n",
      "Epoch: 299, Loss: 0.0737 tsm_loss: 0.0000 reg_loss: 0.0737 N_Y: 125430 N_S: 000 N: 000 N_HV: 000 Val: 0.3635 Test: 0.3635\n",
      "Epoch: 001, Loss: 6.7996 tsm_loss: 0.0000 reg_loss: 6.7996 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7409 Test: 6.7409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/shenwanxiang/anaconda3/envs/clsar/lib/python3.8/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 6.5556 tsm_loss: 0.0000 reg_loss: 6.5556 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7400 Test: 6.7400\n",
      "Epoch: 003, Loss: 6.3399 tsm_loss: 0.0000 reg_loss: 6.3399 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7393 Test: 6.7393\n",
      "Epoch: 004, Loss: 6.1508 tsm_loss: 0.0000 reg_loss: 6.1508 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7389 Test: 6.7389\n",
      "Epoch: 005, Loss: 5.9820 tsm_loss: 0.0000 reg_loss: 5.9820 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7388 Test: 6.7388\n",
      "Epoch: 006, Loss: 5.8207 tsm_loss: 0.0000 reg_loss: 5.8207 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7387 Test: 6.7387\n",
      "Epoch: 007, Loss: 5.6692 tsm_loss: 0.0000 reg_loss: 5.6692 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7388 Test: 6.7388\n",
      "Epoch: 008, Loss: 5.5140 tsm_loss: 0.0000 reg_loss: 5.5140 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7389 Test: 6.7389\n",
      "Epoch: 009, Loss: 5.3588 tsm_loss: 0.0000 reg_loss: 5.3588 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7388 Test: 6.7388\n",
      "Epoch: 010, Loss: 5.2018 tsm_loss: 0.0000 reg_loss: 5.2018 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7386 Test: 6.7386\n",
      "Epoch: 011, Loss: 5.0368 tsm_loss: 0.0000 reg_loss: 5.0368 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7384 Test: 6.7384\n",
      "Epoch: 012, Loss: 4.8663 tsm_loss: 0.0000 reg_loss: 4.8663 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7381 Test: 6.7381\n",
      "Epoch: 013, Loss: 4.6888 tsm_loss: 0.0000 reg_loss: 4.6888 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7376 Test: 6.7376\n",
      "Epoch: 014, Loss: 4.5033 tsm_loss: 0.0000 reg_loss: 4.5033 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7372 Test: 6.7372\n",
      "Epoch: 015, Loss: 4.3220 tsm_loss: 0.0000 reg_loss: 4.3220 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7368 Test: 6.7368\n",
      "Epoch: 016, Loss: 4.1298 tsm_loss: 0.0000 reg_loss: 4.1298 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7364 Test: 6.7364\n",
      "Epoch: 017, Loss: 3.9233 tsm_loss: 0.0000 reg_loss: 3.9233 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7360 Test: 6.7360\n",
      "Epoch: 018, Loss: 3.7062 tsm_loss: 0.0000 reg_loss: 3.7062 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7357 Test: 6.7357\n",
      "Epoch: 019, Loss: 3.4777 tsm_loss: 0.0000 reg_loss: 3.4777 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7351 Test: 6.7351\n",
      "Epoch: 020, Loss: 3.2294 tsm_loss: 0.0000 reg_loss: 3.2294 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7345 Test: 6.7345\n",
      "Epoch: 021, Loss: 2.9669 tsm_loss: 0.0000 reg_loss: 2.9669 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7338 Test: 6.7338\n",
      "Epoch: 022, Loss: 2.6862 tsm_loss: 0.0000 reg_loss: 2.6862 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7332 Test: 6.7332\n",
      "Epoch: 023, Loss: 2.3900 tsm_loss: 0.0000 reg_loss: 2.3900 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7322 Test: 6.7322\n",
      "Epoch: 024, Loss: 2.0687 tsm_loss: 0.0000 reg_loss: 2.0687 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7309 Test: 6.7309\n",
      "Epoch: 025, Loss: 1.7288 tsm_loss: 0.0000 reg_loss: 1.7288 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7289 Test: 6.7289\n",
      "Epoch: 026, Loss: 1.3635 tsm_loss: 0.0000 reg_loss: 1.3635 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7261 Test: 6.7261\n",
      "Epoch: 027, Loss: 1.0183 tsm_loss: 0.0000 reg_loss: 1.0183 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7230 Test: 6.7230\n",
      "Epoch: 028, Loss: 0.7613 tsm_loss: 0.0000 reg_loss: 0.7613 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7184 Test: 6.7184\n",
      "Epoch: 029, Loss: 0.6707 tsm_loss: 0.0000 reg_loss: 0.6707 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.7067 Test: 6.7067\n",
      "Epoch: 030, Loss: 0.5530 tsm_loss: 0.0000 reg_loss: 0.5530 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.6841 Test: 6.6841\n",
      "Epoch: 031, Loss: 0.5231 tsm_loss: 0.0000 reg_loss: 0.5231 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.6477 Test: 6.6477\n",
      "Epoch: 032, Loss: 0.4499 tsm_loss: 0.0000 reg_loss: 0.4499 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.5954 Test: 6.5954\n",
      "Epoch: 033, Loss: 0.3797 tsm_loss: 0.0000 reg_loss: 0.3797 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.5218 Test: 6.5218\n",
      "Epoch: 034, Loss: 0.3006 tsm_loss: 0.0000 reg_loss: 0.3006 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.4192 Test: 6.4192\n",
      "Epoch: 035, Loss: 0.2734 tsm_loss: 0.0000 reg_loss: 0.2734 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.3062 Test: 6.3062\n",
      "Epoch: 036, Loss: 0.2481 tsm_loss: 0.0000 reg_loss: 0.2481 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.1958 Test: 6.1958\n",
      "Epoch: 037, Loss: 0.2309 tsm_loss: 0.0000 reg_loss: 0.2309 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 6.0615 Test: 6.0615\n",
      "Epoch: 038, Loss: 0.2357 tsm_loss: 0.0000 reg_loss: 0.2357 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.8906 Test: 5.8906\n",
      "Epoch: 039, Loss: 0.2112 tsm_loss: 0.0000 reg_loss: 0.2112 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.7210 Test: 5.7210\n",
      "Epoch: 040, Loss: 0.2002 tsm_loss: 0.0000 reg_loss: 0.2002 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.5705 Test: 5.5705\n",
      "Epoch: 041, Loss: 0.1857 tsm_loss: 0.0000 reg_loss: 0.1857 N_Y: 118792 N_S: 000 N: 000 N_HV: 000 Val: 5.4132 Test: 5.4132\n"
     ]
    }
   ],
   "source": [
    "# train, valid, test splitting\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "res = []\n",
    "for seed in [8, 16, 24, 42, 64,]: #,   128, 256, 512, 1024, 2048\n",
    "    dataset = Dataset(path, name=dataset_name, pre_transform=pre_transform).shuffle(42)\n",
    "\n",
    "    for similarity_neg in [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "         for similarity_pos in [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "            for fold, (train_idx, test_idx) in enumerate(kf.split(dataset)):\n",
    "                train_ds = dataset[train_idx.tolist()]\n",
    "                test_ds  = dataset[test_idx.tolist()]\n",
    "                \n",
    "                train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "                test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "                val_loader = test_loader\n",
    "            \n",
    "                deg = get_deg(train_ds)\n",
    "                device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "                df1 = Test_performance(alpha=1.0, similarity_gate = True, gate_type = 'AND',\n",
    "                                       similarity_neg =similarity_neg, similarity_pos=similarity_pos)\n",
    "                df1['seed'] = seed\n",
    "                df1['fold'] = fold\n",
    "                res.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c58580-3e75-4e17-a09b-5a9cd24618d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(res)\n",
    "df.groupby(['similarity_neg', 'similarity_pos', 'seed', 'fold']).test_rmse.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f99d19-0b7a-4cb9-9f1a-02fa309afdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./results/similarity_grid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4f511-db6b-4395-b2bd-2e993b9167f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16898f-b4bb-46ae-8d18-229ad9ab42b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d62189-e6b5-4d5c-8e51-bafc0c9fe2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0887761-ae13-424c-959a-07653e2eafc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
