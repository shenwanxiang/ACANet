{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c11c7-9644-4634-b0bf-234b5ea3bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "import random\n",
    "\n",
    "# import clsar package\n",
    "import sys, os\n",
    "sys.path.insert(0, '/home/was966/Research/bidd-clsar/')\n",
    "\n",
    "from clsar.model.loss import ACALoss, get_best_cliff\n",
    "from clsar.model.model import ACANet_PNA, get_deg, _fix_reproducibility  # model\n",
    "\n",
    "from clsar.model.saver import SaveBestModel\n",
    "from clsar.feature import Gen39AtomFeatures  # feature\n",
    "from clsar.dataset import LSSNS  # dataset\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = 'white', font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdeb5e9-5760-4472-b76f-a2021845f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpuid = 1\n",
    "# torch.cuda.set_device(gpuid)\n",
    "# print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d7863-6d13-4a46-803e-dc5f79fc6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92591581-963d-446c-a063-d445cdc61b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, device, optimizer, model, aca_loss):\n",
    "    total_examples = 0\n",
    "    total_loss = 0\n",
    "    total_tsm_loss = 0\n",
    "    total_reg_loss = 0\n",
    "    n_triplets = []\n",
    "    n_pos_triplets = []\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions, embeddings = model(data.x.float(), data.edge_index,\n",
    "                                        data.edge_attr, data.batch)\n",
    "\n",
    "        loss_out = aca_loss(labels=data.y,\n",
    "                            predictions=predictions,\n",
    "                            embeddings=embeddings)\n",
    "\n",
    "        loss, reg_loss, tsm_loss, n, n_pos = loss_out\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_tsm_loss += float(tsm_loss) * data.num_graphs\n",
    "        total_reg_loss += float(reg_loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "        n_triplets.append(int(n))\n",
    "        n_pos_triplets.append(int(n_pos))\n",
    "\n",
    "    train_loss = total_loss / total_examples\n",
    "    total_tsm_loss = total_tsm_loss / total_examples\n",
    "    total_reg_loss = total_reg_loss / total_examples\n",
    "    n_triplets = int(sum(n_triplets) / (i+1))\n",
    "    n_pos_triplets = int(sum(n_pos_triplets) / (i+1))\n",
    "\n",
    "    return train_loss, total_tsm_loss, total_reg_loss, n_triplets, n_pos_triplets\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(test_loader, device, model, aca_loss):\n",
    "    total_examples = 0\n",
    "    total_loss = 0\n",
    "    total_tsm_loss = 0\n",
    "    total_reg_loss = 0\n",
    "    n_triplets = []\n",
    "    n_pos_triplets = []\n",
    "    mse = []\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        E = model.eval()\n",
    "        predictions, embeddings = E(data.x.float(), data.edge_index,\n",
    "                                        data.edge_attr, data.batch)\n",
    "        loss_out = aca_loss(labels=data.y,\n",
    "                            predictions=predictions,\n",
    "                            embeddings=embeddings)\n",
    "\n",
    "        loss, reg_loss, tsm_loss, n, n_pos = loss_out\n",
    "\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_tsm_loss += float(tsm_loss) * data.num_graphs\n",
    "        total_reg_loss += float(reg_loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "        n_triplets.append(int(n))\n",
    "        n_pos_triplets.append(int(n_pos))\n",
    "\n",
    "        mse.append(F.mse_loss(predictions, data.y, reduction='none').cpu())\n",
    "\n",
    "    test_loss = total_loss / total_examples\n",
    "    total_tsm_loss = total_tsm_loss / total_examples\n",
    "    total_reg_loss = total_reg_loss / total_examples\n",
    "    n_triplets = int(sum(n_triplets) / (i+1))\n",
    "    n_pos_triplets = int(sum(n_pos_triplets) / (i+1))\n",
    "    \n",
    "    test_rmse = float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "    \n",
    "    return test_loss, total_tsm_loss, total_reg_loss, n_triplets, n_pos_triplets, test_rmse\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def _predict(smiles_list, transformer, model):\n",
    "    #test_loader, device, model):\n",
    "    data_list = transformer(smiles_list)\n",
    "    data_loader = DataLoader(data_list, batch_size=64, shuffle=False)\n",
    "    embeds = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    for data in data_loader:\n",
    "        data = data.to(device)\n",
    "        predictions, embeddings = model(data.x.float(), data.edge_index,\n",
    "                                        data.edge_attr, data.batch)\n",
    "        embeds.append(embeddings)\n",
    "        preds.append(predictions)\n",
    "        \n",
    "    embeddings = torch.concat(embeds, axis=0).cpu().numpy()\n",
    "    predictions = torch.concat(preds, axis=0).cpu().numpy()   \n",
    "    return embeddings, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7a7e4-06b7-4516-afa4-37a217361bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'braf'\n",
    "flag = 'no_aca'\n",
    "result_save_dir = './results/%s_%s/' % (dataset_name, flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415548b-639a-4287-ab77-6e756e620823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29161877-2881-4bb5-bee2-a39009b6293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_name = 'model_%s.pth' % dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e84de2-7f92-4407-b8fe-430df63be64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea08529-ae88-4297-8d9c-bf5582dda3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cpu\")\n",
    "mfile = os.path.join(result_save_dir, model_save_name)\n",
    "checkpoint = torch.load(mfile, map_location=torch.device('cpu'))\n",
    "model = ACANet_PNA(**checkpoint['model_args']).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "transformer = checkpoint['data_transformer']\n",
    "dfm = pd.read_csv('./results/chemical_space.csv', index_col='smiles')\n",
    "smiles_list = dfm.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19880b-effb-4828-8694-8e5e22b02c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 30\n",
    "\n",
    "embeddings, predictions = _predict(smiles_list, transformer, model)\n",
    "embeddings = pd.DataFrame(embeddings, index = smiles_list)\n",
    "embeddings.to_csv('./results/embeddings_no_aca.csv')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "u = UMAP(random_state = 42, n_neighbors=50, min_dist=0.8, spread=spread)\n",
    "#u = PCA(n_components=2)\n",
    "\n",
    "xy = u.fit_transform(embeddings)\n",
    "dfs = pd.DataFrame(xy,columns= ['dim1','dim2'], index=smiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd1fe4-083d-4a88-9071-9c5360356aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['chemblid'] = dfs.index.map(dfm['Molecule ChEMBL ID'])\n",
    "dfs['pred'] = predictions\n",
    "dfs['true'] = dfs.index.map(dfm['pChEMBL'])\n",
    "\n",
    "dfs['node_color'] = dfs.index.map(dfm['node_color'])\n",
    "dfs['edgecolor'] = dfs.index.map(dfm['edgecolor'])\n",
    "dfs['node_size'] = dfs.index.map(dfm['node_size'])\n",
    "dfs['label'] = dfs.index.map(dfm['label'])\n",
    "\n",
    "dfs1 = dfs[dfs.label == 'data']\n",
    "dfs2 = dfs[dfs.label != 'data']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.scatter(dfs1.dim1, dfs1.dim2, c = 'k', alpha = 0.4, s = dfs1.node_size, edgecolors = dfs1.edgecolor)\n",
    "ax.scatter(dfs2.dim1, dfs2.dim2, c = dfs2.node_color, s = 500, edgecolors = dfs2.edgecolor)\n",
    "for i in range(len(dfs2)):\n",
    "    ts = dfs2.iloc[i]\n",
    "    ax.text(ts.dim1, ts.dim2, ts.label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46257d3-080b-49d7-908d-7ecf77a25422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfm = pd.read_csv('./results/chemical_space.csv', index_col='smiles')\n",
    "\n",
    "a, p, n = \"CHEMBL3661243\", \"CHEMBL3661245\", \"CHEMBL1357167\" \n",
    "dfs['chemblid'] = dfs.index.map(dfm['Molecule ChEMBL ID'])\n",
    "dfs['pred'] = predictions\n",
    "dfs['true'] = dfs.index.map(dfm['pChEMBL'])\n",
    "\n",
    "dfs['node_color'] = dfs.index.map(dfm['node_color'])\n",
    "dfs['edgecolor'] = dfs.index.map(dfm['edgecolor'])\n",
    "dfs['node_size'] = dfs.index.map(dfm['node_size'])\n",
    "dfs['label'] = dfs.index.map(dfm['label'])\n",
    "\n",
    "dfs1 = dfs[dfs.label == 'data']\n",
    "dfs2 = dfs[dfs.label != 'data']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.scatter(dfs1.dim1, dfs1.dim2, c = dfs1.node_color,s = dfs1.node_size,)\n",
    "ax.scatter(dfs2.dim1, dfs2.dim2, c = dfs2.node_color, s = 500, edgecolors = dfs2.edgecolor)\n",
    "for i in range(len(dfs2)):\n",
    "    ts = dfs2.iloc[i]\n",
    "    ax.text(ts.dim1, ts.dim2, ts.label)\n",
    "    \n",
    "    \n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "fig.savefig('./results/braf_latent_sapce_no_ACA_umap.pdf', dpi = 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3e1c8-6bb9-4bbd-b246-1a066005646d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853f297-3279-4d74-84f2-8dd5dedb9752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd1fa7-7ca1-493c-9a82-00054034261b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68ac8b-11cf-478a-80e5-696ea7903969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
