{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1875c89b-911c-4643-b9b9-e9a700001af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mglur2\n",
      "\n",
      "torch.Size([791, 115])\n",
      "{'name': 'mglur2', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa610554430>, 'pre_filter': None, '_indices': [7, 23, 3, 25, 4, 19, 17, 22, 16, 5, 2, 11, 8, 18, 12, 13, 9, 6, 24, 20, 10, 0, 21, 14, 1, 15], 'data': Data(x=[791, 115], edge_index=[2, 1734], edge_attr=[1734, 7], y=[26, 1], smiles=[26]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([  0,  33,  54,  74, 102, 135, 169, 203, 230, 251, 285, 320, 348, 376,\n",
      "        410, 444, 472, 506, 540, 576, 611, 632, 661, 695, 730, 764, 791]), 'edge_index': tensor([   0,   72,  118,  162,  224,  296,  370,  444,  504,  552,  626,  702,\n",
      "         764,  826,  900,  974, 1036, 1110, 1184, 1262, 1338, 1386, 1450, 1524,\n",
      "        1600, 1674, 1734]), 'edge_attr': tensor([   0,   72,  118,  162,  224,  296,  370,  444,  504,  552,  626,  702,\n",
      "         764,  826,  900,  974, 1036, 1110, 1184, 1262, 1338, 1386, 1450, 1524,\n",
      "        1600, 1674, 1734]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])}), '_data_list': None}\n",
      "minv: 5.570000171661377\n",
      "maxv: 8.050000190734863\n",
      "emb_dim: 300\n",
      "16\n",
      "Epoch: 000, Loss: 0.9795 Val: 1.5576 Test: 1.7985\n",
      "16\n",
      "Epoch: 001, Loss: 0.9474 Val: 1.5321 Test: 1.7496\n",
      "16\n",
      "Epoch: 002, Loss: 0.8171 Val: 1.5242 Test: 1.7389\n",
      "16\n",
      "Epoch: 003, Loss: 0.7758 Val: 1.5150 Test: 1.7277\n",
      "16\n",
      "Epoch: 004, Loss: 0.7542 Val: 1.5020 Test: 1.7131\n",
      "16\n",
      "Epoch: 005, Loss: 0.7342 Val: 1.4853 Test: 1.6961\n",
      "16\n",
      "Epoch: 006, Loss: 0.7185 Val: 1.4717 Test: 1.6804\n",
      "16\n",
      "Epoch: 007, Loss: 0.6532 Val: 1.4616 Test: 1.6671\n",
      "16\n",
      "Epoch: 008, Loss: 0.6270 Val: 1.4441 Test: 1.6544\n",
      "16\n",
      "Epoch: 009, Loss: 0.6095 Val: 1.4298 Test: 1.6433\n",
      "16\n",
      "Epoch: 010, Loss: 0.6057 Val: 1.4193 Test: 1.6333\n",
      "16\n",
      "Epoch: 011, Loss: 0.6009 Val: 1.4114 Test: 1.6243\n",
      "16\n",
      "Epoch: 012, Loss: 0.5959 Val: 1.4066 Test: 1.6160\n",
      "16\n",
      "Epoch: 013, Loss: 0.5828 Val: 1.3955 Test: 1.6093\n",
      "16\n",
      "Epoch: 014, Loss: 0.5903 Val: 1.3832 Test: 1.5986\n",
      "16\n",
      "Epoch: 015, Loss: 0.5562 Val: 1.3765 Test: 1.5909\n",
      "16\n",
      "Epoch: 016, Loss: 0.5811 Val: 1.3714 Test: 1.5837\n",
      "16\n",
      "Epoch: 017, Loss: 0.5464 Val: 1.3638 Test: 1.5747\n",
      "16\n",
      "Epoch: 018, Loss: 0.5477 Val: 1.3528 Test: 1.5650\n",
      "16\n",
      "Epoch: 019, Loss: 0.5534 Val: 1.3438 Test: 1.5559\n",
      "16\n",
      "Epoch: 020, Loss: 0.5539 Val: 1.3373 Test: 1.5479\n",
      "16\n",
      "Epoch: 021, Loss: 0.5494 Val: 1.3317 Test: 1.5392\n",
      "16\n",
      "Epoch: 022, Loss: 0.5649 Val: 1.3259 Test: 1.5303\n",
      "16\n",
      "Epoch: 023, Loss: 0.5493 Val: 1.3203 Test: 1.5199\n",
      "16\n",
      "Epoch: 024, Loss: 0.5621 Val: 1.3160 Test: 1.5110\n",
      "16\n",
      "Epoch: 025, Loss: 0.5334 Val: 1.3101 Test: 1.5037\n",
      "16\n",
      "Epoch: 026, Loss: 0.5372 Val: 1.2997 Test: 1.4980\n",
      "16\n",
      "Epoch: 027, Loss: 0.5472 Val: 1.2843 Test: 1.4794\n",
      "16\n",
      "Epoch: 028, Loss: 0.5275 Val: 1.2695 Test: 1.4671\n",
      "16\n",
      "Epoch: 029, Loss: 0.5178 Val: 1.2547 Test: 1.4564\n",
      "16\n",
      "Epoch: 030, Loss: 0.5261 Val: 1.2387 Test: 1.4457\n",
      "16\n",
      "Epoch: 031, Loss: 0.5425 Val: 1.2220 Test: 1.4349\n",
      "16\n",
      "Epoch: 032, Loss: 0.5033 Val: 1.2110 Test: 1.4247\n",
      "16\n",
      "Epoch: 033, Loss: 0.5104 Val: 1.2013 Test: 1.4156\n",
      "16\n",
      "Epoch: 034, Loss: 0.5321 Val: 1.1917 Test: 1.4063\n",
      "16\n",
      "Epoch: 035, Loss: 0.5471 Val: 1.1796 Test: 1.3962\n",
      "16\n",
      "Epoch: 036, Loss: 0.5023 Val: 1.1660 Test: 1.3850\n",
      "16\n",
      "Epoch: 037, Loss: 0.4857 Val: 1.1534 Test: 1.3753\n",
      "16\n",
      "Epoch: 038, Loss: 0.4843 Val: 1.1544 Test: 1.3653\n",
      "16\n",
      "Epoch: 039, Loss: 0.5210 Val: 1.1508 Test: 1.3574\n",
      "16\n",
      "Epoch: 040, Loss: 0.5060 Val: 1.1413 Test: 1.3494\n",
      "16\n",
      "Epoch: 041, Loss: 0.5195 Val: 1.1313 Test: 1.3416\n",
      "16\n",
      "Epoch: 042, Loss: 0.5108 Val: 1.1227 Test: 1.3342\n",
      "16\n",
      "Epoch: 043, Loss: 0.4947 Val: 1.1163 Test: 1.3260\n",
      "16\n",
      "Epoch: 044, Loss: 0.4870 Val: 1.1137 Test: 1.3185\n",
      "16\n",
      "Epoch: 045, Loss: 0.5030 Val: 1.1175 Test: 1.3109\n",
      "16\n",
      "Epoch: 046, Loss: 0.5222 Val: 1.1329 Test: 1.3042\n",
      "16\n",
      "Epoch: 047, Loss: 0.5108 Val: 1.1457 Test: 1.2971\n",
      "16\n",
      "Epoch: 048, Loss: 0.4834 Val: 1.1279 Test: 1.2941\n",
      "16\n",
      "Epoch: 049, Loss: 0.5025 Val: 1.1237 Test: 1.2989\n",
      "16\n",
      "Epoch: 050, Loss: 0.4742 Val: 1.1140 Test: 1.2989\n",
      "16\n",
      "Epoch: 051, Loss: 0.4687 Val: 1.0848 Test: 1.2867\n",
      "16\n",
      "Epoch: 052, Loss: 0.4844 Val: 1.0588 Test: 1.2696\n",
      "16\n",
      "Epoch: 053, Loss: 0.4873 Val: 1.0359 Test: 1.2518\n",
      "16\n",
      "Epoch: 054, Loss: 0.4509 Val: 1.0163 Test: 1.2370\n",
      "16\n",
      "Epoch: 055, Loss: 0.4527 Val: 0.9982 Test: 1.2228\n",
      "16\n",
      "Epoch: 056, Loss: 0.4787 Val: 0.9823 Test: 1.2088\n",
      "16\n",
      "Epoch: 057, Loss: 0.4546 Val: 0.9791 Test: 1.1973\n",
      "16\n",
      "Epoch: 058, Loss: 0.4460 Val: 0.9772 Test: 1.1895\n",
      "16\n",
      "Epoch: 059, Loss: 0.4610 Val: 0.9710 Test: 1.1799\n",
      "16\n",
      "Epoch: 060, Loss: 0.4873 Val: 0.9617 Test: 1.1695\n",
      "16\n",
      "Epoch: 061, Loss: 0.4624 Val: 0.9393 Test: 1.1403\n",
      "16\n",
      "Epoch: 062, Loss: 0.4488 Val: 0.9224 Test: 1.0933\n",
      "16\n",
      "Epoch: 063, Loss: 0.4217 Val: 0.9244 Test: 1.0758\n",
      "16\n",
      "Epoch: 064, Loss: 0.4853 Val: 0.9159 Test: 1.0834\n",
      "16\n",
      "Epoch: 065, Loss: 0.4390 Val: 0.9225 Test: 1.0927\n",
      "16\n",
      "Epoch: 066, Loss: 0.4479 Val: 0.9282 Test: 1.0952\n",
      "16\n",
      "Epoch: 067, Loss: 0.5277 Val: 0.9322 Test: 1.0953\n",
      "16\n",
      "Epoch: 068, Loss: 0.4597 Val: 0.9307 Test: 1.0962\n",
      "16\n",
      "Epoch: 069, Loss: 0.5233 Val: 0.9266 Test: 1.0952\n",
      "16\n",
      "Epoch: 070, Loss: 0.4046 Val: 0.9269 Test: 1.0905\n",
      "16\n",
      "Epoch: 071, Loss: 0.5204 Val: 0.9262 Test: 1.0850\n",
      "16\n",
      "Epoch: 072, Loss: 0.5193 Val: 0.9236 Test: 1.0789\n",
      "16\n",
      "Epoch: 073, Loss: 0.4223 Val: 0.9205 Test: 1.0721\n",
      "16\n",
      "Epoch: 074, Loss: 0.4504 Val: 0.9169 Test: 1.0663\n",
      "16\n",
      "Epoch: 075, Loss: 0.5150 Val: 0.9131 Test: 1.0606\n",
      "16\n",
      "Epoch: 076, Loss: 0.4461 Val: 0.9052 Test: 1.0551\n",
      "16\n",
      "Epoch: 077, Loss: 0.5103 Val: 0.8982 Test: 1.0499\n",
      "16\n",
      "Epoch: 078, Loss: 0.5073 Val: 0.8917 Test: 1.0447\n",
      "16\n",
      "Epoch: 079, Loss: 0.5041 Val: 0.8852 Test: 1.0398\n",
      "16\n",
      "Epoch: 080, Loss: 0.3955 Val: 0.8820 Test: 1.0340\n",
      "16\n",
      "Epoch: 081, Loss: 0.4988 Val: 0.8786 Test: 1.0286\n",
      "16\n",
      "Epoch: 082, Loss: 0.4298 Val: 0.8795 Test: 1.0198\n",
      "16\n",
      "Epoch: 083, Loss: 0.4261 Val: 0.8792 Test: 1.0120\n",
      "16\n",
      "Epoch: 084, Loss: 0.4955 Val: 0.8786 Test: 1.0044\n",
      "16\n",
      "Epoch: 085, Loss: 0.4940 Val: 0.8777 Test: 0.9969\n",
      "16\n",
      "Epoch: 086, Loss: 0.4922 Val: 0.8767 Test: 0.9898\n",
      "16\n",
      "Epoch: 087, Loss: 0.4901 Val: 0.8754 Test: 0.9829\n",
      "16\n",
      "Epoch: 088, Loss: 0.4883 Val: 0.8744 Test: 0.9765\n",
      "16\n",
      "Epoch: 089, Loss: 0.4864 Val: 0.8738 Test: 0.9707\n",
      "16\n",
      "Epoch: 090, Loss: 0.4845 Val: 0.8737 Test: 0.9659\n",
      "16\n",
      "Epoch: 091, Loss: 0.4826 Val: 0.8742 Test: 0.9618\n",
      "16\n",
      "Epoch: 092, Loss: 0.4806 Val: 0.8752 Test: 0.9582\n",
      "16\n",
      "Epoch: 093, Loss: 0.4787 Val: 0.8760 Test: 0.9540\n",
      "16\n",
      "Epoch: 094, Loss: 0.4768 Val: 0.8767 Test: 0.9497\n",
      "16\n",
      "Epoch: 095, Loss: 0.4747 Val: 0.8775 Test: 0.9453\n",
      "16\n",
      "Epoch: 096, Loss: 0.3941 Val: 0.8736 Test: 0.9391\n",
      "16\n",
      "Epoch: 097, Loss: 0.3620 Val: 0.8656 Test: 0.9368\n",
      "16\n",
      "Epoch: 098, Loss: 0.3633 Val: 0.8577 Test: 0.9346\n",
      "16\n",
      "Epoch: 099, Loss: 0.3684 Val: 0.8493 Test: 0.9290\n",
      "16\n",
      "Epoch: 100, Loss: 0.3732 Val: 0.8384 Test: 0.9198\n",
      "16\n",
      "Epoch: 101, Loss: 0.3497 Val: 0.8237 Test: 0.9095\n",
      "16\n",
      "Epoch: 102, Loss: 0.3511 Val: 0.8143 Test: 0.9040\n",
      "16\n",
      "Epoch: 103, Loss: 0.4619 Val: 0.8042 Test: 0.9030\n",
      "16\n",
      "Epoch: 104, Loss: 0.3824 Val: 0.8113 Test: 0.9004\n",
      "16\n",
      "Epoch: 105, Loss: 0.4588 Val: 0.8165 Test: 0.8999\n",
      "16\n",
      "Epoch: 106, Loss: 0.3294 Val: 0.8373 Test: 0.8853\n",
      "16\n",
      "Epoch: 107, Loss: 0.3729 Val: 0.8406 Test: 0.8751\n",
      "16\n",
      "Epoch: 108, Loss: 0.3627 Val: 0.8377 Test: 0.8602\n",
      "16\n",
      "Epoch: 109, Loss: 0.3599 Val: 0.8274 Test: 0.8409\n",
      "16\n",
      "Epoch: 110, Loss: 0.3342 Val: 0.8044 Test: 0.8128\n",
      "16\n",
      "Epoch: 111, Loss: 0.4494 Val: 0.7772 Test: 0.7792\n",
      "16\n",
      "Epoch: 112, Loss: 0.4479 Val: 0.7464 Test: 0.7330\n",
      "16\n",
      "Epoch: 113, Loss: 0.3656 Val: 0.7232 Test: 0.7170\n",
      "16\n",
      "Epoch: 114, Loss: 0.4444 Val: 0.7012 Test: 0.7074\n",
      "16\n",
      "Epoch: 115, Loss: 0.4427 Val: 0.6834 Test: 0.7042\n",
      "16\n",
      "Epoch: 116, Loss: 0.4412 Val: 0.6661 Test: 0.6971\n",
      "16\n",
      "Epoch: 117, Loss: 0.3501 Val: 0.6341 Test: 0.6537\n",
      "16\n",
      "Epoch: 118, Loss: 0.3633 Val: 0.6207 Test: 0.6833\n",
      "16\n",
      "Epoch: 119, Loss: 0.3311 Val: 0.6006 Test: 0.6949\n",
      "16\n",
      "Epoch: 120, Loss: 0.3210 Val: 0.5680 Test: 0.6804\n",
      "16\n",
      "Epoch: 121, Loss: 0.3304 Val: 0.6011 Test: 0.7753\n",
      "16\n",
      "Epoch: 122, Loss: 0.3581 Val: 0.6282 Test: 0.8141\n",
      "16\n",
      "Epoch: 123, Loss: 0.3610 Val: 0.6452 Test: 0.8298\n",
      "16\n",
      "Epoch: 124, Loss: 0.3481 Val: 0.6594 Test: 0.8345\n",
      "16\n",
      "Epoch: 125, Loss: 0.3111 Val: 0.6685 Test: 0.8393\n",
      "16\n",
      "Epoch: 126, Loss: 0.4276 Val: 0.6652 Test: 0.8443\n",
      "16\n",
      "Epoch: 127, Loss: 0.3147 Val: 0.6504 Test: 0.8526\n",
      "16\n",
      "Epoch: 128, Loss: 0.2811 Val: 0.6525 Test: 0.8614\n",
      "16\n",
      "Epoch: 129, Loss: 0.3166 Val: 0.6421 Test: 0.8684\n",
      "16\n",
      "Epoch: 130, Loss: 0.3412 Val: 0.6058 Test: 0.8731\n",
      "16\n",
      "Epoch: 131, Loss: 0.4236 Val: 0.5671 Test: 0.8747\n",
      "16\n",
      "Epoch: 132, Loss: 0.4217 Val: 0.5338 Test: 0.8752\n",
      "16\n",
      "Epoch: 133, Loss: 0.3449 Val: 0.5216 Test: 0.8685\n",
      "16\n",
      "Epoch: 134, Loss: 0.3011 Val: 0.5165 Test: 0.8671\n",
      "16\n",
      "Epoch: 135, Loss: 0.3096 Val: 0.5856 Test: 0.8706\n",
      "16\n",
      "Epoch: 136, Loss: 0.2943 Val: 0.6313 Test: 0.8717\n",
      "16\n",
      "Epoch: 137, Loss: 0.3205 Val: 0.6564 Test: 0.8644\n",
      "16\n",
      "Epoch: 138, Loss: 0.3167 Val: 0.6682 Test: 0.8471\n",
      "16\n",
      "Epoch: 139, Loss: 0.2905 Val: 0.6754 Test: 0.8269\n",
      "16\n",
      "Epoch: 140, Loss: 0.2951 Val: 0.6741 Test: 0.7960\n",
      "16\n",
      "Epoch: 141, Loss: 0.3493 Val: 0.6725 Test: 0.7442\n",
      "16\n",
      "Epoch: 142, Loss: 0.4088 Val: 0.6683 Test: 0.6840\n",
      "16\n",
      "Epoch: 143, Loss: 0.4070 Val: 0.6639 Test: 0.6186\n",
      "16\n",
      "Epoch: 144, Loss: 0.4046 Val: 0.6630 Test: 0.5477\n",
      "16\n",
      "Epoch: 145, Loss: 0.4008 Val: 0.6617 Test: 0.4857\n",
      "16\n",
      "Epoch: 146, Loss: 0.3976 Val: 0.6588 Test: 0.4484\n",
      "16\n",
      "Epoch: 147, Loss: 0.3909 Val: 0.6545 Test: 0.4302\n",
      "16\n",
      "Epoch: 148, Loss: 0.2763 Val: 0.6488 Test: 0.4447\n",
      "16\n",
      "Epoch: 149, Loss: 0.2441 Val: 0.6462 Test: 0.4728\n",
      "16\n",
      "Epoch: 150, Loss: 0.3676 Val: 0.6357 Test: 0.4899\n",
      "16\n",
      "Epoch: 151, Loss: 0.3183 Val: 0.6188 Test: 0.4992\n",
      "16\n",
      "Epoch: 152, Loss: 0.2832 Val: 0.6015 Test: 0.4791\n",
      "16\n",
      "Epoch: 153, Loss: 0.2660 Val: 0.5811 Test: 0.4297\n",
      "16\n",
      "Epoch: 154, Loss: 0.3169 Val: 0.5598 Test: 0.4057\n",
      "16\n",
      "Epoch: 155, Loss: 0.4063 Val: 0.5359 Test: 0.3817\n",
      "16\n",
      "Epoch: 156, Loss: 0.4073 Val: 0.5158 Test: 0.3669\n",
      "16\n",
      "Epoch: 157, Loss: 0.2771 Val: 0.5623 Test: 0.4586\n",
      "16\n",
      "Epoch: 158, Loss: 0.2647 Val: 0.6327 Test: 0.4748\n",
      "16\n",
      "Epoch: 159, Loss: 0.3134 Val: 0.7136 Test: 0.4761\n",
      "16\n",
      "Epoch: 160, Loss: 0.2922 Val: 0.7475 Test: 0.4687\n",
      "16\n",
      "Epoch: 161, Loss: 0.3102 Val: 0.7888 Test: 0.5520\n",
      "16\n",
      "Epoch: 162, Loss: 0.2960 Val: 0.8019 Test: 0.5425\n",
      "16\n",
      "Epoch: 163, Loss: 0.2937 Val: 0.8035 Test: 0.4893\n",
      "16\n",
      "Epoch: 164, Loss: 0.2998 Val: 0.7885 Test: 0.4248\n",
      "16\n",
      "Epoch: 165, Loss: 0.2558 Val: 0.7888 Test: 0.3944\n",
      "16\n",
      "Epoch: 166, Loss: 0.2945 Val: 0.7856 Test: 0.3800\n",
      "16\n",
      "Epoch: 167, Loss: 0.4070 Val: 0.7803 Test: 0.3740\n",
      "16\n",
      "Epoch: 168, Loss: 0.4061 Val: 0.7722 Test: 0.3688\n",
      "16\n",
      "Epoch: 169, Loss: 0.2559 Val: 0.7621 Test: 0.3655\n",
      "16\n",
      "Epoch: 170, Loss: 0.3165 Val: 0.7440 Test: 0.3614\n",
      "16\n",
      "Epoch: 171, Loss: 0.4018 Val: 0.7298 Test: 0.3596\n",
      "16\n",
      "Epoch: 172, Loss: 0.2767 Val: 0.7239 Test: 0.3517\n",
      "16\n",
      "Epoch: 173, Loss: 0.3055 Val: 0.7309 Test: 0.3408\n",
      "16\n",
      "Epoch: 174, Loss: 0.4047 Val: 0.7373 Test: 0.3299\n",
      "16\n",
      "Epoch: 175, Loss: 0.2665 Val: 0.7415 Test: 0.3228\n",
      "16\n",
      "Epoch: 176, Loss: 0.3107 Val: 0.7364 Test: 0.3183\n",
      "16\n",
      "Epoch: 177, Loss: 0.4003 Val: 0.7290 Test: 0.3189\n",
      "16\n",
      "Epoch: 178, Loss: 0.2714 Val: 0.7180 Test: 0.3182\n",
      "16\n",
      "Epoch: 179, Loss: 0.3077 Val: 0.7129 Test: 0.3137\n",
      "16\n",
      "Epoch: 180, Loss: 0.4036 Val: 0.7118 Test: 0.3099\n",
      "16\n",
      "Epoch: 181, Loss: 0.4040 Val: 0.7145 Test: 0.3077\n",
      "16\n",
      "Epoch: 182, Loss: 0.4051 Val: 0.7185 Test: 0.3080\n",
      "16\n",
      "Epoch: 183, Loss: 0.3056 Val: 0.7291 Test: 0.3118\n",
      "16\n",
      "Epoch: 184, Loss: 0.3134 Val: 0.7397 Test: 0.3196\n",
      "16\n",
      "Epoch: 185, Loss: 0.3996 Val: 0.7479 Test: 0.3297\n",
      "16\n",
      "Epoch: 186, Loss: 0.3995 Val: 0.7531 Test: 0.3361\n",
      "16\n",
      "Epoch: 187, Loss: 0.3988 Val: 0.7546 Test: 0.3382\n",
      "16\n",
      "Epoch: 188, Loss: 0.3967 Val: 0.7511 Test: 0.3356\n",
      "16\n",
      "Epoch: 189, Loss: 0.3934 Val: 0.7461 Test: 0.3282\n",
      "16\n",
      "Epoch: 190, Loss: 0.2940 Val: 0.7242 Test: 0.3166\n",
      "16\n",
      "Epoch: 191, Loss: 0.3931 Val: 0.7037 Test: 0.3105\n",
      "16\n",
      "Epoch: 192, Loss: 0.2955 Val: 0.7172 Test: 0.3083\n",
      "16\n",
      "Epoch: 193, Loss: 0.3059 Val: 0.7374 Test: 0.3099\n",
      "16\n",
      "Epoch: 194, Loss: 0.3073 Val: 0.7597 Test: 0.3149\n",
      "16\n",
      "Epoch: 195, Loss: 0.3007 Val: 0.7846 Test: 0.3198\n",
      "16\n",
      "Epoch: 196, Loss: 0.3987 Val: 0.8015 Test: 0.3253\n",
      "16\n",
      "Epoch: 197, Loss: 0.3994 Val: 0.8143 Test: 0.3288\n",
      "16\n",
      "Epoch: 198, Loss: 0.3993 Val: 0.8188 Test: 0.3263\n",
      "16\n",
      "Epoch: 199, Loss: 0.3978 Val: 0.8191 Test: 0.3201\n",
      "usp7\n",
      "\n",
      "torch.Size([1506, 115])\n",
      "{'name': 'usp7', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa61033da30>, 'pre_filter': None, '_indices': [42, 37, 27, 34, 41, 23, 44, 21, 15, 35, 40, 11, 0, 38, 28, 33, 32, 30, 25, 39, 14, 18, 26, 36, 31, 22, 2, 7, 8, 6, 16, 4, 9, 10, 29, 20, 43, 19, 3, 13, 17, 5, 1, 24, 12], 'data': Data(x=[1506, 115], edge_index=[2, 3304], edge_attr=[3304, 7], y=[45, 1], smiles=[45]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   37,   70,  103,  132,  162,  193,  230,  262,  291,  322,  361,\n",
      "         394,  426,  456,  485,  516,  550,  585,  621,  661,  697,  735,  768,\n",
      "         806,  849,  887,  916,  951,  990, 1027, 1060, 1094, 1122, 1151, 1181,\n",
      "        1215, 1247, 1280, 1308, 1345, 1373, 1399, 1427, 1468, 1506]), 'edge_index': tensor([   0,   82,  154,  224,  288,  354,  420,  502,  570,  634,  704,  790,\n",
      "         862,  930,  996, 1060, 1128, 1202, 1278, 1356, 1444, 1524, 1608, 1680,\n",
      "        1764, 1860, 1944, 2008, 2086, 2172, 2254, 2324, 2398, 2460, 2524, 2590,\n",
      "        2666, 2736, 2808, 2870, 2952, 3014, 3070, 3130, 3220, 3304]), 'edge_attr': tensor([   0,   82,  154,  224,  288,  354,  420,  502,  570,  634,  704,  790,\n",
      "         862,  930,  996, 1060, 1128, 1202, 1278, 1356, 1444, 1524, 1608, 1680,\n",
      "        1764, 1860, 1944, 2008, 2086, 2172, 2254, 2324, 2398, 2460, 2524, 2590,\n",
      "        2666, 2736, 2808, 2870, 2952, 3014, 3070, 3130, 3220, 3304]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45])}), '_data_list': None}\n",
      "minv: 4.050000190734863\n",
      "maxv: 8.220000267028809\n",
      "emb_dim: 300\n",
      "16\n",
      "11\n",
      "Epoch: 000, Loss: 0.8297 Val: 2.6801 Test: 1.8910\n",
      "16\n",
      "11\n",
      "Epoch: 001, Loss: 0.8120 Val: 2.6298 Test: 1.8590\n",
      "16\n",
      "11\n",
      "Epoch: 002, Loss: 0.7845 Val: 2.6062 Test: 1.8300\n",
      "16\n",
      "11\n",
      "Epoch: 003, Loss: 0.7966 Val: 2.5298 Test: 1.8085\n",
      "16\n",
      "11\n",
      "Epoch: 004, Loss: 0.7442 Val: 2.5008 Test: 1.7899\n",
      "16\n",
      "11\n",
      "Epoch: 005, Loss: 0.7227 Val: 2.4807 Test: 1.7619\n",
      "16\n",
      "11\n",
      "Epoch: 006, Loss: 0.7447 Val: 2.4602 Test: 1.7437\n",
      "16\n",
      "11\n",
      "Epoch: 007, Loss: 0.7374 Val: 2.4455 Test: 1.7227\n",
      "16\n",
      "11\n",
      "Epoch: 008, Loss: 0.7632 Val: 2.3967 Test: 1.6941\n",
      "16\n",
      "11\n",
      "Epoch: 009, Loss: 0.7600 Val: 2.3511 Test: 1.6642\n",
      "16\n",
      "11\n",
      "Epoch: 010, Loss: 0.7417 Val: 2.2918 Test: 1.6261\n",
      "16\n",
      "11\n",
      "Epoch: 011, Loss: 0.8127 Val: 2.2382 Test: 1.5865\n",
      "16\n",
      "11\n",
      "Epoch: 012, Loss: 0.7005 Val: 2.1949 Test: 1.5539\n",
      "16\n",
      "11\n",
      "Epoch: 013, Loss: 0.6841 Val: 2.1675 Test: 1.5360\n",
      "16\n",
      "11\n",
      "Epoch: 014, Loss: 0.7168 Val: 2.1518 Test: 1.5174\n",
      "16\n",
      "11\n",
      "Epoch: 015, Loss: 0.6521 Val: 2.1198 Test: 1.4960\n",
      "16\n",
      "11\n",
      "Epoch: 016, Loss: 0.6759 Val: 2.0797 Test: 1.4725\n",
      "16\n",
      "11\n",
      "Epoch: 017, Loss: 0.6642 Val: 2.0389 Test: 1.4483\n",
      "16\n",
      "11\n",
      "Epoch: 018, Loss: 0.6361 Val: 2.0090 Test: 1.4327\n",
      "16\n",
      "11\n",
      "Epoch: 019, Loss: 0.7293 Val: 1.9553 Test: 1.3953\n",
      "16\n",
      "11\n",
      "Epoch: 020, Loss: 0.6418 Val: 1.9132 Test: 1.3649\n",
      "16\n",
      "11\n",
      "Epoch: 021, Loss: 0.7325 Val: 1.8937 Test: 1.3663\n",
      "16\n",
      "11\n",
      "Epoch: 022, Loss: 0.7160 Val: 1.8483 Test: 1.3265\n",
      "16\n",
      "11\n",
      "Epoch: 023, Loss: 0.7162 Val: 1.8091 Test: 1.2928\n",
      "16\n",
      "11\n",
      "Epoch: 024, Loss: 0.6777 Val: 1.7887 Test: 1.3169\n",
      "16\n",
      "11\n",
      "Epoch: 025, Loss: 0.6676 Val: 1.7413 Test: 1.2575\n",
      "16\n",
      "11\n",
      "Epoch: 026, Loss: 0.6466 Val: 1.7056 Test: 1.2108\n",
      "16\n",
      "11\n",
      "Epoch: 027, Loss: 0.5936 Val: 1.6756 Test: 1.1851\n",
      "16\n",
      "11\n",
      "Epoch: 028, Loss: 0.5922 Val: 1.6593 Test: 1.1680\n",
      "16\n",
      "11\n",
      "Epoch: 029, Loss: 0.6129 Val: 1.6350 Test: 1.1442\n",
      "16\n",
      "11\n",
      "Epoch: 030, Loss: 0.7413 Val: 1.5970 Test: 1.1000\n",
      "16\n",
      "11\n",
      "Epoch: 031, Loss: 0.6265 Val: 1.5430 Test: 1.0697\n",
      "16\n",
      "11\n",
      "Epoch: 032, Loss: 0.6212 Val: 1.5030 Test: 1.0581\n",
      "16\n",
      "11\n",
      "Epoch: 033, Loss: 0.6270 Val: 1.4984 Test: 1.0635\n",
      "16\n",
      "11\n",
      "Epoch: 034, Loss: 0.6067 Val: 1.4679 Test: 1.0454\n",
      "16\n",
      "11\n",
      "Epoch: 035, Loss: 0.6411 Val: 1.4567 Test: 1.0504\n",
      "16\n",
      "11\n",
      "Epoch: 036, Loss: 0.5989 Val: 1.4368 Test: 1.0648\n",
      "16\n",
      "11\n",
      "Epoch: 037, Loss: 0.5894 Val: 1.3921 Test: 1.0680\n",
      "16\n",
      "11\n",
      "Epoch: 038, Loss: 0.6298 Val: 1.3490 Test: 1.0703\n",
      "16\n",
      "11\n",
      "Epoch: 039, Loss: 0.5130 Val: 1.3286 Test: 1.0917\n",
      "16\n",
      "11\n",
      "Epoch: 040, Loss: 0.6332 Val: 1.4208 Test: 1.2686\n",
      "16\n",
      "11\n",
      "Epoch: 041, Loss: 0.6126 Val: 1.4512 Test: 1.3582\n",
      "16\n",
      "11\n",
      "Epoch: 042, Loss: 0.6308 Val: 1.4114 Test: 1.3528\n",
      "16\n",
      "11\n",
      "Epoch: 043, Loss: 0.6478 Val: 1.3477 Test: 1.3265\n",
      "16\n",
      "11\n",
      "Epoch: 044, Loss: 0.6104 Val: 1.2940 Test: 1.2967\n",
      "16\n",
      "11\n",
      "Epoch: 045, Loss: 0.6065 Val: 1.2311 Test: 1.2491\n",
      "16\n",
      "11\n",
      "Epoch: 046, Loss: 0.5471 Val: 1.1789 Test: 1.2285\n",
      "16\n",
      "11\n",
      "Epoch: 047, Loss: 0.5663 Val: 1.1633 Test: 1.2552\n",
      "16\n",
      "11\n",
      "Epoch: 048, Loss: 0.5564 Val: 1.1683 Test: 1.2912\n",
      "16\n",
      "11\n",
      "Epoch: 049, Loss: 0.5260 Val: 1.1491 Test: 1.3154\n",
      "16\n",
      "11\n",
      "Epoch: 050, Loss: 0.5283 Val: 1.1430 Test: 1.3546\n",
      "16\n",
      "11\n",
      "Epoch: 051, Loss: 0.6180 Val: 1.1461 Test: 1.3796\n",
      "16\n",
      "11\n",
      "Epoch: 052, Loss: 0.5369 Val: 1.1611 Test: 1.3710\n",
      "16\n",
      "11\n",
      "Epoch: 053, Loss: 0.6320 Val: 1.1555 Test: 1.3653\n",
      "16\n",
      "11\n",
      "Epoch: 054, Loss: 0.6167 Val: 1.1496 Test: 1.3888\n",
      "16\n",
      "11\n",
      "Epoch: 055, Loss: 0.5513 Val: 1.1483 Test: 1.4027\n",
      "16\n",
      "11\n",
      "Epoch: 056, Loss: 0.6303 Val: 1.1277 Test: 1.4174\n",
      "16\n",
      "11\n",
      "Epoch: 057, Loss: 0.5841 Val: 1.0670 Test: 1.4133\n",
      "16\n",
      "11\n",
      "Epoch: 058, Loss: 0.5778 Val: 0.9753 Test: 1.0261\n",
      "16\n",
      "11\n",
      "Epoch: 059, Loss: 0.6430 Val: 0.9589 Test: 1.0326\n",
      "16\n",
      "11\n",
      "Epoch: 060, Loss: 0.5682 Val: 0.9391 Test: 1.0431\n",
      "16\n",
      "11\n",
      "Epoch: 061, Loss: 0.5483 Val: 0.9199 Test: 1.0626\n",
      "16\n",
      "11\n",
      "Epoch: 062, Loss: 0.6111 Val: 0.9376 Test: 1.0728\n",
      "16\n",
      "11\n",
      "Epoch: 063, Loss: 0.5467 Val: 0.9430 Test: 1.0694\n",
      "16\n",
      "11\n",
      "Epoch: 064, Loss: 0.5295 Val: 0.9638 Test: 1.0734\n",
      "16\n",
      "11\n",
      "Epoch: 065, Loss: 0.5817 Val: 1.0029 Test: 1.0802\n",
      "16\n",
      "11\n",
      "Epoch: 066, Loss: 0.5446 Val: 1.0618 Test: 1.0867\n",
      "16\n",
      "11\n",
      "Epoch: 067, Loss: 0.5615 Val: 1.1119 Test: 1.0915\n",
      "16\n",
      "11\n",
      "Epoch: 068, Loss: 0.5895 Val: 1.1475 Test: 1.0929\n",
      "16\n",
      "11\n",
      "Epoch: 069, Loss: 0.5217 Val: 1.1837 Test: 1.1012\n",
      "16\n",
      "11\n",
      "Epoch: 070, Loss: 0.4972 Val: 1.1561 Test: 1.1038\n",
      "16\n",
      "11\n",
      "Epoch: 071, Loss: 0.6174 Val: 1.0077 Test: 1.1028\n",
      "16\n",
      "11\n",
      "Epoch: 072, Loss: 0.5757 Val: 0.9452 Test: 1.0987\n",
      "16\n",
      "11\n",
      "Epoch: 073, Loss: 0.5514 Val: 0.9821 Test: 1.0985\n",
      "16\n",
      "11\n",
      "Epoch: 074, Loss: 0.6409 Val: 0.9995 Test: 1.0964\n",
      "16\n",
      "11\n",
      "Epoch: 075, Loss: 0.5895 Val: 0.9521 Test: 1.1006\n",
      "16\n",
      "11\n",
      "Epoch: 076, Loss: 0.6622 Val: 0.8824 Test: 1.1129\n",
      "16\n",
      "11\n",
      "Epoch: 077, Loss: 0.5374 Val: 0.8757 Test: 1.1165\n",
      "16\n",
      "11\n",
      "Epoch: 078, Loss: 0.5354 Val: 0.8848 Test: 1.0779\n",
      "16\n",
      "11\n",
      "Epoch: 079, Loss: 0.6156 Val: 0.8883 Test: 1.0518\n",
      "16\n",
      "11\n",
      "Epoch: 080, Loss: 0.5263 Val: 0.8915 Test: 1.0569\n",
      "16\n",
      "11\n",
      "Epoch: 081, Loss: 0.5854 Val: 0.8884 Test: 1.0677\n",
      "16\n",
      "11\n",
      "Epoch: 082, Loss: 0.5794 Val: 0.8885 Test: 1.0696\n",
      "16\n",
      "11\n",
      "Epoch: 083, Loss: 0.5292 Val: 0.8819 Test: 1.0986\n",
      "16\n",
      "11\n",
      "Epoch: 084, Loss: 0.5239 Val: 0.8863 Test: 1.1312\n",
      "16\n",
      "11\n",
      "Epoch: 085, Loss: 0.5307 Val: 0.9045 Test: 1.1537\n",
      "16\n",
      "11\n",
      "Epoch: 086, Loss: 0.5475 Val: 0.9408 Test: 1.1594\n",
      "16\n",
      "11\n",
      "Epoch: 087, Loss: 0.5760 Val: 1.0033 Test: 1.1440\n",
      "16\n",
      "11\n",
      "Epoch: 088, Loss: 0.5428 Val: 1.0530 Test: 1.1297\n",
      "16\n",
      "11\n",
      "Epoch: 089, Loss: 0.4940 Val: 1.0718 Test: 1.1284\n",
      "16\n",
      "11\n",
      "Epoch: 090, Loss: 0.4977 Val: 1.0459 Test: 1.1319\n",
      "16\n",
      "11\n",
      "Epoch: 091, Loss: 0.5262 Val: 1.0569 Test: 1.1296\n",
      "16\n",
      "11\n",
      "Epoch: 092, Loss: 0.5591 Val: 1.0825 Test: 1.1229\n",
      "16\n",
      "11\n",
      "Epoch: 093, Loss: 0.5794 Val: 1.1218 Test: 1.1179\n",
      "16\n",
      "11\n",
      "Epoch: 094, Loss: 0.5274 Val: 1.1377 Test: 1.1103\n",
      "16\n",
      "11\n",
      "Epoch: 095, Loss: 0.5388 Val: 1.1365 Test: 1.0804\n",
      "16\n",
      "11\n",
      "Epoch: 096, Loss: 0.5571 Val: 1.1270 Test: 1.0419\n",
      "16\n",
      "11\n",
      "Epoch: 097, Loss: 0.5489 Val: 1.1093 Test: 0.9948\n",
      "16\n",
      "11\n",
      "Epoch: 098, Loss: 0.5323 Val: 1.0897 Test: 0.9226\n",
      "16\n",
      "11\n",
      "Epoch: 099, Loss: 0.5357 Val: 1.0803 Test: 0.8791\n",
      "16\n",
      "11\n",
      "Epoch: 100, Loss: 0.5750 Val: 1.1057 Test: 0.8883\n",
      "16\n",
      "11\n",
      "Epoch: 101, Loss: 0.5324 Val: 1.1639 Test: 0.9239\n",
      "16\n",
      "11\n",
      "Epoch: 102, Loss: 0.5820 Val: 1.1748 Test: 1.1558\n",
      "16\n",
      "11\n",
      "Epoch: 103, Loss: 0.4734 Val: 1.1320 Test: 1.1581\n",
      "16\n",
      "11\n",
      "Epoch: 104, Loss: 0.5971 Val: 1.1555 Test: 1.1554\n",
      "16\n",
      "11\n",
      "Epoch: 105, Loss: 0.5487 Val: 1.1641 Test: 1.1272\n",
      "16\n",
      "11\n",
      "Epoch: 106, Loss: 0.5420 Val: 1.0663 Test: 1.0722\n",
      "16\n",
      "11\n",
      "Epoch: 107, Loss: 0.5295 Val: 1.0278 Test: 0.9659\n",
      "16\n",
      "11\n",
      "Epoch: 108, Loss: 0.4511 Val: 1.0759 Test: 0.9793\n",
      "16\n",
      "11\n",
      "Epoch: 109, Loss: 0.5776 Val: 1.1668 Test: 1.1211\n",
      "16\n",
      "11\n",
      "Epoch: 110, Loss: 0.5265 Val: 1.1369 Test: 1.1608\n",
      "16\n",
      "11\n",
      "Epoch: 111, Loss: 0.5555 Val: 1.1196 Test: 1.1223\n",
      "16\n",
      "11\n",
      "Epoch: 112, Loss: 0.5188 Val: 1.0939 Test: 1.0390\n",
      "16\n",
      "11\n",
      "Epoch: 113, Loss: 0.5912 Val: 1.0579 Test: 0.9745\n",
      "16\n",
      "11\n",
      "Epoch: 114, Loss: 0.4794 Val: 1.0615 Test: 0.9670\n",
      "16\n",
      "11\n",
      "Epoch: 115, Loss: 0.5109 Val: 1.0611 Test: 0.9781\n",
      "16\n",
      "11\n",
      "Epoch: 116, Loss: 0.4720 Val: 1.0335 Test: 0.9939\n",
      "16\n",
      "11\n",
      "Epoch: 117, Loss: 0.4973 Val: 1.0373 Test: 1.0183\n",
      "16\n",
      "11\n",
      "Epoch: 118, Loss: 0.5047 Val: 1.0521 Test: 1.0393\n",
      "16\n",
      "11\n",
      "Epoch: 119, Loss: 0.5363 Val: 1.0859 Test: 1.0506\n",
      "16\n",
      "11\n",
      "Epoch: 120, Loss: 0.5707 Val: 1.0385 Test: 0.9679\n",
      "16\n",
      "11\n",
      "Epoch: 121, Loss: 0.4962 Val: 0.9439 Test: 0.9169\n",
      "16\n",
      "11\n",
      "Epoch: 122, Loss: 0.5262 Val: 0.9135 Test: 0.8843\n",
      "16\n",
      "11\n",
      "Epoch: 123, Loss: 0.4941 Val: 0.9147 Test: 0.8765\n",
      "16\n",
      "11\n",
      "Epoch: 124, Loss: 0.4947 Val: 0.9236 Test: 0.9194\n",
      "16\n",
      "11\n",
      "Epoch: 125, Loss: 0.5291 Val: 0.9497 Test: 0.9328\n",
      "16\n",
      "11\n",
      "Epoch: 126, Loss: 0.5661 Val: 0.9684 Test: 0.9449\n",
      "16\n",
      "11\n",
      "Epoch: 127, Loss: 0.5574 Val: 0.9691 Test: 0.9696\n",
      "16\n",
      "11\n",
      "Epoch: 128, Loss: 0.4352 Val: 0.9721 Test: 1.0195\n",
      "16\n",
      "11\n",
      "Epoch: 129, Loss: 0.4679 Val: 0.9748 Test: 1.0682\n",
      "16\n",
      "11\n",
      "Epoch: 130, Loss: 0.6420 Val: 1.0008 Test: 1.1002\n",
      "16\n",
      "11\n",
      "Epoch: 131, Loss: 0.6953 Val: 1.0351 Test: 1.1163\n",
      "16\n",
      "11\n",
      "Epoch: 132, Loss: 0.4889 Val: 1.0535 Test: 1.1220\n",
      "16\n",
      "11\n",
      "Epoch: 133, Loss: 0.5274 Val: 1.0700 Test: 1.1129\n",
      "16\n",
      "11\n",
      "Epoch: 134, Loss: 0.5162 Val: 1.0741 Test: 1.0810\n",
      "16\n",
      "11\n",
      "Epoch: 135, Loss: 0.5004 Val: 1.0896 Test: 1.0399\n",
      "16\n",
      "11\n",
      "Epoch: 136, Loss: 0.5407 Val: 1.0972 Test: 0.9317\n",
      "16\n",
      "11\n",
      "Epoch: 137, Loss: 0.6412 Val: 1.0912 Test: 0.8457\n",
      "16\n",
      "11\n",
      "Epoch: 138, Loss: 0.3868 Val: 1.0806 Test: 0.8003\n",
      "16\n",
      "11\n",
      "Epoch: 139, Loss: 0.5330 Val: 1.0583 Test: 0.7986\n",
      "16\n",
      "11\n",
      "Epoch: 140, Loss: 0.4447 Val: 1.0340 Test: 0.8118\n",
      "16\n",
      "11\n",
      "Epoch: 141, Loss: 0.5341 Val: 1.0131 Test: 0.8390\n",
      "16\n",
      "11\n",
      "Epoch: 142, Loss: 0.5774 Val: 1.0048 Test: 0.9118\n",
      "16\n",
      "11\n",
      "Epoch: 143, Loss: 0.4561 Val: 1.0122 Test: 0.9733\n",
      "16\n",
      "11\n",
      "Epoch: 144, Loss: 0.5205 Val: 1.0246 Test: 1.0453\n",
      "16\n",
      "11\n",
      "Epoch: 145, Loss: 0.5048 Val: 1.0444 Test: 1.1798\n",
      "16\n",
      "11\n",
      "Epoch: 146, Loss: 0.5156 Val: 1.0616 Test: 1.2310\n",
      "16\n",
      "11\n",
      "Epoch: 147, Loss: 0.5598 Val: 1.0541 Test: 1.2137\n",
      "16\n",
      "11\n",
      "Epoch: 148, Loss: 0.5292 Val: 1.0230 Test: 1.1973\n",
      "16\n",
      "11\n",
      "Epoch: 149, Loss: 0.5488 Val: 1.0115 Test: 1.1522\n",
      "16\n",
      "11\n",
      "Epoch: 150, Loss: 0.4857 Val: 1.0188 Test: 0.8880\n",
      "16\n",
      "11\n",
      "Epoch: 151, Loss: 0.5095 Val: 1.0323 Test: 0.8227\n",
      "16\n",
      "11\n",
      "Epoch: 152, Loss: 0.5599 Val: 1.0270 Test: 0.8326\n",
      "16\n",
      "11\n",
      "Epoch: 153, Loss: 0.5424 Val: 1.0338 Test: 0.8820\n",
      "16\n",
      "11\n",
      "Epoch: 154, Loss: 0.5111 Val: 1.0411 Test: 0.8953\n",
      "16\n",
      "11\n",
      "Epoch: 155, Loss: 0.5115 Val: 1.0579 Test: 0.9102\n",
      "16\n",
      "11\n",
      "Epoch: 156, Loss: 0.5857 Val: 1.0547 Test: 0.9137\n",
      "16\n",
      "11\n",
      "Epoch: 157, Loss: 0.6023 Val: 1.0399 Test: 0.9068\n",
      "16\n",
      "11\n",
      "Epoch: 158, Loss: 0.5263 Val: 1.0205 Test: 0.8896\n",
      "16\n",
      "11\n",
      "Epoch: 159, Loss: 0.4525 Val: 1.0150 Test: 0.8690\n",
      "16\n",
      "11\n",
      "Epoch: 160, Loss: 0.5053 Val: 1.0239 Test: 0.8535\n",
      "16\n",
      "11\n",
      "Epoch: 161, Loss: 0.5228 Val: 1.0244 Test: 0.8359\n",
      "16\n",
      "11\n",
      "Epoch: 162, Loss: 0.5261 Val: 1.0129 Test: 0.8189\n",
      "16\n",
      "11\n",
      "Epoch: 163, Loss: 0.4464 Val: 1.0220 Test: 0.8036\n",
      "16\n",
      "11\n",
      "Epoch: 164, Loss: 0.5968 Val: 1.0637 Test: 0.8003\n",
      "16\n",
      "11\n",
      "Epoch: 165, Loss: 0.6634 Val: 1.0534 Test: 0.7978\n",
      "16\n",
      "11\n",
      "Epoch: 166, Loss: 0.5177 Val: 1.0542 Test: 0.8053\n",
      "16\n",
      "11\n",
      "Epoch: 167, Loss: 0.5906 Val: 1.0498 Test: 0.8144\n",
      "16\n",
      "11\n",
      "Epoch: 168, Loss: 0.5348 Val: 1.0386 Test: 0.8266\n",
      "16\n",
      "11\n",
      "Epoch: 169, Loss: 0.5620 Val: 1.0229 Test: 0.8396\n",
      "16\n",
      "11\n",
      "Epoch: 170, Loss: 0.5492 Val: 0.9994 Test: 0.9455\n",
      "16\n",
      "11\n",
      "Epoch: 171, Loss: 0.5194 Val: 0.9860 Test: 1.2382\n",
      "16\n",
      "11\n",
      "Epoch: 172, Loss: 0.4997 Val: 0.9829 Test: 1.2415\n",
      "16\n",
      "11\n",
      "Epoch: 173, Loss: 0.5437 Val: 0.9824 Test: 1.2342\n",
      "16\n",
      "11\n",
      "Epoch: 174, Loss: 0.6319 Val: 0.9671 Test: 0.7824\n",
      "16\n",
      "11\n",
      "Epoch: 175, Loss: 0.5252 Val: 0.9422 Test: 0.7636\n",
      "16\n",
      "11\n",
      "Epoch: 176, Loss: 0.5412 Val: 0.9480 Test: 0.7635\n",
      "16\n",
      "11\n",
      "Epoch: 177, Loss: 0.5058 Val: 0.9490 Test: 0.7643\n",
      "16\n",
      "11\n",
      "Epoch: 178, Loss: 0.4851 Val: 0.9411 Test: 0.7662\n",
      "16\n",
      "11\n",
      "Epoch: 179, Loss: 0.5467 Val: 0.9624 Test: 0.7780\n",
      "16\n",
      "11\n",
      "Epoch: 180, Loss: 0.5456 Val: 0.9881 Test: 0.7966\n",
      "16\n",
      "11\n",
      "Epoch: 181, Loss: 0.5193 Val: 1.0296 Test: 0.8044\n",
      "16\n",
      "11\n",
      "Epoch: 182, Loss: 0.4925 Val: 1.0573 Test: 0.8980\n",
      "16\n",
      "11\n",
      "Epoch: 183, Loss: 0.5441 Val: 1.0254 Test: 0.8799\n",
      "16\n",
      "11\n",
      "Epoch: 184, Loss: 0.5462 Val: 1.0238 Test: 0.8264\n",
      "16\n",
      "11\n",
      "Epoch: 185, Loss: 0.5746 Val: 1.0244 Test: 0.7975\n",
      "16\n",
      "11\n",
      "Epoch: 186, Loss: 0.5549 Val: 1.0768 Test: 0.8123\n",
      "16\n",
      "11\n",
      "Epoch: 187, Loss: 0.5957 Val: 1.0503 Test: 0.8198\n",
      "16\n",
      "11\n",
      "Epoch: 188, Loss: 0.6125 Val: 0.9852 Test: 0.8331\n",
      "16\n",
      "11\n",
      "Epoch: 189, Loss: 0.4597 Val: 0.9759 Test: 0.8602\n",
      "16\n",
      "11\n",
      "Epoch: 190, Loss: 0.4852 Val: 0.9745 Test: 0.8997\n",
      "16\n",
      "11\n",
      "Epoch: 191, Loss: 0.4801 Val: 0.9662 Test: 0.9212\n",
      "16\n",
      "11\n",
      "Epoch: 192, Loss: 0.5037 Val: 0.9692 Test: 0.9224\n",
      "16\n",
      "11\n",
      "Epoch: 193, Loss: 0.5108 Val: 0.9596 Test: 0.9299\n",
      "16\n",
      "11\n",
      "Epoch: 194, Loss: 0.5310 Val: 0.9808 Test: 0.9198\n",
      "16\n",
      "11\n",
      "Epoch: 195, Loss: 0.5532 Val: 0.9721 Test: 0.8826\n",
      "16\n",
      "11\n",
      "Epoch: 196, Loss: 0.5736 Val: 0.9792 Test: 0.8735\n",
      "16\n",
      "11\n",
      "Epoch: 197, Loss: 0.5215 Val: 0.9326 Test: 0.9045\n",
      "16\n",
      "11\n",
      "Epoch: 198, Loss: 0.5544 Val: 0.8989 Test: 0.8770\n",
      "16\n",
      "11\n",
      "Epoch: 199, Loss: 0.5248 Val: 0.8823 Test: 0.8359\n",
      "mth1\n",
      "\n",
      "torch.Size([804, 115])\n",
      "{'name': 'mth1', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa61037f940>, 'pre_filter': None, '_indices': [45, 27, 32, 1, 23, 12, 26, 34, 40, 25, 20, 41, 38, 3, 11, 13, 21, 5, 15, 37, 31, 4, 35, 36, 7, 19, 6, 17, 24, 30, 8, 42, 9, 18, 10, 43, 14, 0, 22, 16, 2, 39, 44, 33, 28, 29], 'data': Data(x=[804, 115], edge_index=[2, 1746], edge_attr=[1746, 7], y=[46, 1], smiles=[46]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([  0,  19,  31,  50,  77,  98, 115, 137, 152, 173, 196, 210, 225, 238,\n",
      "        255, 272, 287, 307, 323, 339, 354, 370, 384, 399, 413, 433, 451, 470,\n",
      "        490, 508, 526, 545, 559, 573, 586, 601, 622, 643, 664, 680, 699, 718,\n",
      "        732, 747, 766, 784, 804]), 'edge_index': tensor([   0,   44,   68,  112,  174,  220,  256,  306,  340,  386,  438,  466,\n",
      "         496,  522,  558,  594,  624,  668,  704,  736,  766,  798,  826,  856,\n",
      "         884,  930,  970, 1012, 1058, 1100, 1140, 1182, 1210, 1240, 1266, 1296,\n",
      "        1344, 1390, 1438, 1474, 1516, 1558, 1586, 1616, 1658, 1700, 1746]), 'edge_attr': tensor([   0,   44,   68,  112,  174,  220,  256,  306,  340,  386,  438,  466,\n",
      "         496,  522,  558,  594,  624,  668,  704,  736,  766,  798,  826,  856,\n",
      "         884,  930,  970, 1012, 1058, 1100, 1140, 1182, 1210, 1240, 1266, 1296,\n",
      "        1344, 1390, 1438, 1474, 1516, 1558, 1586, 1616, 1658, 1700, 1746]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46])}), '_data_list': None}\n",
      "minv: 5.0\n",
      "maxv: 10.0\n",
      "emb_dim: 300\n",
      "16\n",
      "12\n",
      "Epoch: 000, Loss: 0.8353 Val: 2.0154 Test: 2.7949\n",
      "16\n",
      "12\n",
      "Epoch: 001, Loss: 0.7864 Val: 1.9895 Test: 2.7411\n",
      "16\n",
      "12\n",
      "Epoch: 002, Loss: 0.7554 Val: 1.9506 Test: 2.6791\n",
      "16\n",
      "12\n",
      "Epoch: 003, Loss: 0.7277 Val: 1.9364 Test: 2.6360\n",
      "16\n",
      "12\n",
      "Epoch: 004, Loss: 0.7085 Val: 1.8896 Test: 2.6177\n",
      "16\n",
      "12\n",
      "Epoch: 005, Loss: 0.6715 Val: 1.8280 Test: 2.5679\n",
      "16\n",
      "12\n",
      "Epoch: 006, Loss: 0.6179 Val: 1.7944 Test: 2.5175\n",
      "16\n",
      "12\n",
      "Epoch: 007, Loss: 0.6373 Val: 1.8328 Test: 2.4904\n",
      "16\n",
      "12\n",
      "Epoch: 008, Loss: 0.6603 Val: 1.8095 Test: 2.4744\n",
      "16\n",
      "12\n",
      "Epoch: 009, Loss: 0.5989 Val: 1.7697 Test: 2.4385\n",
      "16\n",
      "12\n",
      "Epoch: 010, Loss: 0.6062 Val: 1.7275 Test: 2.3780\n",
      "16\n",
      "12\n",
      "Epoch: 011, Loss: 0.5718 Val: 1.6663 Test: 2.3394\n",
      "16\n",
      "12\n",
      "Epoch: 012, Loss: 0.5731 Val: 1.6467 Test: 2.2932\n",
      "16\n",
      "12\n",
      "Epoch: 013, Loss: 0.6485 Val: 1.6436 Test: 2.3225\n",
      "16\n",
      "12\n",
      "Epoch: 014, Loss: 0.5640 Val: 1.5789 Test: 2.2449\n",
      "16\n",
      "12\n",
      "Epoch: 015, Loss: 0.5587 Val: 1.5726 Test: 2.2386\n",
      "16\n",
      "12\n",
      "Epoch: 016, Loss: 0.5596 Val: 1.5724 Test: 2.2201\n",
      "16\n",
      "12\n",
      "Epoch: 017, Loss: 0.5577 Val: 1.5062 Test: 2.1450\n",
      "16\n",
      "12\n",
      "Epoch: 018, Loss: 0.6142 Val: 1.4809 Test: 2.1025\n",
      "16\n",
      "12\n",
      "Epoch: 019, Loss: 0.5523 Val: 1.5268 Test: 2.0683\n",
      "16\n",
      "12\n",
      "Epoch: 020, Loss: 0.5114 Val: 1.5381 Test: 2.1703\n",
      "16\n",
      "12\n",
      "Epoch: 021, Loss: 0.5901 Val: 1.4959 Test: 2.0878\n",
      "16\n",
      "12\n",
      "Epoch: 022, Loss: 0.5077 Val: 1.3788 Test: 2.0972\n",
      "16\n",
      "12\n",
      "Epoch: 023, Loss: 0.7101 Val: 1.4043 Test: 2.0749\n",
      "16\n",
      "12\n",
      "Epoch: 024, Loss: 0.7390 Val: 1.3704 Test: 1.9864\n",
      "16\n",
      "12\n",
      "Epoch: 025, Loss: 0.6493 Val: 1.3727 Test: 1.9581\n",
      "16\n",
      "12\n",
      "Epoch: 026, Loss: 0.6251 Val: 1.3614 Test: 1.9109\n",
      "16\n",
      "12\n",
      "Epoch: 027, Loss: 0.6002 Val: 1.3249 Test: 1.8622\n",
      "16\n",
      "12\n",
      "Epoch: 028, Loss: 0.5517 Val: 1.2917 Test: 1.8230\n",
      "16\n",
      "12\n",
      "Epoch: 029, Loss: 0.5343 Val: 1.2512 Test: 1.7834\n",
      "16\n",
      "12\n",
      "Epoch: 030, Loss: 0.5409 Val: 1.2007 Test: 1.7442\n",
      "16\n",
      "12\n",
      "Epoch: 031, Loss: 0.5535 Val: 1.1507 Test: 1.7079\n",
      "16\n",
      "12\n",
      "Epoch: 032, Loss: 0.5231 Val: 1.1057 Test: 1.6706\n",
      "16\n",
      "12\n",
      "Epoch: 033, Loss: 0.4893 Val: 1.0950 Test: 1.6208\n",
      "16\n",
      "12\n",
      "Epoch: 034, Loss: 0.4489 Val: 1.1305 Test: 1.5765\n",
      "16\n",
      "12\n",
      "Epoch: 035, Loss: 0.5089 Val: 1.0775 Test: 1.5500\n",
      "16\n",
      "12\n",
      "Epoch: 036, Loss: 0.4354 Val: 1.0126 Test: 1.5260\n",
      "16\n",
      "12\n",
      "Epoch: 037, Loss: 0.5671 Val: 0.9843 Test: 1.5054\n",
      "16\n",
      "12\n",
      "Epoch: 038, Loss: 0.4564 Val: 1.1597 Test: 1.4497\n",
      "16\n",
      "12\n",
      "Epoch: 039, Loss: 0.4412 Val: 1.2033 Test: 1.4245\n",
      "16\n",
      "12\n",
      "Epoch: 040, Loss: 0.4548 Val: 1.2219 Test: 1.4079\n",
      "16\n",
      "12\n",
      "Epoch: 041, Loss: 0.4349 Val: 1.1977 Test: 1.3809\n",
      "16\n",
      "12\n",
      "Epoch: 042, Loss: 0.4301 Val: 1.1647 Test: 1.3410\n",
      "16\n",
      "12\n",
      "Epoch: 043, Loss: 0.4919 Val: 1.0998 Test: 1.3442\n",
      "16\n",
      "12\n",
      "Epoch: 044, Loss: 0.5371 Val: 0.8710 Test: 1.2647\n",
      "16\n",
      "12\n",
      "Epoch: 045, Loss: 0.5379 Val: 1.0493 Test: 1.2454\n",
      "16\n",
      "12\n",
      "Epoch: 046, Loss: 0.4019 Val: 1.1114 Test: 1.2156\n",
      "16\n",
      "12\n",
      "Epoch: 047, Loss: 0.5016 Val: 1.1447 Test: 1.1938\n",
      "16\n",
      "12\n",
      "Epoch: 048, Loss: 0.4126 Val: 1.1939 Test: 1.1790\n",
      "16\n",
      "12\n",
      "Epoch: 049, Loss: 0.4707 Val: 1.2303 Test: 1.1605\n",
      "16\n",
      "12\n",
      "Epoch: 050, Loss: 0.5116 Val: 1.2542 Test: 1.1605\n",
      "16\n",
      "12\n",
      "Epoch: 051, Loss: 0.3957 Val: 1.2914 Test: 1.1889\n",
      "16\n",
      "12\n",
      "Epoch: 052, Loss: 0.4186 Val: 1.2686 Test: 1.3106\n",
      "16\n",
      "12\n",
      "Epoch: 053, Loss: 0.3630 Val: 1.2864 Test: 1.3085\n",
      "16\n",
      "12\n",
      "Epoch: 054, Loss: 0.4261 Val: 1.2731 Test: 1.3177\n",
      "16\n",
      "12\n",
      "Epoch: 055, Loss: 0.3942 Val: 1.2095 Test: 1.2839\n",
      "16\n",
      "12\n",
      "Epoch: 056, Loss: 0.3605 Val: 1.1462 Test: 1.2588\n",
      "16\n",
      "12\n",
      "Epoch: 057, Loss: 0.4677 Val: 1.1916 Test: 1.2720\n",
      "16\n",
      "12\n",
      "Epoch: 058, Loss: 0.3493 Val: 1.2167 Test: 1.3370\n",
      "16\n",
      "12\n",
      "Epoch: 059, Loss: 0.6440 Val: 1.4263 Test: 1.1898\n",
      "16\n",
      "12\n",
      "Epoch: 060, Loss: 0.8602 Val: 1.4082 Test: 1.1246\n",
      "16\n",
      "12\n",
      "Epoch: 061, Loss: 0.8267 Val: 1.2393 Test: 1.2222\n",
      "16\n",
      "12\n",
      "Epoch: 062, Loss: 0.5999 Val: 1.1726 Test: 1.2240\n",
      "16\n",
      "12\n",
      "Epoch: 063, Loss: 0.3866 Val: 1.1764 Test: 1.2281\n",
      "16\n",
      "12\n",
      "Epoch: 064, Loss: 0.3767 Val: 1.1836 Test: 1.2116\n",
      "16\n",
      "12\n",
      "Epoch: 065, Loss: 0.3585 Val: 1.1833 Test: 1.1769\n",
      "16\n",
      "12\n",
      "Epoch: 066, Loss: 0.2973 Val: 1.1979 Test: 1.1389\n",
      "16\n",
      "12\n",
      "Epoch: 067, Loss: 0.3288 Val: 1.1907 Test: 1.0419\n",
      "16\n",
      "12\n",
      "Epoch: 068, Loss: 0.2829 Val: 1.1761 Test: 0.8210\n",
      "16\n",
      "12\n",
      "Epoch: 069, Loss: 0.3417 Val: 1.1407 Test: 0.8112\n",
      "16\n",
      "12\n",
      "Epoch: 070, Loss: 0.3450 Val: 1.1293 Test: 0.8210\n",
      "16\n",
      "12\n",
      "Epoch: 071, Loss: 0.3218 Val: 1.1222 Test: 0.8299\n",
      "16\n",
      "12\n",
      "Epoch: 072, Loss: 0.3598 Val: 1.0044 Test: 0.7762\n",
      "16\n",
      "12\n",
      "Epoch: 073, Loss: 0.2719 Val: 1.1206 Test: 0.7047\n",
      "16\n",
      "12\n",
      "Epoch: 074, Loss: 0.3152 Val: 1.1910 Test: 0.6646\n",
      "16\n",
      "12\n",
      "Epoch: 075, Loss: 0.3299 Val: 1.1823 Test: 0.6714\n",
      "16\n",
      "12\n",
      "Epoch: 076, Loss: 0.4127 Val: 1.1802 Test: 0.6584\n",
      "16\n",
      "12\n",
      "Epoch: 077, Loss: 0.3847 Val: 1.1854 Test: 0.6312\n",
      "16\n",
      "12\n",
      "Epoch: 078, Loss: 0.3587 Val: 1.1853 Test: 0.6177\n",
      "16\n",
      "12\n",
      "Epoch: 079, Loss: 0.3741 Val: 1.1922 Test: 0.5979\n",
      "16\n",
      "12\n",
      "Epoch: 080, Loss: 0.2383 Val: 1.1908 Test: 0.5899\n",
      "16\n",
      "12\n",
      "Epoch: 081, Loss: 0.3139 Val: 1.1890 Test: 0.5963\n",
      "16\n",
      "12\n",
      "Epoch: 082, Loss: 0.2828 Val: 1.2081 Test: 0.6008\n",
      "16\n",
      "12\n",
      "Epoch: 083, Loss: 0.2670 Val: 1.2954 Test: 0.6013\n",
      "16\n",
      "12\n",
      "Epoch: 084, Loss: 0.2982 Val: 1.3741 Test: 0.5820\n",
      "16\n",
      "12\n",
      "Epoch: 085, Loss: 0.3011 Val: 1.3456 Test: 0.5531\n",
      "16\n",
      "12\n",
      "Epoch: 086, Loss: 0.3030 Val: 1.2932 Test: 0.5377\n",
      "16\n",
      "12\n",
      "Epoch: 087, Loss: 0.2965 Val: 1.2510 Test: 0.5397\n",
      "16\n",
      "12\n",
      "Epoch: 088, Loss: 0.3071 Val: 1.2441 Test: 0.5604\n",
      "16\n",
      "12\n",
      "Epoch: 089, Loss: 0.2405 Val: 1.2452 Test: 0.5780\n",
      "16\n",
      "12\n",
      "Epoch: 090, Loss: 0.2585 Val: 1.2303 Test: 0.5900\n",
      "16\n",
      "12\n",
      "Epoch: 091, Loss: 0.2682 Val: 1.2025 Test: 0.5839\n",
      "16\n",
      "12\n",
      "Epoch: 092, Loss: 0.3248 Val: 1.2010 Test: 0.5708\n",
      "16\n",
      "12\n",
      "Epoch: 093, Loss: 0.2501 Val: 1.1976 Test: 0.5787\n",
      "16\n",
      "12\n",
      "Epoch: 094, Loss: 0.3391 Val: 1.1894 Test: 0.6051\n",
      "16\n",
      "12\n",
      "Epoch: 095, Loss: 0.2881 Val: 1.1759 Test: 0.6193\n",
      "16\n",
      "12\n",
      "Epoch: 096, Loss: 0.3447 Val: 1.1628 Test: 0.5895\n",
      "16\n",
      "12\n",
      "Epoch: 097, Loss: 0.2609 Val: 1.1536 Test: 0.5610\n",
      "16\n",
      "12\n",
      "Epoch: 098, Loss: 0.2968 Val: 1.1946 Test: 0.5248\n",
      "16\n",
      "12\n",
      "Epoch: 099, Loss: 0.2923 Val: 1.2135 Test: 0.5349\n",
      "16\n",
      "12\n",
      "Epoch: 100, Loss: 0.1956 Val: 1.2047 Test: 0.5634\n",
      "16\n",
      "12\n",
      "Epoch: 101, Loss: 0.3360 Val: 1.0986 Test: 0.5649\n",
      "16\n",
      "12\n",
      "Epoch: 102, Loss: 0.2240 Val: 0.9569 Test: 0.6001\n",
      "16\n",
      "12\n",
      "Epoch: 103, Loss: 0.1731 Val: 0.8992 Test: 0.6578\n",
      "16\n",
      "12\n",
      "Epoch: 104, Loss: 0.2140 Val: 0.8672 Test: 0.7188\n",
      "16\n",
      "12\n",
      "Epoch: 105, Loss: 0.3975 Val: 0.9347 Test: 0.7267\n",
      "16\n",
      "12\n",
      "Epoch: 106, Loss: 0.2828 Val: 1.1263 Test: 0.7486\n",
      "16\n",
      "12\n",
      "Epoch: 107, Loss: 0.2692 Val: 1.2758 Test: 0.7507\n",
      "16\n",
      "12\n",
      "Epoch: 108, Loss: 0.2788 Val: 1.3523 Test: 0.7902\n",
      "16\n",
      "12\n",
      "Epoch: 109, Loss: 0.1925 Val: 1.3988 Test: 0.8238\n",
      "16\n",
      "12\n",
      "Epoch: 110, Loss: 0.2823 Val: 1.4329 Test: 0.8433\n",
      "16\n",
      "12\n",
      "Epoch: 111, Loss: 0.1402 Val: 1.4551 Test: 0.8571\n",
      "16\n",
      "12\n",
      "Epoch: 112, Loss: 0.3520 Val: 1.4717 Test: 0.8568\n",
      "16\n",
      "12\n",
      "Epoch: 113, Loss: 0.2397 Val: 1.4801 Test: 0.8539\n",
      "16\n",
      "12\n",
      "Epoch: 114, Loss: 0.2600 Val: 1.4894 Test: 0.8457\n",
      "16\n",
      "12\n",
      "Epoch: 115, Loss: 0.3016 Val: 1.4836 Test: 0.8337\n",
      "16\n",
      "12\n",
      "Epoch: 116, Loss: 0.2713 Val: 1.4535 Test: 0.8430\n",
      "16\n",
      "12\n",
      "Epoch: 117, Loss: 0.2131 Val: 1.4180 Test: 0.8587\n",
      "16\n",
      "12\n",
      "Epoch: 118, Loss: 0.2655 Val: 1.3856 Test: 0.8695\n",
      "16\n",
      "12\n",
      "Epoch: 119, Loss: 0.2924 Val: 1.3328 Test: 0.8731\n",
      "16\n",
      "12\n",
      "Epoch: 120, Loss: 0.1983 Val: 1.3045 Test: 0.8694\n",
      "16\n",
      "12\n",
      "Epoch: 121, Loss: 0.2240 Val: 1.3100 Test: 0.8549\n",
      "16\n",
      "12\n",
      "Epoch: 122, Loss: 0.3008 Val: 1.3251 Test: 0.8524\n",
      "16\n",
      "12\n",
      "Epoch: 123, Loss: 0.2732 Val: 1.3234 Test: 0.8629\n",
      "16\n",
      "12\n",
      "Epoch: 124, Loss: 0.3273 Val: 1.3017 Test: 0.8317\n",
      "16\n",
      "12\n",
      "Epoch: 125, Loss: 0.2295 Val: 1.2858 Test: 0.8133\n",
      "16\n",
      "12\n",
      "Epoch: 126, Loss: 0.2343 Val: 1.2455 Test: 0.7982\n",
      "16\n",
      "12\n",
      "Epoch: 127, Loss: 0.2338 Val: 1.2337 Test: 0.7873\n",
      "16\n",
      "12\n",
      "Epoch: 128, Loss: 0.2523 Val: 1.2101 Test: 0.7771\n",
      "16\n",
      "12\n",
      "Epoch: 129, Loss: 0.1622 Val: 1.1842 Test: 0.7641\n",
      "16\n",
      "12\n",
      "Epoch: 130, Loss: 0.2862 Val: 1.1654 Test: 0.7527\n",
      "16\n",
      "12\n",
      "Epoch: 131, Loss: 0.2151 Val: 1.1496 Test: 0.7364\n",
      "16\n",
      "12\n",
      "Epoch: 132, Loss: 0.2270 Val: 1.1402 Test: 0.7162\n",
      "16\n",
      "12\n",
      "Epoch: 133, Loss: 0.2104 Val: 1.1457 Test: 0.7052\n",
      "16\n",
      "12\n",
      "Epoch: 134, Loss: 0.2594 Val: 1.1597 Test: 0.7126\n",
      "16\n",
      "12\n",
      "Epoch: 135, Loss: 0.2849 Val: 1.1723 Test: 0.7218\n",
      "16\n",
      "12\n",
      "Epoch: 136, Loss: 0.2321 Val: 1.1757 Test: 0.7418\n",
      "16\n",
      "12\n",
      "Epoch: 137, Loss: 0.2967 Val: 1.1797 Test: 0.7684\n",
      "16\n",
      "12\n",
      "Epoch: 138, Loss: 0.2567 Val: 1.1801 Test: 0.7812\n",
      "16\n",
      "12\n",
      "Epoch: 139, Loss: 0.1753 Val: 1.1841 Test: 0.7853\n",
      "16\n",
      "12\n",
      "Epoch: 140, Loss: 0.2726 Val: 1.1877 Test: 0.7920\n",
      "16\n",
      "12\n",
      "Epoch: 141, Loss: 0.1809 Val: 1.1983 Test: 0.8092\n",
      "16\n",
      "12\n",
      "Epoch: 142, Loss: 0.1860 Val: 1.0232 Test: 0.8388\n",
      "16\n",
      "12\n",
      "Epoch: 143, Loss: 0.2848 Val: 0.7957 Test: 0.8652\n",
      "16\n",
      "12\n",
      "Epoch: 144, Loss: 0.2674 Val: 0.7906 Test: 0.8783\n",
      "16\n",
      "12\n",
      "Epoch: 145, Loss: 0.2391 Val: 0.8121 Test: 0.8842\n",
      "16\n",
      "12\n",
      "Epoch: 146, Loss: 0.1866 Val: 0.8233 Test: 0.8817\n",
      "16\n",
      "12\n",
      "Epoch: 147, Loss: 0.1995 Val: 0.8399 Test: 0.8819\n",
      "16\n",
      "12\n",
      "Epoch: 148, Loss: 0.2459 Val: 0.8470 Test: 0.8891\n",
      "16\n",
      "12\n",
      "Epoch: 149, Loss: 0.1719 Val: 0.8506 Test: 0.8891\n",
      "16\n",
      "12\n",
      "Epoch: 150, Loss: 0.1460 Val: 0.8615 Test: 0.8759\n",
      "16\n",
      "12\n",
      "Epoch: 151, Loss: 0.1636 Val: 0.8711 Test: 0.8663\n",
      "16\n",
      "12\n",
      "Epoch: 152, Loss: 0.1900 Val: 0.8699 Test: 0.8562\n",
      "16\n",
      "12\n",
      "Epoch: 153, Loss: 0.2096 Val: 0.8591 Test: 0.8585\n",
      "16\n",
      "12\n",
      "Epoch: 154, Loss: 0.3036 Val: 0.8447 Test: 0.8715\n",
      "16\n",
      "12\n",
      "Epoch: 155, Loss: 0.1131 Val: 0.8383 Test: 0.8867\n",
      "16\n",
      "12\n",
      "Epoch: 156, Loss: 0.3023 Val: 0.8338 Test: 0.8973\n",
      "16\n",
      "12\n",
      "Epoch: 157, Loss: 0.2616 Val: 0.8283 Test: 0.9051\n",
      "16\n",
      "12\n",
      "Epoch: 158, Loss: 0.1703 Val: 0.8280 Test: 0.9200\n",
      "16\n",
      "12\n",
      "Epoch: 159, Loss: 0.2066 Val: 0.8319 Test: 0.9242\n",
      "16\n",
      "12\n",
      "Epoch: 160, Loss: 0.2558 Val: 0.8402 Test: 0.9308\n",
      "16\n",
      "12\n",
      "Epoch: 161, Loss: 0.1848 Val: 0.8417 Test: 0.9322\n",
      "16\n",
      "12\n",
      "Epoch: 162, Loss: 0.2385 Val: 0.8432 Test: 0.9241\n",
      "16\n",
      "12\n",
      "Epoch: 163, Loss: 0.1647 Val: 0.8523 Test: 0.9109\n",
      "16\n",
      "12\n",
      "Epoch: 164, Loss: 0.1174 Val: 0.8565 Test: 0.8990\n",
      "16\n",
      "12\n",
      "Epoch: 165, Loss: 0.1291 Val: 0.8539 Test: 0.9000\n",
      "16\n",
      "12\n",
      "Epoch: 166, Loss: 0.1845 Val: 0.8349 Test: 0.9200\n",
      "16\n",
      "12\n",
      "Epoch: 167, Loss: 0.1746 Val: 0.8237 Test: 0.9373\n",
      "16\n",
      "12\n",
      "Epoch: 168, Loss: 0.1507 Val: 0.8241 Test: 0.9671\n",
      "16\n",
      "12\n",
      "Epoch: 169, Loss: 0.2565 Val: 0.8217 Test: 0.9609\n",
      "16\n",
      "12\n",
      "Epoch: 170, Loss: 0.2074 Val: 0.8185 Test: 0.9241\n",
      "16\n",
      "12\n",
      "Epoch: 171, Loss: 0.1997 Val: 0.8192 Test: 0.8854\n",
      "16\n",
      "12\n",
      "Epoch: 172, Loss: 0.1580 Val: 0.8234 Test: 0.8552\n",
      "16\n",
      "12\n",
      "Epoch: 173, Loss: 0.2099 Val: 0.8155 Test: 0.8391\n",
      "16\n",
      "12\n",
      "Epoch: 174, Loss: 0.1054 Val: 0.8174 Test: 0.8345\n",
      "16\n",
      "12\n",
      "Epoch: 175, Loss: 0.1544 Val: 0.8189 Test: 0.8688\n",
      "16\n",
      "12\n",
      "Epoch: 176, Loss: 0.2972 Val: 0.8279 Test: 0.9054\n",
      "16\n",
      "12\n",
      "Epoch: 177, Loss: 0.1974 Val: 0.8478 Test: 0.9640\n",
      "16\n",
      "12\n",
      "Epoch: 178, Loss: 0.1337 Val: 0.8609 Test: 1.0154\n",
      "16\n",
      "12\n",
      "Epoch: 179, Loss: 0.5399 Val: 1.1262 Test: 1.2499\n",
      "16\n",
      "12\n",
      "Epoch: 180, Loss: 0.5384 Val: 1.1084 Test: 1.2587\n",
      "16\n",
      "12\n",
      "Epoch: 181, Loss: 0.4684 Val: 1.0500 Test: 1.2060\n",
      "16\n",
      "12\n",
      "Epoch: 182, Loss: 0.5556 Val: 0.9036 Test: 1.0069\n",
      "16\n",
      "12\n",
      "Epoch: 183, Loss: 0.2852 Val: 0.9276 Test: 0.8073\n",
      "16\n",
      "12\n",
      "Epoch: 184, Loss: 0.1856 Val: 0.9260 Test: 0.8110\n",
      "16\n",
      "12\n",
      "Epoch: 185, Loss: 0.2957 Val: 0.9375 Test: 0.7985\n",
      "16\n",
      "12\n",
      "Epoch: 186, Loss: 0.2338 Val: 0.9410 Test: 0.7904\n",
      "16\n",
      "12\n",
      "Epoch: 187, Loss: 0.3168 Val: 0.9263 Test: 0.7796\n",
      "16\n",
      "12\n",
      "Epoch: 188, Loss: 0.2185 Val: 0.9115 Test: 0.7602\n",
      "16\n",
      "12\n",
      "Epoch: 189, Loss: 0.2413 Val: 0.9017 Test: 0.7413\n",
      "16\n",
      "12\n",
      "Epoch: 190, Loss: 0.1894 Val: 0.8910 Test: 0.7905\n",
      "16\n",
      "12\n",
      "Epoch: 191, Loss: 0.2037 Val: 0.8847 Test: 0.8871\n",
      "16\n",
      "12\n",
      "Epoch: 192, Loss: 0.2004 Val: 0.8716 Test: 0.9458\n",
      "16\n",
      "12\n",
      "Epoch: 193, Loss: 0.2631 Val: 0.8719 Test: 0.9882\n",
      "16\n",
      "12\n",
      "Epoch: 194, Loss: 0.2932 Val: 0.8686 Test: 0.9988\n",
      "16\n",
      "12\n",
      "Epoch: 195, Loss: 0.2445 Val: 0.8677 Test: 0.9683\n",
      "16\n",
      "12\n",
      "Epoch: 196, Loss: 0.2890 Val: 0.8596 Test: 0.9343\n",
      "16\n",
      "12\n",
      "Epoch: 197, Loss: 0.2585 Val: 0.8400 Test: 0.8896\n",
      "16\n",
      "12\n",
      "Epoch: 198, Loss: 0.1715 Val: 0.8247 Test: 0.8568\n",
      "16\n",
      "12\n",
      "Epoch: 199, Loss: 0.1358 Val: 0.8122 Test: 0.8333\n",
      "rip2\n",
      "\n",
      "torch.Size([1428, 115])\n",
      "{'name': 'rip2', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa610364af0>, 'pre_filter': None, '_indices': [21, 41, 3, 11, 28, 18, 42, 50, 24, 22, 47, 46, 23, 7, 13, 51, 44, 4, 2, 39, 34, 31, 35, 48, 1, 29, 12, 49, 16, 5, 37, 19, 33, 8, 32, 36, 27, 45, 10, 30, 43, 6, 26, 14, 0, 17, 15, 52, 38, 9, 40, 20, 25], 'data': Data(x=[1428, 115], edge_index=[2, 3086], edge_attr=[3086, 7], y=[53, 1], smiles=[53]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   26,   52,   79,  107,  133,  159,  188,  215,  241,  269,  295,\n",
      "         322,  345,  372,  400,  425,  451,  477,  505,  530,  556,  580,  609,\n",
      "         636,  664,  694,  721,  751,  781,  806,  832,  857,  884,  903,  932,\n",
      "         959,  988, 1016, 1044, 1072, 1099, 1124, 1151, 1176, 1201, 1229, 1263,\n",
      "        1290, 1317, 1345, 1373, 1400, 1428]), 'edge_index': tensor([   0,   56,  112,  172,  234,  290,  346,  408,  466,  522,  582,  638,\n",
      "         698,  748,  808,  868,  922,  978, 1034, 1094, 1148, 1204, 1256, 1318,\n",
      "        1376, 1436, 1500, 1560, 1624, 1688, 1742, 1798, 1852, 1912, 1954, 2016,\n",
      "        2074, 2136, 2196, 2256, 2316, 2374, 2428, 2486, 2540, 2594, 2654, 2728,\n",
      "        2786, 2844, 2906, 2968, 3026, 3086]), 'edge_attr': tensor([   0,   56,  112,  172,  234,  290,  346,  408,  466,  522,  582,  638,\n",
      "         698,  748,  808,  868,  922,  978, 1034, 1094, 1148, 1204, 1256, 1318,\n",
      "        1376, 1436, 1500, 1560, 1624, 1688, 1742, 1798, 1852, 1912, 1954, 2016,\n",
      "        2074, 2136, 2196, 2256, 2316, 2374, 2428, 2486, 2540, 2594, 2654, 2728,\n",
      "        2786, 2844, 2906, 2968, 3026, 3086]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53])}), '_data_list': None}\n",
      "minv: 5.329999923706055\n",
      "maxv: 8.699999809265137\n",
      "emb_dim: 300\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 000, Loss: 0.7361 Val: 1.4256 Test: 2.2566\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 001, Loss: 0.7714 Val: 1.4045 Test: 2.2227\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 002, Loss: 0.8721 Val: 1.3720 Test: 2.1900\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 003, Loss: 0.6523 Val: 1.3486 Test: 2.1773\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 004, Loss: 0.6608 Val: 1.3197 Test: 2.1083\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 005, Loss: 0.7300 Val: 1.2926 Test: 2.0772\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 006, Loss: 0.6788 Val: 1.2623 Test: 2.0495\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 007, Loss: 0.7483 Val: 1.2527 Test: 2.0449\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 008, Loss: 0.6987 Val: 1.2565 Test: 2.0163\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 009, Loss: 0.6866 Val: 1.2539 Test: 1.9968\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 010, Loss: 0.6977 Val: 1.2216 Test: 1.9564\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 011, Loss: 0.6568 Val: 1.1970 Test: 1.9269\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 012, Loss: 0.6309 Val: 1.1782 Test: 1.9057\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 013, Loss: 0.6217 Val: 1.1576 Test: 1.8795\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 014, Loss: 0.6093 Val: 1.1457 Test: 1.8562\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 015, Loss: 0.6155 Val: 1.1000 Test: 1.8166\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 016, Loss: 0.6148 Val: 1.0569 Test: 1.7488\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 017, Loss: 0.5493 Val: 1.0317 Test: 1.6981\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 018, Loss: 0.6595 Val: 0.9871 Test: 1.6523\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 019, Loss: 0.6046 Val: 0.9616 Test: 1.6214\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 020, Loss: 0.5938 Val: 0.9446 Test: 1.5852\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 021, Loss: 0.5469 Val: 0.9254 Test: 1.5247\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 022, Loss: 0.5570 Val: 0.8969 Test: 1.4853\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 023, Loss: 0.5115 Val: 0.9147 Test: 1.4524\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 024, Loss: 0.5515 Val: 0.8929 Test: 1.4113\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 025, Loss: 0.5108 Val: 0.8778 Test: 1.3639\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 026, Loss: 0.4748 Val: 0.8778 Test: 1.3432\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 027, Loss: 0.4488 Val: 0.8694 Test: 1.3107\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 028, Loss: 0.4365 Val: 0.8710 Test: 1.2825\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 029, Loss: 0.4624 Val: 0.8430 Test: 1.1906\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 030, Loss: 0.4474 Val: 0.8065 Test: 1.1195\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 031, Loss: 0.4405 Val: 0.7872 Test: 1.0716\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 032, Loss: 0.4131 Val: 0.8075 Test: 1.0383\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 033, Loss: 0.4186 Val: 0.8158 Test: 0.9890\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 034, Loss: 0.4272 Val: 0.8093 Test: 0.9194\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 035, Loss: 0.4323 Val: 0.8257 Test: 0.8852\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 036, Loss: 0.3931 Val: 0.9128 Test: 0.8450\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 037, Loss: 0.3876 Val: 0.9334 Test: 0.7817\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 038, Loss: 0.3789 Val: 0.9138 Test: 0.7549\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 039, Loss: 0.3939 Val: 0.8888 Test: 0.7334\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 040, Loss: 0.3636 Val: 0.8728 Test: 0.7301\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 041, Loss: 0.3620 Val: 0.8550 Test: 0.7347\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 042, Loss: 0.3153 Val: 0.8379 Test: 0.7323\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 043, Loss: 0.3566 Val: 0.8437 Test: 0.7805\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 044, Loss: 0.4831 Val: 0.8478 Test: 0.7213\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 045, Loss: 0.3724 Val: 0.8815 Test: 0.6675\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 046, Loss: 0.3754 Val: 0.9226 Test: 0.6598\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 047, Loss: 0.3199 Val: 0.9645 Test: 0.6463\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 048, Loss: 0.3346 Val: 0.9586 Test: 0.6553\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 049, Loss: 0.3898 Val: 0.9860 Test: 0.6344\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 050, Loss: 0.4146 Val: 0.9892 Test: 0.6260\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 051, Loss: 0.4405 Val: 0.9918 Test: 0.6271\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 052, Loss: 0.3918 Val: 0.9893 Test: 0.6340\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 053, Loss: 0.3505 Val: 1.0132 Test: 0.6395\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 054, Loss: 0.3498 Val: 0.9870 Test: 0.6384\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 055, Loss: 0.3048 Val: 0.9489 Test: 0.6307\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 056, Loss: 0.3483 Val: 0.8942 Test: 0.6625\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 057, Loss: 0.3355 Val: 0.8683 Test: 0.6490\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 058, Loss: 0.2998 Val: 0.9409 Test: 0.6350\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 059, Loss: 0.3882 Val: 0.9668 Test: 0.6312\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 060, Loss: 0.3609 Val: 0.9739 Test: 0.6779\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 061, Loss: 0.3672 Val: 0.9624 Test: 0.7086\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 062, Loss: 0.3337 Val: 0.9358 Test: 0.7574\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 063, Loss: 0.3449 Val: 0.8952 Test: 0.6038\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 064, Loss: 0.3738 Val: 0.8785 Test: 0.6380\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 065, Loss: 0.3971 Val: 0.9010 Test: 0.6963\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 066, Loss: 0.3211 Val: 0.9710 Test: 0.6896\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 067, Loss: 0.3299 Val: 1.0273 Test: 0.6374\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 068, Loss: 0.3057 Val: 1.0675 Test: 0.6140\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 069, Loss: 0.2950 Val: 1.0671 Test: 0.5817\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 070, Loss: 0.2870 Val: 1.0380 Test: 0.5656\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 071, Loss: 0.2891 Val: 1.0189 Test: 0.5617\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 072, Loss: 0.2844 Val: 1.0185 Test: 0.5704\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 073, Loss: 0.2656 Val: 1.0235 Test: 0.5731\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 074, Loss: 0.3237 Val: 1.0325 Test: 0.5748\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 075, Loss: 0.3412 Val: 1.0381 Test: 0.6010\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 076, Loss: 0.4239 Val: 1.0736 Test: 0.5511\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 077, Loss: 0.2983 Val: 1.0777 Test: 0.5084\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 078, Loss: 0.3261 Val: 1.0974 Test: 0.5436\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 079, Loss: 0.3851 Val: 1.1084 Test: 0.6190\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 080, Loss: 0.3107 Val: 1.1294 Test: 0.6820\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 081, Loss: 0.3204 Val: 1.1323 Test: 0.6704\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 082, Loss: 0.3946 Val: 1.1097 Test: 0.6066\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 083, Loss: 0.2486 Val: 1.0710 Test: 0.5504\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 084, Loss: 0.3023 Val: 1.0659 Test: 0.5438\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 085, Loss: 0.3242 Val: 1.0926 Test: 0.6128\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 086, Loss: 0.3526 Val: 1.0943 Test: 0.6351\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 087, Loss: 0.3571 Val: 1.0931 Test: 0.5575\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 088, Loss: 0.2673 Val: 1.0903 Test: 0.5183\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 089, Loss: 0.3078 Val: 1.0788 Test: 0.5121\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 090, Loss: 0.2050 Val: 1.0780 Test: 0.5383\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 091, Loss: 0.4131 Val: 1.0872 Test: 0.5871\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 092, Loss: 0.3106 Val: 1.1233 Test: 0.5699\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 093, Loss: 0.2074 Val: 1.1367 Test: 0.5549\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 094, Loss: 0.2517 Val: 1.1450 Test: 0.5570\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 095, Loss: 0.3094 Val: 1.1586 Test: 0.5544\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 096, Loss: 0.3004 Val: 1.1239 Test: 0.5399\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 097, Loss: 0.2707 Val: 1.0606 Test: 0.5562\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 098, Loss: 0.3277 Val: 1.0157 Test: 0.5741\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 099, Loss: 0.3178 Val: 1.0156 Test: 0.6001\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 100, Loss: 0.5420 Val: 0.9936 Test: 0.4651\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 101, Loss: 0.4682 Val: 0.9250 Test: 0.5714\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 102, Loss: 0.2697 Val: 1.0265 Test: 0.7002\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 103, Loss: 0.3181 Val: 1.1500 Test: 0.6519\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 104, Loss: 0.2967 Val: 1.2231 Test: 0.5742\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 105, Loss: 0.3519 Val: 1.2329 Test: 0.5554\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 106, Loss: 0.3287 Val: 1.1656 Test: 0.6277\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 107, Loss: 0.3771 Val: 1.0979 Test: 0.7196\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 108, Loss: 0.2631 Val: 1.0169 Test: 0.7539\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 109, Loss: 0.3167 Val: 1.1415 Test: 0.7948\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 110, Loss: 0.4541 Val: 1.1421 Test: 0.7254\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 111, Loss: 0.3126 Val: 1.1177 Test: 0.6581\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 112, Loss: 0.3992 Val: 1.0512 Test: 0.5335\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 113, Loss: 0.3534 Val: 1.0049 Test: 0.4708\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 114, Loss: 0.5353 Val: 1.2032 Test: 0.8686\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 115, Loss: 0.4175 Val: 1.3762 Test: 0.9278\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 116, Loss: 0.3735 Val: 1.4474 Test: 0.8365\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 117, Loss: 0.3572 Val: 1.4296 Test: 0.9110\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 118, Loss: 0.3714 Val: 1.1923 Test: 0.8480\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 119, Loss: 0.3420 Val: 1.1432 Test: 0.7023\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 120, Loss: 0.3193 Val: 1.1001 Test: 0.7046\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 121, Loss: 0.3037 Val: 1.1062 Test: 0.5875\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 122, Loss: 0.2303 Val: 1.1527 Test: 0.5526\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 123, Loss: 0.4120 Val: 1.1929 Test: 0.4994\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 124, Loss: 0.2815 Val: 1.2117 Test: 0.4871\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 125, Loss: 0.3839 Val: 1.2268 Test: 0.4975\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 126, Loss: 0.2947 Val: 1.1575 Test: 0.5622\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 127, Loss: 0.3457 Val: 1.1278 Test: 0.6595\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 128, Loss: 0.3289 Val: 1.1346 Test: 0.5847\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 129, Loss: 0.2377 Val: 1.1440 Test: 0.4486\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 130, Loss: 0.3954 Val: 1.1703 Test: 0.3956\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 131, Loss: 0.3098 Val: 1.1826 Test: 0.3816\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 132, Loss: 0.4541 Val: 1.1920 Test: 0.4109\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 133, Loss: 0.3295 Val: 1.2039 Test: 0.4842\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 134, Loss: 0.2171 Val: 1.2028 Test: 0.5473\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 135, Loss: 0.3700 Val: 1.2014 Test: 0.5765\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 136, Loss: 0.2757 Val: 1.2070 Test: 0.5841\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 137, Loss: 0.3215 Val: 1.2168 Test: 0.5864\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 138, Loss: 0.3012 Val: 1.2604 Test: 0.5176\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 139, Loss: 0.3378 Val: 1.3264 Test: 0.5088\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 140, Loss: 0.2806 Val: 1.3351 Test: 0.5207\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 141, Loss: 0.2939 Val: 1.2901 Test: 0.5600\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 142, Loss: 0.2849 Val: 1.2107 Test: 0.6312\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 143, Loss: 0.3250 Val: 1.1372 Test: 0.6852\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 144, Loss: 0.2670 Val: 1.0533 Test: 0.6867\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 145, Loss: 0.2535 Val: 1.0024 Test: 0.5846\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 146, Loss: 0.2679 Val: 0.9792 Test: 0.5193\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 147, Loss: 0.3420 Val: 0.9751 Test: 0.5263\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 148, Loss: 0.2710 Val: 0.9756 Test: 0.5526\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 149, Loss: 0.3482 Val: 1.0164 Test: 0.5437\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 150, Loss: 0.2896 Val: 1.1270 Test: 0.5799\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 151, Loss: 0.2843 Val: 1.2479 Test: 0.8549\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 152, Loss: 0.2548 Val: 1.3072 Test: 0.9277\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 153, Loss: 0.2942 Val: 1.3418 Test: 0.9263\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 154, Loss: 0.3184 Val: 1.3226 Test: 0.8846\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 155, Loss: 0.2889 Val: 1.3121 Test: 0.6365\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 156, Loss: 0.2912 Val: 1.2924 Test: 0.6699\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 157, Loss: 0.3223 Val: 1.2599 Test: 0.6584\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 158, Loss: 0.4252 Val: 1.2223 Test: 0.6043\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 159, Loss: 0.3201 Val: 1.1903 Test: 0.5121\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 160, Loss: 0.2181 Val: 1.1844 Test: 0.4967\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 161, Loss: 0.3260 Val: 1.1833 Test: 0.5446\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 162, Loss: 0.2802 Val: 1.1779 Test: 0.5980\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 163, Loss: 0.4266 Val: 1.1985 Test: 0.5817\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 164, Loss: 0.2087 Val: 1.2220 Test: 0.5763\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 165, Loss: 0.2613 Val: 1.2087 Test: 0.6089\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 166, Loss: 0.3525 Val: 1.2321 Test: 0.6227\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 167, Loss: 0.2513 Val: 1.2366 Test: 0.6055\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 168, Loss: 0.2839 Val: 1.2711 Test: 0.5307\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 169, Loss: 0.2998 Val: 1.3038 Test: 0.5003\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 170, Loss: 0.3078 Val: 1.2943 Test: 0.5095\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 171, Loss: 0.3675 Val: 1.2382 Test: 0.5183\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 172, Loss: 0.3444 Val: 1.1621 Test: 0.5855\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 173, Loss: 0.2581 Val: 1.1100 Test: 0.6771\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 174, Loss: 0.2719 Val: 1.1095 Test: 0.6869\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 175, Loss: 0.2977 Val: 1.1684 Test: 0.6377\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 176, Loss: 0.2026 Val: 1.2233 Test: 0.6415\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 177, Loss: 0.3501 Val: 1.2401 Test: 0.6622\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 178, Loss: 0.2266 Val: 1.2139 Test: 0.6760\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 179, Loss: 0.1829 Val: 1.1766 Test: 0.7046\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 180, Loss: 0.3992 Val: 1.1415 Test: 0.6985\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 181, Loss: 0.2934 Val: 1.1433 Test: 0.6766\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 182, Loss: 0.2676 Val: 1.1437 Test: 0.6674\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 183, Loss: 0.3212 Val: 1.1486 Test: 0.6251\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 184, Loss: 0.2913 Val: 1.1573 Test: 0.5647\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 185, Loss: 0.2772 Val: 1.1239 Test: 0.5558\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 186, Loss: 0.3250 Val: 1.0821 Test: 0.6029\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 187, Loss: 0.2462 Val: 1.0540 Test: 0.6819\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 188, Loss: 0.3351 Val: 1.0483 Test: 0.6466\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 189, Loss: 0.3441 Val: 1.0973 Test: 0.5757\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 190, Loss: 0.1715 Val: 1.1534 Test: 0.5312\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 191, Loss: 0.1565 Val: 1.2037 Test: 0.5188\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 192, Loss: 0.2659 Val: 1.2286 Test: 0.5943\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 193, Loss: 0.2457 Val: 1.2115 Test: 0.6716\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 194, Loss: 0.2794 Val: 1.1851 Test: 0.6984\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 195, Loss: 0.2512 Val: 1.1753 Test: 0.6870\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 196, Loss: 0.2210 Val: 1.1639 Test: 0.6401\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 197, Loss: 0.3498 Val: 1.1430 Test: 0.6246\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 198, Loss: 0.2394 Val: 1.1220 Test: 0.6032\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 199, Loss: 0.2101 Val: 1.1083 Test: 0.5140\n",
      "pkci\n",
      "\n",
      "torch.Size([1270, 115])\n",
      "{'name': 'pkci', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa610377ca0>, 'pre_filter': None, '_indices': [53, 25, 35, 37, 33, 36, 61, 49, 9, 50, 41, 58, 27, 43, 40, 11, 7, 21, 15, 14, 16, 8, 12, 29, 52, 20, 38, 2, 18, 3, 60, 31, 42, 10, 55, 22, 46, 1, 45, 24, 5, 28, 51, 17, 56, 23, 48, 13, 47, 59, 4, 34, 19, 6, 57, 30, 32, 0, 26, 44, 39, 54], 'data': Data(x=[1270, 115], edge_index=[2, 2870], edge_attr=[2870, 7], y=[62, 1], smiles=[62]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   10,   21,   32,   47,   57,   67,   78,   92,  104,  116,  128,\n",
      "         144,  158,  172,  186,  201,  219,  234,  253,  271,  290,  309,  327,\n",
      "         345,  364,  383,  405,  429,  453,  477,  502,  527,  553,  579,  607,\n",
      "         636,  665,  694,  723,  752,  781,  810,  842,  872,  902,  933,  965,\n",
      "         992, 1011, 1029, 1049, 1066, 1091, 1107, 1125, 1141, 1169, 1185, 1207,\n",
      "        1235, 1254, 1270]), 'edge_index': tensor([   0,   22,   46,   70,  102,  124,  146,  170,  200,  226,  252,  276,\n",
      "         310,  338,  366,  396,  430,  470,  504,  548,  590,  634,  678,  720,\n",
      "         762,  806,  850,  902,  958, 1014, 1070, 1128, 1186, 1246, 1306, 1370,\n",
      "        1438, 1506, 1574, 1642, 1710, 1778, 1846, 1920, 1990, 2060, 2132, 2206,\n",
      "        2270, 2312, 2350, 2392, 2428, 2482, 2516, 2554, 2588, 2650, 2684, 2732,\n",
      "        2794, 2836, 2870]), 'edge_attr': tensor([   0,   22,   46,   70,  102,  124,  146,  170,  200,  226,  252,  276,\n",
      "         310,  338,  366,  396,  430,  470,  504,  548,  590,  634,  678,  720,\n",
      "         762,  806,  850,  902,  958, 1014, 1070, 1128, 1186, 1246, 1306, 1370,\n",
      "        1438, 1506, 1574, 1642, 1710, 1778, 1846, 1920, 1990, 2060, 2132, 2206,\n",
      "        2270, 2312, 2350, 2392, 2428, 2482, 2516, 2554, 2588, 2650, 2684, 2732,\n",
      "        2794, 2836, 2870]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62])}), '_data_list': None}\n",
      "minv: 2.6544301509857178\n",
      "maxv: 8.568635940551758\n",
      "emb_dim: 300\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 000, Loss: 0.7584 Val: 3.0538 Test: 2.0869\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 001, Loss: 0.6852 Val: 3.0110 Test: 2.0615\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 002, Loss: 0.6899 Val: 2.9881 Test: 2.0379\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 003, Loss: 0.7122 Val: 2.9076 Test: 1.9996\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 004, Loss: 0.7147 Val: 2.8961 Test: 2.0052\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 005, Loss: 0.6741 Val: 2.8633 Test: 1.9873\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 006, Loss: 0.5811 Val: 2.8353 Test: 1.9597\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 007, Loss: 0.5249 Val: 2.8148 Test: 1.9344\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 008, Loss: 0.6926 Val: 2.7741 Test: 1.9242\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 009, Loss: 0.5784 Val: 2.7205 Test: 1.9055\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 010, Loss: 0.5992 Val: 2.7029 Test: 1.8744\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 011, Loss: 0.5897 Val: 2.7381 Test: 1.8909\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 012, Loss: 0.6383 Val: 2.7261 Test: 1.8891\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 013, Loss: 0.7220 Val: 2.7056 Test: 1.8746\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 014, Loss: 0.7022 Val: 2.6731 Test: 1.8468\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 015, Loss: 0.6382 Val: 2.6346 Test: 1.8307\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 016, Loss: 0.6170 Val: 2.5895 Test: 1.8165\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 017, Loss: 0.7542 Val: 2.5406 Test: 1.7762\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 018, Loss: 0.6548 Val: 2.4841 Test: 1.7212\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 019, Loss: 0.5766 Val: 2.4232 Test: 1.6683\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 020, Loss: 0.6370 Val: 2.3759 Test: 1.6415\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 021, Loss: 0.5579 Val: 2.3531 Test: 1.6491\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 022, Loss: 0.5874 Val: 2.3137 Test: 1.6390\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 023, Loss: 0.5489 Val: 2.2623 Test: 1.6021\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 024, Loss: 0.6234 Val: 2.1926 Test: 1.5789\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 025, Loss: 0.6370 Val: 2.1723 Test: 1.5565\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 026, Loss: 0.6627 Val: 2.1459 Test: 1.5959\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 027, Loss: 0.6287 Val: 2.1339 Test: 1.6010\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 028, Loss: 0.6112 Val: 2.1011 Test: 1.5879\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 029, Loss: 0.5330 Val: 2.0945 Test: 1.5878\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 030, Loss: 0.5392 Val: 2.0700 Test: 1.5919\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 031, Loss: 0.4915 Val: 1.9492 Test: 1.4747\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 032, Loss: 0.4387 Val: 1.8810 Test: 1.4082\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 033, Loss: 0.6176 Val: 1.8222 Test: 1.3583\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 034, Loss: 0.7138 Val: 1.8043 Test: 1.3710\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 035, Loss: 0.5157 Val: 1.8633 Test: 1.4461\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 036, Loss: 0.4555 Val: 1.8193 Test: 1.5643\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 037, Loss: 0.4701 Val: 1.8659 Test: 1.5851\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 038, Loss: 0.4649 Val: 1.8148 Test: 1.5701\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 039, Loss: 0.4539 Val: 1.7781 Test: 1.5563\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 040, Loss: 0.3981 Val: 1.7122 Test: 1.5240\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 041, Loss: 0.4247 Val: 1.7089 Test: 1.5595\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 042, Loss: 0.3871 Val: 1.6891 Test: 1.5881\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 043, Loss: 0.4271 Val: 1.7088 Test: 1.6012\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 044, Loss: 0.5088 Val: 1.6901 Test: 1.5924\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 045, Loss: 0.4045 Val: 1.6147 Test: 1.5662\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 046, Loss: 0.3985 Val: 1.5854 Test: 1.5591\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 047, Loss: 0.4268 Val: 1.6311 Test: 1.3898\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 048, Loss: 0.7543 Val: 1.5267 Test: 1.4202\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 049, Loss: 0.4579 Val: 1.4071 Test: 1.3898\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 050, Loss: 0.4966 Val: 1.3544 Test: 1.3827\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 051, Loss: 0.6743 Val: 1.3412 Test: 1.5417\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 052, Loss: 0.5090 Val: 1.4665 Test: 1.6629\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 053, Loss: 0.4947 Val: 1.4497 Test: 1.6922\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 054, Loss: 0.5052 Val: 1.4127 Test: 1.6369\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 055, Loss: 0.5279 Val: 1.3799 Test: 1.5838\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 056, Loss: 0.5048 Val: 1.3133 Test: 1.5414\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 057, Loss: 0.4992 Val: 1.3165 Test: 1.4948\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 058, Loss: 0.4587 Val: 1.3317 Test: 1.4395\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 059, Loss: 0.4807 Val: 1.3712 Test: 1.4434\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 060, Loss: 0.3855 Val: 1.3338 Test: 1.4153\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 061, Loss: 0.4119 Val: 1.3282 Test: 1.3744\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 062, Loss: 0.4736 Val: 1.3128 Test: 1.3915\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 063, Loss: 0.4032 Val: 1.3270 Test: 1.4030\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 064, Loss: 0.3712 Val: 1.3489 Test: 1.3693\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 065, Loss: 0.3863 Val: 1.4078 Test: 1.4183\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 066, Loss: 0.3837 Val: 1.5191 Test: 1.5177\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 067, Loss: 0.3790 Val: 1.5675 Test: 1.6422\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 068, Loss: 0.4033 Val: 1.5394 Test: 1.6609\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 069, Loss: 0.4644 Val: 1.4825 Test: 1.6170\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 070, Loss: 0.3944 Val: 1.3484 Test: 1.5408\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 071, Loss: 0.3036 Val: 1.2443 Test: 1.4913\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 072, Loss: 0.4648 Val: 1.1637 Test: 1.4948\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 073, Loss: 0.5401 Val: 1.1184 Test: 1.5095\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 074, Loss: 0.4250 Val: 1.0565 Test: 1.4234\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 075, Loss: 0.4034 Val: 1.3570 Test: 1.1850\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 076, Loss: 0.5288 Val: 1.0209 Test: 1.1739\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 077, Loss: 0.5928 Val: 1.1881 Test: 1.1203\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 078, Loss: 0.4604 Val: 1.2466 Test: 1.0524\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 079, Loss: 0.6330 Val: 1.2886 Test: 1.1047\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 080, Loss: 0.5085 Val: 1.5670 Test: 1.2491\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 081, Loss: 0.5392 Val: 1.4745 Test: 1.2440\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 082, Loss: 0.4941 Val: 0.9735 Test: 1.2113\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 083, Loss: 0.6270 Val: 0.9549 Test: 1.1487\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 084, Loss: 0.5247 Val: 0.9465 Test: 1.1389\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 085, Loss: 0.5152 Val: 0.9627 Test: 1.1542\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 086, Loss: 0.3925 Val: 0.9568 Test: 1.1826\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 087, Loss: 0.4428 Val: 1.0249 Test: 1.2326\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 088, Loss: 0.4249 Val: 1.1693 Test: 1.2631\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 089, Loss: 0.4240 Val: 1.2328 Test: 1.2821\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 090, Loss: 0.3911 Val: 1.1929 Test: 1.2791\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 091, Loss: 0.4111 Val: 1.1984 Test: 1.2739\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 092, Loss: 0.4018 Val: 1.1937 Test: 1.2239\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 093, Loss: 0.4375 Val: 1.1063 Test: 1.1825\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 094, Loss: 0.4347 Val: 1.0567 Test: 1.1503\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 095, Loss: 0.4560 Val: 0.9960 Test: 1.1483\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 096, Loss: 0.4596 Val: 1.0077 Test: 1.2438\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 097, Loss: 0.4489 Val: 1.0711 Test: 1.2772\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 098, Loss: 0.5000 Val: 1.0879 Test: 1.2741\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 099, Loss: 0.5522 Val: 0.9873 Test: 1.1542\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 100, Loss: 0.4331 Val: 0.9024 Test: 0.9426\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 101, Loss: 0.5469 Val: 0.9247 Test: 1.4565\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 102, Loss: 0.4500 Val: 0.9326 Test: 1.5240\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 103, Loss: 0.4697 Val: 0.9386 Test: 1.4675\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 104, Loss: 0.4232 Val: 0.9434 Test: 1.3968\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 105, Loss: 0.4484 Val: 0.8872 Test: 1.3795\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 106, Loss: 0.4889 Val: 0.8550 Test: 1.4114\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 107, Loss: 0.5019 Val: 0.8606 Test: 1.4062\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 108, Loss: 0.4483 Val: 0.8852 Test: 1.3943\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 109, Loss: 0.4367 Val: 0.9209 Test: 1.3864\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 110, Loss: 0.4573 Val: 1.0330 Test: 1.3566\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 111, Loss: 0.4170 Val: 0.9160 Test: 1.3680\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 112, Loss: 0.3430 Val: 0.9040 Test: 1.4318\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 113, Loss: 0.2907 Val: 0.9068 Test: 1.3942\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 114, Loss: 0.5325 Val: 0.9464 Test: 1.3550\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 115, Loss: 0.4160 Val: 1.1739 Test: 1.3284\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 116, Loss: 0.6878 Val: 1.3239 Test: 1.3240\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 117, Loss: 0.6864 Val: 1.0435 Test: 1.2992\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 118, Loss: 0.6184 Val: 0.9839 Test: 1.2574\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 119, Loss: 0.4035 Val: 0.9797 Test: 1.0905\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 120, Loss: 0.3800 Val: 0.9435 Test: 0.8958\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 121, Loss: 0.3431 Val: 0.8849 Test: 0.8822\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 122, Loss: 0.4853 Val: 0.9174 Test: 0.9351\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 123, Loss: 0.3785 Val: 1.0007 Test: 1.2035\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 124, Loss: 0.3952 Val: 1.0305 Test: 1.3513\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 125, Loss: 0.3854 Val: 1.0535 Test: 1.4078\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 126, Loss: 0.4167 Val: 1.0350 Test: 1.4248\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 127, Loss: 0.3680 Val: 0.9469 Test: 1.4113\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 128, Loss: 0.3269 Val: 1.0195 Test: 1.4269\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 129, Loss: 0.3653 Val: 1.0242 Test: 1.3913\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 130, Loss: 0.4066 Val: 0.9972 Test: 1.2741\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 131, Loss: 0.3680 Val: 0.9958 Test: 1.0255\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 132, Loss: 0.4520 Val: 0.9233 Test: 0.9901\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 133, Loss: 0.3674 Val: 0.9206 Test: 1.0249\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 134, Loss: 0.4001 Val: 0.8824 Test: 1.0880\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 135, Loss: 0.4492 Val: 0.8750 Test: 1.1240\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 136, Loss: 0.4224 Val: 0.9263 Test: 1.1362\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 137, Loss: 0.3626 Val: 0.8719 Test: 1.0937\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 138, Loss: 0.4173 Val: 0.7610 Test: 0.9712\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 139, Loss: 0.4086 Val: 0.7385 Test: 0.9059\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 140, Loss: 0.3897 Val: 0.7486 Test: 0.9055\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 141, Loss: 0.3716 Val: 0.7924 Test: 0.9217\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 142, Loss: 0.3046 Val: 0.8402 Test: 0.9433\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 143, Loss: 0.2740 Val: 0.8979 Test: 1.0421\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 144, Loss: 0.3014 Val: 0.9604 Test: 1.1128\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 145, Loss: 0.4202 Val: 0.8861 Test: 1.1322\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 146, Loss: 0.4801 Val: 0.8179 Test: 1.0855\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 147, Loss: 0.3929 Val: 0.7376 Test: 1.0032\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 148, Loss: 0.3518 Val: 0.7255 Test: 0.9633\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 149, Loss: 0.3541 Val: 0.8593 Test: 0.9530\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 150, Loss: 0.2916 Val: 0.9023 Test: 0.9928\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 151, Loss: 0.3406 Val: 0.8407 Test: 1.0547\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 152, Loss: 0.3188 Val: 0.8205 Test: 1.0485\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 153, Loss: 0.3254 Val: 0.8669 Test: 1.0340\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 154, Loss: 0.3577 Val: 0.9524 Test: 1.0328\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 155, Loss: 0.3322 Val: 0.9602 Test: 1.0507\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 156, Loss: 0.5035 Val: 0.9456 Test: 1.0499\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 157, Loss: 0.3491 Val: 0.9564 Test: 0.9935\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 158, Loss: 0.3123 Val: 0.8482 Test: 0.9779\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 159, Loss: 0.3423 Val: 0.8274 Test: 0.9596\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 160, Loss: 0.3173 Val: 0.7946 Test: 0.9582\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 161, Loss: 0.2631 Val: 0.7421 Test: 0.9589\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 162, Loss: 0.3193 Val: 0.6887 Test: 0.9453\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 163, Loss: 0.3190 Val: 0.6882 Test: 0.9238\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 164, Loss: 0.4696 Val: 0.7313 Test: 0.9014\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 165, Loss: 0.4159 Val: 0.9797 Test: 1.2272\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 166, Loss: 0.4402 Val: 0.9945 Test: 1.3190\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 167, Loss: 0.5111 Val: 1.0535 Test: 1.3382\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 168, Loss: 0.4631 Val: 1.1129 Test: 1.2650\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 169, Loss: 0.6304 Val: 0.8758 Test: 1.0269\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 170, Loss: 0.4785 Val: 0.8573 Test: 1.2740\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 171, Loss: 0.4720 Val: 0.8490 Test: 0.8541\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 172, Loss: 0.4599 Val: 0.7988 Test: 1.2628\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 173, Loss: 0.6988 Val: 0.7845 Test: 1.3541\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 174, Loss: 0.5950 Val: 0.7686 Test: 1.3641\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 175, Loss: 0.5778 Val: 0.7014 Test: 1.3818\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 176, Loss: 0.6279 Val: 0.6379 Test: 1.4171\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 177, Loss: 0.6224 Val: 0.8255 Test: 1.5066\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 178, Loss: 0.4855 Val: 0.9643 Test: 1.5541\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 179, Loss: 0.6055 Val: 1.0141 Test: 1.5994\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 180, Loss: 0.6373 Val: 1.0034 Test: 1.6248\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 181, Loss: 0.5547 Val: 0.7527 Test: 1.4265\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 182, Loss: 0.3963 Val: 0.5081 Test: 1.1145\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 183, Loss: 0.3641 Val: 0.7150 Test: 0.9219\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 184, Loss: 0.3838 Val: 0.9105 Test: 0.8282\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 185, Loss: 0.4770 Val: 0.8431 Test: 0.7838\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 186, Loss: 0.3893 Val: 0.6387 Test: 0.7450\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 187, Loss: 0.4696 Val: 0.5211 Test: 0.7308\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 188, Loss: 0.3425 Val: 0.4619 Test: 0.7344\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 189, Loss: 0.4407 Val: 0.4505 Test: 0.7486\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 190, Loss: 0.5097 Val: 0.5087 Test: 0.7654\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 191, Loss: 0.4521 Val: 0.6159 Test: 0.7717\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 192, Loss: 0.4837 Val: 0.7205 Test: 0.7560\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 193, Loss: 0.3597 Val: 0.7207 Test: 0.7612\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 194, Loss: 0.5959 Val: 0.7528 Test: 0.7731\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 195, Loss: 0.5448 Val: 0.7498 Test: 0.7953\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 196, Loss: 0.3232 Val: 0.6969 Test: 0.8016\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 197, Loss: 0.3126 Val: 0.6188 Test: 0.7971\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 198, Loss: 0.2819 Val: 0.5305 Test: 0.8416\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 199, Loss: 0.3592 Val: 0.5027 Test: 0.8919\n",
      "phgdh\n",
      "\n",
      "torch.Size([1831, 115])\n",
      "{'name': 'phgdh', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa61033d880>, 'pre_filter': None, '_indices': [20, 27, 43, 5, 39, 7, 64, 3, 37, 12, 54, 8, 23, 2, 61, 11, 63, 17, 32, 50, 26, 18, 60, 4, 1, 30, 62, 41, 56, 36, 57, 10, 59, 44, 21, 29, 55, 34, 66, 45, 13, 24, 49, 25, 0, 52, 53, 35, 28, 42, 38, 51, 15, 14, 16, 46, 19, 47, 65, 9, 48, 31, 22, 58, 40, 6, 33], 'data': Data(x=[1831, 115], edge_index=[2, 3954], edge_attr=[3954, 7], y=[67, 1], smiles=[67]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   30,   54,   85,  109,  133,  162,  191,  219,  247,  270,  300,\n",
      "         330,  356,  382,  412,  437,  461,  488,  516,  548,  574,  602,  625,\n",
      "         651,  677,  707,  733,  763,  790,  814,  841,  869,  895,  922,  952,\n",
      "         978, 1007, 1030, 1054, 1081, 1112, 1137, 1167, 1193, 1220, 1247, 1275,\n",
      "        1304, 1334, 1360, 1385, 1410, 1437, 1469, 1497, 1523, 1550, 1582, 1611,\n",
      "        1636, 1665, 1695, 1720, 1746, 1774, 1804, 1831]), 'edge_index': tensor([   0,   66,  118,  184,  236,  288,  352,  416,  478,  538,  588,  652,\n",
      "         716,  772,  828,  892,  946,  998, 1056, 1116, 1184, 1240, 1300, 1350,\n",
      "        1406, 1462, 1528, 1584, 1648, 1706, 1758, 1816, 1878, 1934, 1992, 2058,\n",
      "        2114, 2178, 2228, 2280, 2338, 2404, 2458, 2522, 2578, 2636, 2694, 2754,\n",
      "        2818, 2882, 2938, 2992, 3046, 3104, 3172, 3234, 3290, 3348, 3418, 3480,\n",
      "        3534, 3598, 3662, 3716, 3772, 3832, 3896, 3954]), 'edge_attr': tensor([   0,   66,  118,  184,  236,  288,  352,  416,  478,  538,  588,  652,\n",
      "         716,  772,  828,  892,  946,  998, 1056, 1116, 1184, 1240, 1300, 1350,\n",
      "        1406, 1462, 1528, 1584, 1648, 1706, 1758, 1816, 1878, 1934, 1992, 2058,\n",
      "        2114, 2178, 2228, 2280, 2338, 2404, 2458, 2522, 2578, 2636, 2694, 2754,\n",
      "        2818, 2882, 2938, 2992, 3046, 3104, 3172, 3234, 3290, 3348, 3418, 3480,\n",
      "        3534, 3598, 3662, 3716, 3772, 3832, 3896, 3954]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67])}), '_data_list': None}\n",
      "minv: 4.0\n",
      "maxv: 8.699999809265137\n",
      "emb_dim: 300\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 000, Loss: 0.7798 Val: 2.1945 Test: 2.3091\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 001, Loss: 0.6972 Val: 2.1421 Test: 2.2550\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 002, Loss: 0.6629 Val: 2.0918 Test: 2.2225\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 003, Loss: 0.6732 Val: 2.0265 Test: 2.1722\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 004, Loss: 0.6364 Val: 1.9760 Test: 2.1358\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 005, Loss: 0.6792 Val: 1.9230 Test: 2.0901\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 006, Loss: 0.6771 Val: 1.8741 Test: 2.0452\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 007, Loss: 0.6868 Val: 1.8192 Test: 1.9894\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 008, Loss: 0.6396 Val: 1.7688 Test: 1.9598\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 009, Loss: 0.6616 Val: 1.7173 Test: 1.9292\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 010, Loss: 0.6214 Val: 1.6980 Test: 1.8946\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 011, Loss: 0.6040 Val: 1.6617 Test: 1.8747\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 012, Loss: 0.5679 Val: 1.5829 Test: 1.8308\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 013, Loss: 0.6509 Val: 1.5309 Test: 1.7962\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 014, Loss: 0.6541 Val: 1.4919 Test: 1.7479\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 015, Loss: 0.6203 Val: 1.4943 Test: 1.7383\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 016, Loss: 0.5754 Val: 1.5080 Test: 1.7445\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 017, Loss: 0.5739 Val: 1.4283 Test: 1.6970\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 018, Loss: 0.5634 Val: 1.3133 Test: 1.6465\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 019, Loss: 0.5284 Val: 1.2763 Test: 1.6194\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 020, Loss: 0.5773 Val: 1.2583 Test: 1.5883\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 021, Loss: 0.6093 Val: 1.2030 Test: 1.5694\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 022, Loss: 0.5658 Val: 1.1265 Test: 1.5305\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 023, Loss: 0.5246 Val: 1.0817 Test: 1.4848\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 024, Loss: 0.5010 Val: 1.0332 Test: 1.4292\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 025, Loss: 0.5157 Val: 1.0035 Test: 1.4159\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 026, Loss: 0.5150 Val: 0.9757 Test: 1.4053\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 027, Loss: 0.5317 Val: 0.9130 Test: 1.3721\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 028, Loss: 0.5202 Val: 0.8688 Test: 1.3373\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 029, Loss: 0.5257 Val: 0.8516 Test: 1.3005\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 030, Loss: 0.4838 Val: 0.8275 Test: 1.2824\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 031, Loss: 0.5119 Val: 0.8356 Test: 1.2635\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 032, Loss: 0.4929 Val: 0.7989 Test: 1.2501\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 033, Loss: 0.4927 Val: 0.7881 Test: 1.2040\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 034, Loss: 0.5223 Val: 0.7287 Test: 1.2735\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 035, Loss: 0.5026 Val: 0.6619 Test: 1.2449\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 036, Loss: 0.4735 Val: 0.6604 Test: 1.2090\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 037, Loss: 0.4797 Val: 0.6721 Test: 1.1671\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 038, Loss: 0.4645 Val: 0.7068 Test: 1.1504\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 039, Loss: 0.4663 Val: 0.7284 Test: 1.1588\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 040, Loss: 0.5042 Val: 0.7852 Test: 1.2033\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 041, Loss: 0.5033 Val: 0.8377 Test: 1.0632\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 042, Loss: 0.5757 Val: 0.8541 Test: 1.0109\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 043, Loss: 0.4705 Val: 0.7700 Test: 1.0171\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 044, Loss: 0.4696 Val: 0.7950 Test: 1.1377\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 045, Loss: 0.4827 Val: 0.7852 Test: 1.0378\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 046, Loss: 0.4514 Val: 0.8163 Test: 0.9958\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 047, Loss: 0.4569 Val: 0.8756 Test: 1.0532\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 048, Loss: 0.5291 Val: 0.8995 Test: 1.0354\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 049, Loss: 0.5154 Val: 0.8923 Test: 1.0449\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 050, Loss: 0.4945 Val: 0.9356 Test: 1.0605\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 051, Loss: 0.4311 Val: 0.9478 Test: 0.9914\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 052, Loss: 0.4281 Val: 0.9230 Test: 0.9371\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 053, Loss: 0.4205 Val: 0.8613 Test: 0.9039\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 054, Loss: 0.4714 Val: 0.8994 Test: 0.8715\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 055, Loss: 0.4784 Val: 0.8763 Test: 0.8451\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 056, Loss: 0.4435 Val: 0.8553 Test: 0.8749\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 057, Loss: 0.6351 Val: 0.8367 Test: 0.9629\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 058, Loss: 0.6239 Val: 0.7391 Test: 1.0599\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 059, Loss: 0.4737 Val: 0.8099 Test: 0.9926\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 060, Loss: 0.4922 Val: 0.8238 Test: 0.9545\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 061, Loss: 0.4575 Val: 0.8531 Test: 0.9480\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 062, Loss: 0.3722 Val: 0.8224 Test: 0.9623\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 063, Loss: 0.4695 Val: 0.8610 Test: 0.9608\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 064, Loss: 0.4551 Val: 0.9160 Test: 0.9490\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 065, Loss: 0.4180 Val: 0.9826 Test: 0.8992\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 066, Loss: 0.5064 Val: 0.8141 Test: 1.0312\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 067, Loss: 0.4724 Val: 0.7826 Test: 1.1357\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 068, Loss: 0.4751 Val: 0.8545 Test: 1.1259\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 069, Loss: 0.4178 Val: 0.9249 Test: 0.9422\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 070, Loss: 0.4190 Val: 0.9716 Test: 0.9029\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 071, Loss: 0.4970 Val: 0.9369 Test: 0.8634\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 072, Loss: 0.4914 Val: 0.8950 Test: 0.8588\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 073, Loss: 0.4625 Val: 0.8990 Test: 0.8536\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 074, Loss: 0.4113 Val: 0.9463 Test: 0.8141\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 075, Loss: 0.4394 Val: 0.9299 Test: 0.7960\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 076, Loss: 0.4313 Val: 0.9103 Test: 0.8650\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 077, Loss: 0.4593 Val: 0.8920 Test: 0.8808\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 078, Loss: 0.4626 Val: 0.8446 Test: 0.8012\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 079, Loss: 0.4269 Val: 0.8525 Test: 0.8612\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 080, Loss: 0.4927 Val: 0.8440 Test: 1.1195\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 081, Loss: 0.4646 Val: 0.7550 Test: 1.0828\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 082, Loss: 0.4666 Val: 0.7180 Test: 0.9660\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 083, Loss: 0.5169 Val: 0.7633 Test: 0.8606\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 084, Loss: 0.5550 Val: 0.9470 Test: 0.8186\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 085, Loss: 0.4959 Val: 0.9158 Test: 0.7768\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 086, Loss: 0.4893 Val: 0.9019 Test: 0.8178\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 087, Loss: 0.4746 Val: 0.9083 Test: 0.7470\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 088, Loss: 0.4544 Val: 0.9609 Test: 0.7352\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 089, Loss: 0.4535 Val: 0.9584 Test: 0.7521\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 090, Loss: 0.4129 Val: 0.9675 Test: 0.7308\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 091, Loss: 0.4585 Val: 0.9771 Test: 0.8114\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 092, Loss: 0.4521 Val: 0.9443 Test: 0.8182\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 093, Loss: 0.4588 Val: 0.9557 Test: 0.7576\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 094, Loss: 0.4131 Val: 0.9111 Test: 0.7701\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 095, Loss: 0.4106 Val: 0.8854 Test: 0.7828\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 096, Loss: 0.4048 Val: 0.8580 Test: 0.7914\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 097, Loss: 0.3952 Val: 0.8369 Test: 0.8068\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 098, Loss: 0.3667 Val: 0.8062 Test: 0.8440\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 099, Loss: 0.4407 Val: 0.7879 Test: 0.8451\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 100, Loss: 0.3817 Val: 0.7837 Test: 0.8015\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 101, Loss: 0.3842 Val: 0.7729 Test: 0.7794\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 102, Loss: 0.3512 Val: 0.7987 Test: 0.7621\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 103, Loss: 0.3610 Val: 0.8182 Test: 0.7381\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 104, Loss: 0.4002 Val: 0.8409 Test: 0.7324\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 105, Loss: 0.3823 Val: 0.8363 Test: 0.7683\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 106, Loss: 0.4134 Val: 0.8068 Test: 0.7955\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 107, Loss: 0.3649 Val: 0.7981 Test: 0.7956\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 108, Loss: 0.3704 Val: 0.8212 Test: 0.8034\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 109, Loss: 0.3870 Val: 0.8305 Test: 0.8110\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 110, Loss: 0.3135 Val: 0.8332 Test: 0.8168\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 111, Loss: 0.3554 Val: 0.8225 Test: 0.8261\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 112, Loss: 0.3716 Val: 0.8104 Test: 0.8333\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 113, Loss: 0.4167 Val: 0.7978 Test: 0.8307\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 114, Loss: 0.3201 Val: 0.7843 Test: 0.8307\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 115, Loss: 0.4173 Val: 0.7915 Test: 0.8116\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 116, Loss: 0.4345 Val: 0.7877 Test: 0.7775\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 117, Loss: 0.3548 Val: 0.8723 Test: 0.7729\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 118, Loss: 0.4420 Val: 0.9514 Test: 0.8225\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 119, Loss: 0.3770 Val: 0.9338 Test: 0.8575\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 120, Loss: 0.3835 Val: 0.8603 Test: 0.8122\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 121, Loss: 0.4434 Val: 0.8334 Test: 0.8015\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 122, Loss: 0.4602 Val: 0.8393 Test: 0.8060\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 123, Loss: 0.3996 Val: 0.8696 Test: 0.8212\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 124, Loss: 0.3032 Val: 0.9080 Test: 0.8150\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 125, Loss: 0.3508 Val: 0.9093 Test: 0.8013\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 126, Loss: 0.3822 Val: 0.8799 Test: 0.7796\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 127, Loss: 0.4054 Val: 0.9752 Test: 0.7385\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 128, Loss: 0.3858 Val: 0.9777 Test: 0.7270\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 129, Loss: 0.3761 Val: 0.9726 Test: 0.7244\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 130, Loss: 0.3658 Val: 0.9511 Test: 0.7290\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 131, Loss: 0.3316 Val: 0.9253 Test: 0.7687\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 132, Loss: 0.3428 Val: 0.9367 Test: 0.7779\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 133, Loss: 0.3440 Val: 0.9563 Test: 0.7618\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 134, Loss: 0.3369 Val: 0.9754 Test: 0.7583\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 135, Loss: 0.3497 Val: 0.9867 Test: 0.7658\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 136, Loss: 0.3907 Val: 0.9869 Test: 0.7762\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 137, Loss: 0.3590 Val: 0.9870 Test: 0.7968\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 138, Loss: 0.3851 Val: 0.9806 Test: 0.8014\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 139, Loss: 0.4011 Val: 0.9722 Test: 0.7718\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 140, Loss: 0.3618 Val: 0.9804 Test: 0.7476\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 141, Loss: 0.3847 Val: 1.0100 Test: 0.7384\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 142, Loss: 0.3640 Val: 1.0361 Test: 0.7124\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 143, Loss: 0.4822 Val: 0.9791 Test: 0.6690\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 144, Loss: 0.5971 Val: 0.9938 Test: 0.7414\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 145, Loss: 0.4718 Val: 1.0054 Test: 0.7781\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 146, Loss: 0.4243 Val: 0.9913 Test: 0.7756\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 147, Loss: 0.4227 Val: 1.0047 Test: 0.7705\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 148, Loss: 0.3600 Val: 0.9265 Test: 0.7541\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 149, Loss: 0.4659 Val: 0.9092 Test: 0.8009\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 150, Loss: 0.4856 Val: 0.9750 Test: 0.7970\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 151, Loss: 0.4611 Val: 0.9702 Test: 0.8485\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 152, Loss: 0.4697 Val: 0.9881 Test: 0.8361\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 153, Loss: 0.4568 Val: 1.0914 Test: 0.7350\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 154, Loss: 0.4565 Val: 1.1822 Test: 0.7162\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 155, Loss: 0.5306 Val: 1.1862 Test: 0.7652\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 156, Loss: 0.4365 Val: 1.1594 Test: 0.7411\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 157, Loss: 0.5438 Val: 1.1217 Test: 0.6923\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 158, Loss: 0.4480 Val: 1.0063 Test: 0.7880\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 159, Loss: 0.4826 Val: 1.0856 Test: 0.7987\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 160, Loss: 0.4742 Val: 0.8987 Test: 0.7553\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 161, Loss: 0.5007 Val: 0.9230 Test: 0.8004\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 162, Loss: 0.5496 Val: 0.9179 Test: 0.7886\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 163, Loss: 0.5271 Val: 0.9570 Test: 0.7431\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 164, Loss: 0.4144 Val: 1.0268 Test: 0.7188\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 165, Loss: 0.4798 Val: 1.0125 Test: 0.7244\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 166, Loss: 0.4354 Val: 0.9756 Test: 0.8172\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 167, Loss: 0.4395 Val: 0.9440 Test: 0.8816\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 168, Loss: 0.4097 Val: 0.9290 Test: 0.9515\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 169, Loss: 0.4448 Val: 0.9341 Test: 0.8773\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 170, Loss: 0.4352 Val: 0.9679 Test: 0.7579\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 171, Loss: 0.4638 Val: 0.9595 Test: 0.7489\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 172, Loss: 0.5180 Val: 0.9102 Test: 0.7415\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 173, Loss: 0.4034 Val: 0.8603 Test: 0.7733\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 174, Loss: 0.4061 Val: 0.8502 Test: 0.8535\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 175, Loss: 0.4757 Val: 0.8868 Test: 0.8146\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 176, Loss: 0.4301 Val: 0.8915 Test: 0.7121\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 177, Loss: 0.3887 Val: 0.8784 Test: 0.6880\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 178, Loss: 0.4290 Val: 0.8834 Test: 0.6958\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 179, Loss: 0.4115 Val: 0.9130 Test: 0.6936\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 180, Loss: 0.3477 Val: 0.9534 Test: 0.6962\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 181, Loss: 0.3591 Val: 0.9701 Test: 0.7073\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 182, Loss: 0.4553 Val: 0.9566 Test: 0.7402\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 183, Loss: 0.4037 Val: 0.9221 Test: 0.7963\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 184, Loss: 0.3917 Val: 0.9296 Test: 0.8321\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 185, Loss: 0.4501 Val: 0.8565 Test: 0.7721\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 186, Loss: 0.3921 Val: 0.8790 Test: 0.7244\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 187, Loss: 0.4091 Val: 0.9034 Test: 0.7165\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 188, Loss: 0.4832 Val: 0.9156 Test: 0.7302\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 189, Loss: 0.4214 Val: 0.8780 Test: 0.7172\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 190, Loss: 0.3601 Val: 0.8461 Test: 0.7446\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 191, Loss: 0.4748 Val: 0.8761 Test: 0.7333\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 192, Loss: 0.4703 Val: 0.8911 Test: 0.7374\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 193, Loss: 0.3624 Val: 0.9308 Test: 0.7448\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 194, Loss: 0.3900 Val: 0.9262 Test: 0.7393\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 195, Loss: 0.3733 Val: 0.9180 Test: 0.7320\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 196, Loss: 0.3622 Val: 0.9364 Test: 0.7256\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 197, Loss: 0.4075 Val: 0.9202 Test: 0.7142\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 198, Loss: 0.4028 Val: 0.9055 Test: 0.7200\n",
      "16\n",
      "16\n",
      "9\n",
      "Epoch: 199, Loss: 0.4368 Val: 0.9069 Test: 0.7198\n",
      "rorg\n",
      "\n",
      "torch.Size([2778, 115])\n",
      "{'name': 'rorg', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa61033d5b0>, 'pre_filter': None, '_indices': [61, 66, 3, 21, 56, 18, 49, 26, 31, 14, 1, 15, 35, 62, 43, 16, 2, 64, 33, 23, 60, 22, 41, 63, 54, 38, 6, 12, 40, 4, 11, 44, 5, 57, 42, 20, 67, 29, 58, 9, 51, 17, 7, 28, 8, 39, 37, 50, 30, 10, 0, 24, 46, 34, 27, 53, 65, 47, 32, 59, 45, 25, 55, 52, 48, 19, 13, 36], 'data': Data(x=[2778, 115], edge_index=[2, 5836], edge_attr=[5836, 7], y=[68, 1], smiles=[68]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   44,   88,  128,  170,  211,  252,  291,  331,  370,  410,  450,\n",
      "         496,  538,  577,  621,  662,  701,  742,  783,  827,  867,  912,  954,\n",
      "         995, 1035, 1077, 1117, 1160, 1198, 1238, 1278, 1320, 1363, 1404, 1444,\n",
      "        1483, 1526, 1567, 1609, 1648, 1686, 1726, 1767, 1806, 1846, 1884, 1923,\n",
      "        1963, 2003, 2044, 2082, 2122, 2166, 2210, 2252, 2295, 2339, 2380, 2420,\n",
      "        2461, 2496, 2537, 2578, 2616, 2657, 2699, 2738, 2778]), 'edge_index': tensor([   0,   92,  184,  268,  354,  438,  526,  606,  690,  772,  854,  938,\n",
      "        1038, 1128, 1208, 1304, 1392, 1476, 1562, 1650, 1746, 1830, 1926, 2014,\n",
      "        2100, 2184, 2272, 2356, 2446, 2528, 2612, 2696, 2784, 2874, 2960, 3044,\n",
      "        3124, 3214, 3300, 3388, 3472, 3550, 3634, 3720, 3802, 3888, 3966, 4048,\n",
      "        4132, 4216, 4302, 4380, 4462, 4556, 4650, 4738, 4828, 4922, 5008, 5090,\n",
      "        5174, 5248, 5334, 5420, 5500, 5584, 5672, 5754, 5836]), 'edge_attr': tensor([   0,   92,  184,  268,  354,  438,  526,  606,  690,  772,  854,  938,\n",
      "        1038, 1128, 1208, 1304, 1392, 1476, 1562, 1650, 1746, 1830, 1926, 2014,\n",
      "        2100, 2184, 2272, 2356, 2446, 2528, 2612, 2696, 2784, 2874, 2960, 3044,\n",
      "        3124, 3214, 3300, 3388, 3472, 3550, 3634, 3720, 3802, 3888, 3966, 4048,\n",
      "        4132, 4216, 4302, 4380, 4462, 4556, 4650, 4738, 4828, 4922, 5008, 5090,\n",
      "        5174, 5248, 5334, 5420, 5500, 5584, 5672, 5754, 5836]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68])}), '_data_list': None}\n",
      "minv: 5.559999942779541\n",
      "maxv: 8.369999885559082\n",
      "emb_dim: 300\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 000, Loss: 0.7062 Val: 1.9444 Test: 1.8772\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 001, Loss: 0.6915 Val: 1.8866 Test: 1.8201\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 002, Loss: 0.6361 Val: 1.7779 Test: 1.7183\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 003, Loss: 0.6418 Val: 1.7128 Test: 1.6550\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 004, Loss: 0.6035 Val: 1.6622 Test: 1.5994\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 005, Loss: 0.5999 Val: 1.6070 Test: 1.5347\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 006, Loss: 0.5717 Val: 1.5459 Test: 1.4666\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 007, Loss: 0.6167 Val: 1.4788 Test: 1.4025\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 008, Loss: 0.5824 Val: 1.4135 Test: 1.3389\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 009, Loss: 0.5834 Val: 1.3541 Test: 1.2802\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 010, Loss: 0.5407 Val: 1.2980 Test: 1.2346\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 011, Loss: 0.5637 Val: 1.2458 Test: 1.1983\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 012, Loss: 0.5227 Val: 1.1941 Test: 1.1425\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 013, Loss: 0.5427 Val: 1.1498 Test: 1.0814\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 014, Loss: 0.5331 Val: 1.1040 Test: 1.0301\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 015, Loss: 0.5465 Val: 1.0540 Test: 0.9793\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 016, Loss: 0.4459 Val: 1.0035 Test: 0.9307\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 017, Loss: 0.4630 Val: 0.9553 Test: 0.8833\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 018, Loss: 0.4584 Val: 0.9078 Test: 0.8364\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 019, Loss: 0.4502 Val: 0.8621 Test: 0.7994\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 020, Loss: 0.4638 Val: 0.8147 Test: 0.7678\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 021, Loss: 0.4837 Val: 0.7709 Test: 0.7322\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 022, Loss: 0.4744 Val: 0.7318 Test: 0.6713\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 023, Loss: 0.4716 Val: 0.6956 Test: 0.6343\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 024, Loss: 0.4248 Val: 0.6538 Test: 0.5930\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 025, Loss: 0.4281 Val: 0.6110 Test: 0.5502\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 026, Loss: 0.4248 Val: 0.5677 Test: 0.5125\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 027, Loss: 0.4043 Val: 0.5300 Test: 0.4796\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 028, Loss: 0.3745 Val: 0.5293 Test: 0.4609\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 029, Loss: 0.4048 Val: 0.4629 Test: 0.4302\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 030, Loss: 0.4217 Val: 0.4369 Test: 0.4133\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 031, Loss: 0.4289 Val: 0.4028 Test: 0.4000\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 032, Loss: 0.4188 Val: 0.3846 Test: 0.3913\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 033, Loss: 0.4096 Val: 0.3675 Test: 0.3857\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 034, Loss: 0.2923 Val: 0.4710 Test: 0.3834\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 035, Loss: 0.3619 Val: 0.3202 Test: 0.3857\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 036, Loss: 0.3603 Val: 0.3879 Test: 0.3945\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 037, Loss: 0.3883 Val: 0.3416 Test: 0.4175\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 038, Loss: 0.3287 Val: 0.4444 Test: 0.4545\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 039, Loss: 0.3439 Val: 0.3366 Test: 0.4151\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 040, Loss: 0.3257 Val: 0.4835 Test: 0.4211\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 041, Loss: 0.4140 Val: 0.6166 Test: 0.4191\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 042, Loss: 0.5193 Val: 0.3067 Test: 0.4136\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 043, Loss: 0.3702 Val: 0.3055 Test: 0.4032\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 044, Loss: 0.4049 Val: 0.3021 Test: 0.4096\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 045, Loss: 0.4088 Val: 0.5003 Test: 0.4076\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 046, Loss: 0.3402 Val: 0.3026 Test: 0.4121\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 047, Loss: 0.3828 Val: 0.3026 Test: 0.4225\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 048, Loss: 0.3699 Val: 0.3013 Test: 0.4284\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 049, Loss: 0.4047 Val: 0.2987 Test: 0.4318\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 050, Loss: 0.3948 Val: 0.2936 Test: 0.4321\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 051, Loss: 0.3480 Val: 0.2879 Test: 0.4392\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 052, Loss: 0.3405 Val: 0.2829 Test: 0.4593\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 053, Loss: 0.3829 Val: 0.2861 Test: 0.4840\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 054, Loss: 0.3600 Val: 0.2985 Test: 0.4583\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 055, Loss: 0.3782 Val: 0.3019 Test: 0.4497\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 056, Loss: 0.3676 Val: 0.3055 Test: 0.4364\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 057, Loss: 0.3700 Val: 0.3074 Test: 0.4172\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 058, Loss: 0.3847 Val: 0.3056 Test: 0.4143\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 059, Loss: 0.3449 Val: 0.3015 Test: 0.4172\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 060, Loss: 0.3632 Val: 0.3011 Test: 0.4220\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 061, Loss: 0.4052 Val: 0.3000 Test: 0.4269\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 062, Loss: 0.2405 Val: 0.2988 Test: 0.4331\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 063, Loss: 0.4012 Val: 0.2958 Test: 0.4323\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 064, Loss: 0.3798 Val: 0.2904 Test: 0.4270\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 065, Loss: 0.3528 Val: 0.2872 Test: 0.4231\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 066, Loss: 0.3535 Val: 0.2869 Test: 0.4207\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 067, Loss: 0.4128 Val: 0.2889 Test: 0.4262\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 068, Loss: 0.3821 Val: 0.2909 Test: 0.4243\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 069, Loss: 0.3171 Val: 0.2849 Test: 0.4301\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 070, Loss: 0.3737 Val: 0.2799 Test: 0.4315\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 071, Loss: 0.3998 Val: 0.2775 Test: 0.4305\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 072, Loss: 0.3143 Val: 0.2768 Test: 0.4279\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 073, Loss: 0.3903 Val: 0.2775 Test: 0.4289\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 074, Loss: 0.4282 Val: 0.2849 Test: 0.4303\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 075, Loss: 0.3641 Val: 0.2882 Test: 0.4250\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 076, Loss: 0.3844 Val: 0.2897 Test: 0.4231\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 077, Loss: 0.4366 Val: 0.2900 Test: 0.4213\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 078, Loss: 0.3557 Val: 0.2878 Test: 0.4255\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 079, Loss: 0.3466 Val: 0.2818 Test: 0.4288\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 080, Loss: 0.3416 Val: 0.2777 Test: 0.4272\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 081, Loss: 0.3633 Val: 0.2776 Test: 0.4254\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 082, Loss: 0.3994 Val: 0.2773 Test: 0.4271\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 083, Loss: 0.4025 Val: 0.2773 Test: 0.4281\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 084, Loss: 0.3624 Val: 0.2762 Test: 0.4253\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 085, Loss: 0.3552 Val: 0.2709 Test: 0.4259\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 086, Loss: 0.2954 Val: 0.2698 Test: 0.4271\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 087, Loss: 0.3571 Val: 0.2699 Test: 0.4292\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 088, Loss: 0.3862 Val: 0.3035 Test: 0.4198\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 089, Loss: 0.3968 Val: 0.2684 Test: 0.4365\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 090, Loss: 0.4031 Val: 0.2733 Test: 0.4405\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 091, Loss: 0.4484 Val: 0.2824 Test: 0.4411\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 092, Loss: 0.3616 Val: 0.2879 Test: 0.4266\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 093, Loss: 0.3898 Val: 0.2924 Test: 0.4113\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 094, Loss: 0.3435 Val: 0.2937 Test: 0.3993\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 095, Loss: 0.3408 Val: 0.5291 Test: 0.4144\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 096, Loss: 0.3426 Val: 0.5409 Test: 0.4118\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 097, Loss: 0.3759 Val: 0.5498 Test: 0.3891\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 098, Loss: 0.3638 Val: 0.5812 Test: 0.3776\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 099, Loss: 0.3028 Val: 0.6426 Test: 0.4140\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 100, Loss: 0.3807 Val: 0.5933 Test: 0.4781\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 101, Loss: 0.3837 Val: 0.6217 Test: 0.4861\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 102, Loss: 0.5066 Val: 0.2967 Test: 0.4156\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 103, Loss: 0.3136 Val: 0.3026 Test: 0.4029\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 104, Loss: 0.3954 Val: 0.3016 Test: 0.4090\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 105, Loss: 0.3073 Val: 0.2979 Test: 0.4208\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 106, Loss: 0.3020 Val: 0.2938 Test: 0.4329\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 107, Loss: 0.3632 Val: 0.2879 Test: 0.4348\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 108, Loss: 0.3708 Val: 0.2827 Test: 0.4371\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 109, Loss: 0.3187 Val: 0.2762 Test: 0.4361\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 110, Loss: 0.3218 Val: 0.2733 Test: 0.4365\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 111, Loss: 0.3247 Val: 0.2809 Test: 0.4404\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 112, Loss: 0.3769 Val: 0.2868 Test: 0.4435\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 113, Loss: 0.3789 Val: 0.2856 Test: 0.4413\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 114, Loss: 0.3049 Val: 0.2816 Test: 0.4426\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 115, Loss: 0.4192 Val: 0.2734 Test: 0.4457\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 116, Loss: 0.4144 Val: 0.2718 Test: 0.4356\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 117, Loss: 0.4043 Val: 0.2701 Test: 0.4307\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 118, Loss: 0.3307 Val: 0.2694 Test: 0.4366\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 119, Loss: 0.3736 Val: 0.2605 Test: 0.4304\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 120, Loss: 0.4025 Val: 0.2593 Test: 0.4392\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 121, Loss: 0.4302 Val: 0.2646 Test: 0.4543\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 122, Loss: 0.3490 Val: 0.2640 Test: 0.4549\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 123, Loss: 0.3178 Val: 0.2656 Test: 0.4571\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 124, Loss: 0.3443 Val: 0.2670 Test: 0.4559\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 125, Loss: 0.4016 Val: 0.2702 Test: 0.4507\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 126, Loss: 0.3681 Val: 0.2700 Test: 0.4460\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 127, Loss: 0.3990 Val: 0.2677 Test: 0.4455\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 128, Loss: 0.3740 Val: 0.2700 Test: 0.4531\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 129, Loss: 0.3382 Val: 0.2752 Test: 0.4535\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 130, Loss: 0.3905 Val: 0.2792 Test: 0.4543\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 131, Loss: 0.3557 Val: 0.2784 Test: 0.4536\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 132, Loss: 0.3564 Val: 0.3014 Test: 0.4333\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 133, Loss: 0.3314 Val: 0.3492 Test: 0.4315\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 134, Loss: 0.3961 Val: 0.2895 Test: 0.4323\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 135, Loss: 0.2592 Val: 0.2866 Test: 0.4375\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 136, Loss: 0.3650 Val: 0.2738 Test: 0.4529\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 137, Loss: 0.3433 Val: 0.2683 Test: 0.4571\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 138, Loss: 0.4396 Val: 0.3459 Test: 0.3827\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 139, Loss: 0.4478 Val: 0.2907 Test: 0.3791\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 140, Loss: 0.4053 Val: 0.2760 Test: 0.4595\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 141, Loss: 0.4027 Val: 0.2844 Test: 0.4494\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 142, Loss: 0.3717 Val: 0.2883 Test: 0.4572\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 143, Loss: 0.4112 Val: 0.2897 Test: 0.4697\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 144, Loss: 0.3151 Val: 0.2881 Test: 0.4732\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 145, Loss: 0.4115 Val: 0.2893 Test: 0.4724\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 146, Loss: 0.3803 Val: 0.3084 Test: 0.4680\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 147, Loss: 0.3635 Val: 0.2895 Test: 0.4829\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 148, Loss: 0.3722 Val: 0.2898 Test: 0.4920\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 149, Loss: 0.3930 Val: 0.2872 Test: 0.4939\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 150, Loss: 0.3034 Val: 0.2760 Test: 0.4976\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 151, Loss: 0.3331 Val: 0.2722 Test: 0.5065\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 152, Loss: 0.4391 Val: 0.2754 Test: 0.4935\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 153, Loss: 0.3225 Val: 0.2826 Test: 0.4445\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 154, Loss: 0.3812 Val: 0.3031 Test: 0.5660\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 155, Loss: 0.3325 Val: 0.2965 Test: 0.6565\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 156, Loss: 0.5372 Val: 0.2823 Test: 0.5136\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 157, Loss: 0.3627 Val: 0.2811 Test: 0.4773\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 158, Loss: 0.3554 Val: 0.4962 Test: 0.4760\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 159, Loss: 0.3635 Val: 0.2786 Test: 0.4629\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 160, Loss: 0.3212 Val: 0.2753 Test: 0.4674\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 161, Loss: 0.3435 Val: 0.2733 Test: 0.4690\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 162, Loss: 0.4078 Val: 0.2740 Test: 0.4703\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 163, Loss: 0.3836 Val: 0.3024 Test: 0.4706\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 164, Loss: 0.3880 Val: 0.3030 Test: 0.4680\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 165, Loss: 0.3321 Val: 0.3207 Test: 0.4554\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 166, Loss: 0.4421 Val: 0.3376 Test: 0.4453\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 167, Loss: 0.4262 Val: 0.2760 Test: 0.4459\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 168, Loss: 0.3659 Val: 0.2776 Test: 0.4379\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 169, Loss: 0.2953 Val: 0.2773 Test: 0.3771\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 170, Loss: 0.4058 Val: 0.3118 Test: 0.3849\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 171, Loss: 0.4483 Val: 0.2848 Test: 0.3873\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 172, Loss: 0.3994 Val: 0.2768 Test: 0.4064\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 173, Loss: 0.3837 Val: 0.2800 Test: 0.4294\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 174, Loss: 0.4017 Val: 0.2839 Test: 0.4386\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 175, Loss: 0.2874 Val: 0.2868 Test: 0.4468\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 176, Loss: 0.4289 Val: 0.2810 Test: 0.4534\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 177, Loss: 0.4222 Val: 0.2742 Test: 0.4524\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 178, Loss: 0.4153 Val: 0.2712 Test: 0.4350\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 179, Loss: 0.3585 Val: 0.2745 Test: 0.4396\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 180, Loss: 0.4049 Val: 0.3137 Test: 0.4168\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 181, Loss: 0.3553 Val: 0.2926 Test: 0.4384\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 182, Loss: 0.3881 Val: 0.2827 Test: 0.4230\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 183, Loss: 0.3866 Val: 0.2834 Test: 0.4153\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 184, Loss: 0.3784 Val: 0.2862 Test: 0.4166\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 185, Loss: 0.3671 Val: 0.2845 Test: 0.4247\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 186, Loss: 0.4398 Val: 0.2842 Test: 0.4342\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 187, Loss: 0.3990 Val: 0.2851 Test: 0.4400\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 188, Loss: 0.3187 Val: 0.2867 Test: 0.4433\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 189, Loss: 0.4075 Val: 0.2899 Test: 0.4379\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 190, Loss: 0.3577 Val: 0.2904 Test: 0.4400\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 191, Loss: 0.3749 Val: 0.2899 Test: 0.4396\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 192, Loss: 0.3543 Val: 0.2883 Test: 0.4376\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 193, Loss: 0.3908 Val: 0.2859 Test: 0.4322\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 194, Loss: 0.3582 Val: 0.2846 Test: 0.4339\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 195, Loss: 0.3640 Val: 0.2859 Test: 0.4352\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 196, Loss: 0.3860 Val: 0.2854 Test: 0.4374\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 197, Loss: 0.3833 Val: 0.2852 Test: 0.4364\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 198, Loss: 0.3699 Val: 0.2844 Test: 0.4376\n",
      "16\n",
      "16\n",
      "10\n",
      "Epoch: 199, Loss: 0.3750 Val: 0.2841 Test: 0.4378\n",
      "ido1\n",
      "\n",
      "torch.Size([1632, 115])\n",
      "{'name': 'ido1', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa6103542e0>, 'pre_filter': None, '_indices': [73, 34, 39, 62, 6, 67, 38, 20, 68, 44, 8, 58, 12, 27, 46, 21, 3, 53, 13, 5, 61, 48, 40, 19, 71, 1, 10, 32, 16, 41, 33, 75, 54, 70, 11, 25, 49, 31, 64, 74, 0, 50, 42, 43, 9, 45, 65, 36, 63, 22, 66, 52, 14, 30, 29, 2, 37, 72, 35, 60, 28, 7, 24, 26, 56, 57, 17, 59, 76, 77, 55, 51, 15, 23, 47, 69, 18, 4], 'data': Data(x=[1632, 115], edge_index=[2, 3664], edge_attr=[3664, 7], y=[78, 1], smiles=[78]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   22,   45,   68,   83,  105,  130,  158,  188,  199,  211,  230,\n",
      "         251,  271,  295,  317,  347,  370,  391,  404,  418,  436,  456,  469,\n",
      "         490,  520,  543,  566,  585,  598,  611,  629,  646,  675,  699,  712,\n",
      "         733,  763,  793,  816,  835,  847,  870,  889,  902,  923,  953,  975,\n",
      "         996, 1017, 1031, 1054, 1077, 1094, 1114, 1135, 1156, 1187, 1209, 1232,\n",
      "        1253, 1270, 1291, 1314, 1334, 1355, 1376, 1399, 1420, 1434, 1447, 1469,\n",
      "        1495, 1525, 1546, 1568, 1588, 1609, 1632]), 'edge_index': tensor([   0,   50,  102,  154,  188,  238,  294,  356,  424,  448,  474,  516,\n",
      "         562,  608,  662,  712,  780,  832,  880,  908,  938,  976, 1020, 1050,\n",
      "        1098, 1166, 1218, 1270, 1312, 1340, 1368, 1406, 1442, 1508, 1562, 1592,\n",
      "        1640, 1708, 1776, 1828, 1870, 1898, 1950, 1992, 2020, 2068, 2136, 2186,\n",
      "        2232, 2280, 2310, 2362, 2414, 2452, 2498, 2546, 2594, 2664, 2714, 2766,\n",
      "        2812, 2850, 2898, 2950, 2994, 3042, 3086, 3138, 3186, 3216, 3244, 3294,\n",
      "        3352, 3420, 3468, 3518, 3564, 3612, 3664]), 'edge_attr': tensor([   0,   50,  102,  154,  188,  238,  294,  356,  424,  448,  474,  516,\n",
      "         562,  608,  662,  712,  780,  832,  880,  908,  938,  976, 1020, 1050,\n",
      "        1098, 1166, 1218, 1270, 1312, 1340, 1368, 1406, 1442, 1508, 1562, 1592,\n",
      "        1640, 1708, 1776, 1828, 1870, 1898, 1950, 1992, 2020, 2068, 2136, 2186,\n",
      "        2232, 2280, 2310, 2362, 2414, 2452, 2498, 2546, 2594, 2664, 2714, 2766,\n",
      "        2812, 2850, 2898, 2950, 2994, 3042, 3086, 3138, 3186, 3216, 3244, 3294,\n",
      "        3352, 3420, 3468, 3518, 3564, 3612, 3664]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78])}), '_data_list': None}\n",
      "minv: 4.329999923706055\n",
      "maxv: 7.679999828338623\n",
      "emb_dim: 300\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 000, Loss: 0.8749 Val: 1.6476 Test: 2.0948\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 001, Loss: 0.8071 Val: 1.6209 Test: 2.0726\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 002, Loss: 0.7551 Val: 1.5977 Test: 2.0407\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 003, Loss: 0.7757 Val: 1.5628 Test: 2.0121\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 004, Loss: 0.8241 Val: 1.5367 Test: 1.9865\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 005, Loss: 0.7496 Val: 1.5187 Test: 1.9586\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 006, Loss: 0.6936 Val: 1.4929 Test: 1.9260\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 007, Loss: 0.7646 Val: 1.4643 Test: 1.8932\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 008, Loss: 0.7386 Val: 1.4334 Test: 1.8664\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 009, Loss: 0.7539 Val: 1.4040 Test: 1.8400\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 010, Loss: 0.7353 Val: 1.3782 Test: 1.8036\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 011, Loss: 0.7280 Val: 1.3517 Test: 1.7554\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 012, Loss: 0.7122 Val: 1.3237 Test: 1.7168\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 013, Loss: 0.7621 Val: 1.2869 Test: 1.6793\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 014, Loss: 0.6700 Val: 1.2599 Test: 1.6559\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 015, Loss: 0.7427 Val: 1.2277 Test: 1.6298\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 016, Loss: 0.7489 Val: 1.2062 Test: 1.5767\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 017, Loss: 0.7081 Val: 1.1744 Test: 1.5359\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 018, Loss: 0.6413 Val: 1.1413 Test: 1.4969\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 019, Loss: 0.7074 Val: 1.1276 Test: 1.4571\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 020, Loss: 0.6450 Val: 1.1036 Test: 1.4183\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 021, Loss: 0.7529 Val: 1.0467 Test: 1.3809\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 022, Loss: 0.6608 Val: 1.0199 Test: 1.3371\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 023, Loss: 0.6973 Val: 0.9912 Test: 1.2861\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 024, Loss: 0.7572 Val: 0.9459 Test: 1.2511\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 025, Loss: 0.6306 Val: 0.9088 Test: 1.2029\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 026, Loss: 0.7581 Val: 0.9032 Test: 1.1603\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 027, Loss: 0.6612 Val: 0.8818 Test: 1.1305\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 028, Loss: 0.6391 Val: 0.8525 Test: 1.0865\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 029, Loss: 0.6249 Val: 0.8239 Test: 1.0501\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 030, Loss: 0.6753 Val: 0.8130 Test: 1.0163\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 031, Loss: 0.6366 Val: 0.8167 Test: 0.9806\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 032, Loss: 0.7029 Val: 0.8116 Test: 0.9501\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 033, Loss: 0.6554 Val: 0.7991 Test: 0.9745\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 034, Loss: 0.7104 Val: 0.8054 Test: 0.9992\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 035, Loss: 0.5546 Val: 0.8041 Test: 0.8965\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 036, Loss: 0.6289 Val: 0.8560 Test: 0.8428\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 037, Loss: 0.6561 Val: 0.8627 Test: 0.7968\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 038, Loss: 0.6073 Val: 0.8829 Test: 0.7590\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 039, Loss: 0.5451 Val: 0.8733 Test: 0.7414\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 040, Loss: 0.6323 Val: 0.8652 Test: 0.7341\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 041, Loss: 0.5810 Val: 0.8664 Test: 0.6843\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 042, Loss: 0.6439 Val: 0.8651 Test: 0.6933\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 043, Loss: 0.5905 Val: 0.9202 Test: 0.8014\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 044, Loss: 0.6192 Val: 0.9315 Test: 0.7913\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 045, Loss: 0.6991 Val: 0.9353 Test: 0.7606\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 046, Loss: 0.6112 Val: 0.8655 Test: 0.7103\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 047, Loss: 0.5779 Val: 0.8916 Test: 0.6892\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 048, Loss: 0.4838 Val: 0.8504 Test: 0.6663\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 049, Loss: 0.6087 Val: 0.8535 Test: 0.6433\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 050, Loss: 0.6273 Val: 0.9795 Test: 0.8246\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 051, Loss: 0.6804 Val: 0.9019 Test: 0.6938\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 052, Loss: 0.6321 Val: 0.9748 Test: 0.7121\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 053, Loss: 0.5488 Val: 1.0931 Test: 0.7673\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 054, Loss: 0.5539 Val: 1.0513 Test: 0.8296\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 055, Loss: 0.5778 Val: 0.9877 Test: 0.8337\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 056, Loss: 0.6384 Val: 0.9624 Test: 0.8373\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 057, Loss: 0.6004 Val: 1.0023 Test: 0.9127\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 058, Loss: 0.4974 Val: 1.0237 Test: 0.8771\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 059, Loss: 0.5464 Val: 1.0164 Test: 0.8319\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 060, Loss: 0.6379 Val: 1.0072 Test: 0.8423\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 061, Loss: 0.5455 Val: 0.9998 Test: 0.8710\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 062, Loss: 0.6034 Val: 0.9825 Test: 0.8754\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 063, Loss: 0.6169 Val: 0.9621 Test: 0.8693\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 064, Loss: 0.4609 Val: 0.9530 Test: 0.8733\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 065, Loss: 0.5631 Val: 0.9625 Test: 0.9095\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 066, Loss: 0.5727 Val: 0.9626 Test: 0.8952\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 067, Loss: 0.7068 Val: 0.9775 Test: 0.7897\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 068, Loss: 0.6132 Val: 0.9757 Test: 0.7407\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 069, Loss: 0.5150 Val: 0.9545 Test: 0.7245\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 070, Loss: 0.5943 Val: 0.9639 Test: 0.7336\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 071, Loss: 0.5588 Val: 0.9855 Test: 0.7237\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 072, Loss: 0.7173 Val: 0.9925 Test: 0.7518\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 073, Loss: 0.6145 Val: 1.0093 Test: 0.8814\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 074, Loss: 0.6081 Val: 0.9722 Test: 0.9028\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 075, Loss: 0.5131 Val: 0.9701 Test: 0.8735\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 076, Loss: 0.6093 Val: 0.9807 Test: 0.8677\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 077, Loss: 0.5494 Val: 1.0016 Test: 0.8459\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 078, Loss: 0.4866 Val: 1.0124 Test: 0.8066\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 079, Loss: 0.5171 Val: 1.0106 Test: 0.8113\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 080, Loss: 0.5673 Val: 0.9834 Test: 0.8049\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 081, Loss: 0.5468 Val: 1.0036 Test: 0.7864\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 082, Loss: 0.5349 Val: 0.9747 Test: 0.8185\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 083, Loss: 0.5930 Val: 0.9769 Test: 0.7938\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 084, Loss: 0.5508 Val: 0.9787 Test: 0.7636\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 085, Loss: 0.5042 Val: 0.9707 Test: 0.7526\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 086, Loss: 0.6208 Val: 0.9734 Test: 0.7857\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 087, Loss: 0.5897 Val: 0.9539 Test: 0.8058\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 088, Loss: 0.5855 Val: 0.9223 Test: 0.7944\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 089, Loss: 0.5561 Val: 0.9225 Test: 0.7857\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 090, Loss: 0.6112 Val: 0.9404 Test: 0.8101\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 091, Loss: 0.5943 Val: 0.9631 Test: 0.8397\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 092, Loss: 0.5390 Val: 1.0195 Test: 0.8197\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 093, Loss: 0.5292 Val: 1.0663 Test: 0.8200\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 094, Loss: 0.5473 Val: 1.0593 Test: 0.8254\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 095, Loss: 0.5628 Val: 1.0207 Test: 0.8345\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 096, Loss: 0.5191 Val: 0.9937 Test: 0.8361\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 097, Loss: 0.5531 Val: 0.9944 Test: 0.8115\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 098, Loss: 0.5742 Val: 0.9982 Test: 0.7985\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 099, Loss: 0.4845 Val: 0.9865 Test: 0.8098\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 100, Loss: 0.4915 Val: 0.9433 Test: 0.8146\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 101, Loss: 0.5372 Val: 0.9287 Test: 0.8332\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 102, Loss: 0.6297 Val: 0.9387 Test: 0.8302\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 103, Loss: 0.5058 Val: 0.9567 Test: 0.8232\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 104, Loss: 0.6560 Val: 1.0507 Test: 0.8760\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 105, Loss: 0.5030 Val: 1.0629 Test: 0.8743\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 106, Loss: 0.5402 Val: 1.0355 Test: 0.8727\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 107, Loss: 0.5490 Val: 1.0010 Test: 0.8752\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 108, Loss: 0.5046 Val: 0.9646 Test: 0.8735\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 109, Loss: 0.4457 Val: 0.9361 Test: 0.8833\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 110, Loss: 0.4939 Val: 0.9481 Test: 0.9061\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 111, Loss: 0.6110 Val: 0.9819 Test: 0.8905\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 112, Loss: 0.6258 Val: 1.0216 Test: 0.8592\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 113, Loss: 0.5043 Val: 1.0389 Test: 0.8461\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 114, Loss: 0.5360 Val: 1.0374 Test: 0.8463\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 115, Loss: 0.5426 Val: 1.0237 Test: 0.8830\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 116, Loss: 0.5073 Val: 1.0055 Test: 0.9264\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 117, Loss: 0.5449 Val: 1.0020 Test: 0.9478\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 118, Loss: 0.5506 Val: 1.0046 Test: 0.9412\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 119, Loss: 0.5541 Val: 1.0106 Test: 0.9172\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 120, Loss: 0.5122 Val: 0.9969 Test: 0.8843\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 121, Loss: 0.5152 Val: 0.9787 Test: 0.8846\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 122, Loss: 0.4619 Val: 0.9656 Test: 0.8820\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 123, Loss: 0.6162 Val: 0.9633 Test: 0.9148\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 124, Loss: 0.5029 Val: 0.9934 Test: 0.9222\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 125, Loss: 0.5749 Val: 0.9897 Test: 0.9078\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 126, Loss: 0.4936 Val: 0.9762 Test: 0.8677\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 127, Loss: 0.4104 Val: 0.9428 Test: 0.8207\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 128, Loss: 0.4746 Val: 0.9865 Test: 0.8194\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 129, Loss: 0.4872 Val: 1.0656 Test: 0.8012\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 130, Loss: 0.6736 Val: 1.0877 Test: 0.7779\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 131, Loss: 0.6988 Val: 1.0763 Test: 0.7895\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 132, Loss: 0.5552 Val: 1.0405 Test: 0.8478\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 133, Loss: 0.5922 Val: 1.0286 Test: 0.8784\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 134, Loss: 0.5690 Val: 1.0114 Test: 0.8771\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 135, Loss: 0.5349 Val: 1.0005 Test: 0.8488\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 136, Loss: 0.5253 Val: 0.9817 Test: 0.7890\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 137, Loss: 0.4805 Val: 1.0268 Test: 0.7312\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 138, Loss: 0.5253 Val: 1.0522 Test: 0.8153\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 139, Loss: 0.5479 Val: 1.0438 Test: 0.8063\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 140, Loss: 0.5397 Val: 1.0237 Test: 0.8001\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 141, Loss: 0.4477 Val: 1.0448 Test: 0.8542\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 142, Loss: 0.5516 Val: 1.0751 Test: 0.8755\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 143, Loss: 0.5394 Val: 1.0798 Test: 0.8389\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 144, Loss: 0.4929 Val: 1.0707 Test: 0.8179\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 145, Loss: 0.5110 Val: 1.0908 Test: 0.8069\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 146, Loss: 0.4768 Val: 1.1098 Test: 0.8091\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 147, Loss: 0.6786 Val: 1.0810 Test: 0.8124\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 148, Loss: 0.5691 Val: 1.0302 Test: 0.7923\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 149, Loss: 0.5632 Val: 1.0668 Test: 0.7854\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 150, Loss: 0.5477 Val: 1.0921 Test: 0.7605\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 151, Loss: 0.4505 Val: 1.1368 Test: 0.7417\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 152, Loss: 0.4066 Val: 1.1652 Test: 0.7369\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 153, Loss: 0.5957 Val: 1.1030 Test: 0.6227\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 154, Loss: 0.6072 Val: 1.0210 Test: 0.6421\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 155, Loss: 0.5990 Val: 0.9904 Test: 0.6381\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 156, Loss: 0.4659 Val: 0.9699 Test: 0.6594\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 157, Loss: 0.5362 Val: 0.9353 Test: 0.7299\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 158, Loss: 0.5188 Val: 0.9158 Test: 0.7727\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 159, Loss: 0.5596 Val: 0.9794 Test: 0.7993\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 160, Loss: 0.5481 Val: 1.0225 Test: 0.8141\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 161, Loss: 0.6121 Val: 0.9788 Test: 0.8750\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 162, Loss: 0.5531 Val: 0.8981 Test: 0.8938\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 163, Loss: 0.5743 Val: 0.8554 Test: 0.8089\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 164, Loss: 0.5437 Val: 0.8498 Test: 0.7835\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 165, Loss: 0.6296 Val: 0.8631 Test: 0.7931\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 166, Loss: 0.5620 Val: 0.8767 Test: 0.7764\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 167, Loss: 0.4814 Val: 0.8918 Test: 0.7541\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 168, Loss: 0.5384 Val: 0.9110 Test: 0.7351\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 169, Loss: 0.4779 Val: 0.9107 Test: 0.6714\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 170, Loss: 0.4327 Val: 0.9103 Test: 0.7122\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 171, Loss: 0.6649 Val: 0.8984 Test: 0.7677\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 172, Loss: 0.5560 Val: 0.8954 Test: 0.8191\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 173, Loss: 0.5514 Val: 0.8900 Test: 0.8172\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 174, Loss: 0.5506 Val: 0.8811 Test: 0.8131\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 175, Loss: 0.5287 Val: 0.8744 Test: 0.8086\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 176, Loss: 0.5395 Val: 0.8742 Test: 0.8180\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 177, Loss: 0.4652 Val: 0.8838 Test: 0.8335\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 178, Loss: 0.4776 Val: 0.8863 Test: 0.8509\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 179, Loss: 0.4891 Val: 0.8908 Test: 0.8681\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 180, Loss: 0.5463 Val: 0.9022 Test: 0.8966\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 181, Loss: 0.5363 Val: 0.9132 Test: 0.9162\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 182, Loss: 0.5385 Val: 0.9174 Test: 0.9156\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 183, Loss: 0.5530 Val: 0.9245 Test: 0.9003\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 184, Loss: 0.4958 Val: 0.9211 Test: 0.8770\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 185, Loss: 0.5598 Val: 0.9218 Test: 0.8199\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 186, Loss: 0.5582 Val: 0.9127 Test: 0.7778\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 187, Loss: 0.5576 Val: 0.9136 Test: 0.7372\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 188, Loss: 0.4537 Val: 0.9095 Test: 0.7492\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 189, Loss: 0.5319 Val: 0.8982 Test: 0.7559\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 190, Loss: 0.4997 Val: 0.8908 Test: 0.7600\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 191, Loss: 0.5181 Val: 0.8971 Test: 0.7442\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 192, Loss: 0.5306 Val: 0.9059 Test: 0.7429\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 193, Loss: 0.5190 Val: 0.9145 Test: 0.7721\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 194, Loss: 0.5990 Val: 0.9311 Test: 0.7425\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 195, Loss: 0.5035 Val: 0.9469 Test: 0.7071\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 196, Loss: 0.5386 Val: 0.9232 Test: 0.7229\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 197, Loss: 0.5236 Val: 0.8986 Test: 0.7684\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 198, Loss: 0.5748 Val: 1.0037 Test: 0.7943\n",
      "16\n",
      "16\n",
      "16\n",
      "Epoch: 199, Loss: 0.5034 Val: 1.0279 Test: 0.8054\n",
      "klk5\n",
      "\n",
      "torch.Size([2118, 115])\n",
      "{'name': 'klk5', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa61032fac0>, 'pre_filter': None, '_indices': [24, 65, 62, 60, 70, 22, 19, 77, 75, 57, 64, 14, 32, 44, 29, 74, 40, 10, 68, 52, 38, 2, 72, 23, 39, 71, 76, 1, 33, 42, 54, 21, 43, 8, 11, 5, 51, 46, 55, 31, 36, 47, 78, 25, 6, 7, 12, 27, 0, 34, 35, 17, 66, 15, 20, 41, 4, 61, 56, 13, 9, 30, 3, 26, 73, 37, 67, 53, 16, 48, 49, 50, 45, 59, 28, 58, 18, 69, 63], 'data': Data(x=[2118, 115], edge_index=[2, 4484], edge_attr=[4484, 7], y=[79, 1], smiles=[79]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   30,   49,   77,   99,  128,  158,  177,  200,  230,  260,  281,\n",
      "         310,  333,  362,  392,  423,  450,  481,  511,  541,  571,  594,  618,\n",
      "         640,  670,  700,  720,  751,  782,  812,  833,  863,  894,  915,  937,\n",
      "         964,  986, 1007, 1035, 1068, 1085, 1118, 1140, 1162, 1192, 1223, 1245,\n",
      "        1267, 1298, 1329, 1362, 1392, 1425, 1445, 1470, 1492, 1513, 1535, 1564,\n",
      "        1594, 1621, 1644, 1669, 1699, 1716, 1746, 1777, 1806, 1839, 1861, 1891,\n",
      "        1914, 1945, 1975, 2006, 2027, 2060, 2088, 2118]), 'edge_index': tensor([   0,   62,  102,  162,  210,  272,  336,  376,  424,  488,  552,  596,\n",
      "         658,  704,  768,  832,  900,  956, 1020, 1084, 1148, 1212, 1258, 1308,\n",
      "        1356, 1422, 1484, 1528, 1594, 1660, 1724, 1768, 1832, 1898, 1942, 1986,\n",
      "        2040, 2086, 2130, 2192, 2262, 2296, 2366, 2412, 2458, 2522, 2588, 2636,\n",
      "        2682, 2750, 2818, 2888, 2952, 3022, 3064, 3114, 3162, 3208, 3254, 3316,\n",
      "        3380, 3434, 3480, 3530, 3596, 3630, 3694, 3760, 3822, 3892, 3938, 4002,\n",
      "        4048, 4114, 4178, 4246, 4290, 4360, 4418, 4484]), 'edge_attr': tensor([   0,   62,  102,  162,  210,  272,  336,  376,  424,  488,  552,  596,\n",
      "         658,  704,  768,  832,  900,  956, 1020, 1084, 1148, 1212, 1258, 1308,\n",
      "        1356, 1422, 1484, 1528, 1594, 1660, 1724, 1768, 1832, 1898, 1942, 1986,\n",
      "        2040, 2086, 2130, 2192, 2262, 2296, 2366, 2412, 2458, 2522, 2588, 2636,\n",
      "        2682, 2750, 2818, 2888, 2952, 3022, 3064, 3114, 3162, 3208, 3254, 3316,\n",
      "        3380, 3434, 3480, 3530, 3596, 3630, 3694, 3760, 3822, 3892, 3938, 4002,\n",
      "        4048, 4114, 4178, 4246, 4290, 4360, 4418, 4484]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79])}), '_data_list': None}\n",
      "minv: 4.300000190734863\n",
      "maxv: 9.300000190734863\n",
      "emb_dim: 300\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 000, Loss: 0.7567 Val: 2.4009 Test: 2.5571\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 001, Loss: 0.6136 Val: 2.3538 Test: 2.5047\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 002, Loss: 0.8048 Val: 2.3192 Test: 2.4849\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 003, Loss: 0.7490 Val: 2.2655 Test: 2.4406\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 004, Loss: 0.8685 Val: 2.2262 Test: 2.4088\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 005, Loss: 0.7099 Val: 2.1959 Test: 2.3845\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 006, Loss: 0.6501 Val: 2.1544 Test: 2.3394\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 007, Loss: 0.5940 Val: 2.0938 Test: 2.2850\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 008, Loss: 0.5102 Val: 2.0689 Test: 2.2636\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 009, Loss: 0.6180 Val: 2.0547 Test: 2.2218\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 010, Loss: 0.5357 Val: 2.0027 Test: 2.1818\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 011, Loss: 0.5933 Val: 1.9764 Test: 2.1502\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 012, Loss: 0.4833 Val: 1.9255 Test: 2.1171\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 013, Loss: 0.5339 Val: 1.9069 Test: 2.0931\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 014, Loss: 0.6471 Val: 2.0673 Test: 2.1792\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 015, Loss: 0.8578 Val: 1.9724 Test: 2.1260\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 016, Loss: 0.8126 Val: 1.7819 Test: 1.9744\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 017, Loss: 0.6150 Val: 1.7089 Test: 1.9128\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 018, Loss: 0.6150 Val: 1.6465 Test: 1.8944\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 019, Loss: 0.6229 Val: 1.6943 Test: 1.8931\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 020, Loss: 0.4855 Val: 1.6721 Test: 1.8712\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 021, Loss: 0.5090 Val: 1.6153 Test: 1.8476\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 022, Loss: 0.6170 Val: 1.5679 Test: 1.8120\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 023, Loss: 0.7012 Val: 1.9895 Test: 1.9865\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 024, Loss: 0.8339 Val: 1.9537 Test: 2.1140\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 025, Loss: 0.8283 Val: 1.8749 Test: 2.0828\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 026, Loss: 0.7161 Val: 1.7789 Test: 2.0093\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 027, Loss: 0.7106 Val: 1.6956 Test: 1.8951\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 028, Loss: 0.6423 Val: 1.5699 Test: 1.7976\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 029, Loss: 0.7019 Val: 1.4735 Test: 1.7302\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 030, Loss: 0.6734 Val: 1.4297 Test: 1.6764\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 031, Loss: 0.6238 Val: 1.3983 Test: 1.6397\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 032, Loss: 0.7025 Val: 1.3660 Test: 1.6024\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 033, Loss: 0.4646 Val: 1.3105 Test: 1.5455\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 034, Loss: 0.5789 Val: 1.2899 Test: 1.6758\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 035, Loss: 0.6436 Val: 1.2040 Test: 1.5211\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 036, Loss: 0.6242 Val: 1.1338 Test: 1.5057\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 037, Loss: 0.6477 Val: 1.0929 Test: 1.4310\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 038, Loss: 0.6891 Val: 1.0916 Test: 1.3389\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 039, Loss: 0.5989 Val: 1.0260 Test: 1.3006\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 040, Loss: 0.5982 Val: 0.9643 Test: 1.2961\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 041, Loss: 0.4172 Val: 0.9184 Test: 1.2750\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 042, Loss: 0.5611 Val: 0.8800 Test: 1.2833\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 043, Loss: 0.5201 Val: 0.8615 Test: 1.2473\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 044, Loss: 0.5771 Val: 0.8601 Test: 1.1985\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 045, Loss: 0.5926 Val: 0.8600 Test: 1.1412\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 046, Loss: 0.5305 Val: 0.8554 Test: 1.0777\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 047, Loss: 0.5479 Val: 0.8639 Test: 1.0162\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 048, Loss: 0.4995 Val: 0.8556 Test: 0.9676\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 049, Loss: 0.5113 Val: 0.8331 Test: 0.9240\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 050, Loss: 0.5122 Val: 0.7948 Test: 0.9626\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 051, Loss: 0.6108 Val: 0.8337 Test: 1.0515\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 052, Loss: 0.5217 Val: 0.8330 Test: 1.0897\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 053, Loss: 0.5993 Val: 0.8489 Test: 1.0977\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 054, Loss: 0.5519 Val: 0.8535 Test: 1.0803\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 055, Loss: 0.5641 Val: 0.8551 Test: 1.0571\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 056, Loss: 0.5488 Val: 0.8743 Test: 1.0898\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 057, Loss: 0.5339 Val: 0.8786 Test: 1.1380\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 058, Loss: 0.5073 Val: 0.8862 Test: 1.1519\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 059, Loss: 0.4718 Val: 0.8629 Test: 1.1279\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 060, Loss: 0.5440 Val: 0.8489 Test: 1.1320\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 061, Loss: 0.5512 Val: 0.8377 Test: 1.1193\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 062, Loss: 0.5363 Val: 0.8566 Test: 1.1072\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 063, Loss: 0.5176 Val: 0.8861 Test: 1.1456\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 064, Loss: 0.4827 Val: 0.8551 Test: 1.1175\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 065, Loss: 0.4906 Val: 0.8453 Test: 1.1979\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 066, Loss: 0.4209 Val: 0.8251 Test: 1.1856\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 067, Loss: 0.4319 Val: 0.8779 Test: 1.4641\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 068, Loss: 0.4101 Val: 0.9008 Test: 1.3574\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 069, Loss: 0.4495 Val: 1.3040 Test: 1.9098\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 070, Loss: 0.6754 Val: 1.4373 Test: 1.8591\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 071, Loss: 0.6178 Val: 1.2681 Test: 1.6535\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 072, Loss: 0.5682 Val: 1.0781 Test: 1.4281\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 073, Loss: 0.5580 Val: 0.9500 Test: 1.2331\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 074, Loss: 0.5431 Val: 0.8772 Test: 1.1270\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 075, Loss: 0.5187 Val: 0.8491 Test: 1.0650\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 076, Loss: 0.5013 Val: 0.8176 Test: 1.0971\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 077, Loss: 0.5019 Val: 0.9081 Test: 1.1767\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 078, Loss: 0.5180 Val: 0.8459 Test: 1.0915\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 079, Loss: 0.5256 Val: 0.8050 Test: 0.8840\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 080, Loss: 0.5741 Val: 0.8222 Test: 1.0130\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 081, Loss: 0.4632 Val: 1.2615 Test: 1.2033\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 082, Loss: 0.7003 Val: 1.5109 Test: 1.7780\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 083, Loss: 0.5803 Val: 1.0125 Test: 0.9929\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 084, Loss: 0.4777 Val: 1.1386 Test: 0.8294\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 085, Loss: 0.4952 Val: 1.0467 Test: 1.0292\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 086, Loss: 0.4526 Val: 1.0746 Test: 1.1563\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 087, Loss: 0.4625 Val: 1.0476 Test: 0.9379\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 088, Loss: 0.4010 Val: 1.0481 Test: 0.8734\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 089, Loss: 0.4798 Val: 1.0966 Test: 1.0270\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 090, Loss: 0.3455 Val: 1.1104 Test: 1.1235\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 091, Loss: 0.3959 Val: 1.1045 Test: 1.0953\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 092, Loss: 0.3467 Val: 1.0824 Test: 0.9999\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 093, Loss: 0.3530 Val: 1.1037 Test: 0.9748\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 094, Loss: 0.4896 Val: 1.0303 Test: 0.9792\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 095, Loss: 0.3927 Val: 1.0081 Test: 1.0100\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 096, Loss: 0.3834 Val: 0.9829 Test: 0.9050\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 097, Loss: 0.3626 Val: 1.0062 Test: 0.9097\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 098, Loss: 0.3960 Val: 1.0262 Test: 0.9370\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 099, Loss: 0.5758 Val: 1.0313 Test: 0.9618\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 100, Loss: 0.3781 Val: 1.0245 Test: 0.9560\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 101, Loss: 0.4922 Val: 1.0095 Test: 0.9390\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 102, Loss: 0.3427 Val: 1.0186 Test: 0.9344\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 103, Loss: 0.3746 Val: 1.0131 Test: 0.9353\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 104, Loss: 0.3323 Val: 0.9991 Test: 0.9418\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 105, Loss: 0.3299 Val: 0.9913 Test: 0.9488\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 106, Loss: 0.3377 Val: 1.0114 Test: 0.9696\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 107, Loss: 0.4000 Val: 1.0447 Test: 1.0447\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 108, Loss: 0.3413 Val: 1.0483 Test: 1.1008\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 109, Loss: 0.5734 Val: 1.0311 Test: 1.2242\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 110, Loss: 0.7111 Val: 1.8896 Test: 2.1255\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 111, Loss: 0.9152 Val: 1.7223 Test: 1.8942\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 112, Loss: 0.8389 Val: 1.5757 Test: 2.0178\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 113, Loss: 0.7907 Val: 1.2405 Test: 1.5042\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 114, Loss: 0.7408 Val: 1.1097 Test: 1.3614\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 115, Loss: 0.6598 Val: 1.0267 Test: 1.1635\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 116, Loss: 0.5605 Val: 1.0185 Test: 0.8949\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 117, Loss: 0.4832 Val: 1.0131 Test: 0.8580\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 118, Loss: 0.5349 Val: 1.0349 Test: 0.8605\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 119, Loss: 0.3892 Val: 1.0437 Test: 0.8591\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 120, Loss: 0.4625 Val: 0.9854 Test: 0.8405\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 121, Loss: 0.3819 Val: 0.9870 Test: 0.8570\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 122, Loss: 0.3963 Val: 1.0412 Test: 0.8715\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 123, Loss: 0.4488 Val: 1.0228 Test: 0.9225\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 124, Loss: 0.4456 Val: 1.0735 Test: 0.8965\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 125, Loss: 0.4688 Val: 1.0794 Test: 0.8633\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 126, Loss: 0.3766 Val: 1.0795 Test: 0.8779\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 127, Loss: 0.4251 Val: 1.0740 Test: 0.9231\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 128, Loss: 0.3991 Val: 1.0464 Test: 0.8739\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 129, Loss: 0.4958 Val: 0.9766 Test: 0.8721\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 130, Loss: 0.4380 Val: 0.9353 Test: 0.8498\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 131, Loss: 0.4673 Val: 1.0032 Test: 0.8340\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 132, Loss: 0.6357 Val: 0.9532 Test: 0.9462\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 133, Loss: 0.6249 Val: 0.9771 Test: 0.9355\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 134, Loss: 0.5503 Val: 1.0043 Test: 0.8799\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 135, Loss: 0.4337 Val: 0.9983 Test: 0.8691\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 136, Loss: 0.3811 Val: 1.0056 Test: 0.8472\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 137, Loss: 0.3565 Val: 1.0451 Test: 0.8404\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 138, Loss: 0.3963 Val: 1.0717 Test: 0.8599\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 139, Loss: 0.3716 Val: 1.0819 Test: 0.8687\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 140, Loss: 0.3697 Val: 1.0610 Test: 0.8272\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 141, Loss: 0.3512 Val: 0.9991 Test: 0.8017\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 142, Loss: 0.3887 Val: 1.0771 Test: 0.8028\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 143, Loss: 0.3363 Val: 1.0807 Test: 0.8097\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 144, Loss: 0.2863 Val: 1.0883 Test: 0.8114\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 145, Loss: 0.3796 Val: 1.0634 Test: 0.8175\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 146, Loss: 0.2912 Val: 1.0644 Test: 0.8112\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 147, Loss: 0.4034 Val: 1.0605 Test: 0.8157\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 148, Loss: 0.3796 Val: 1.0448 Test: 0.8194\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 149, Loss: 0.3354 Val: 1.0242 Test: 0.8213\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 150, Loss: 0.3011 Val: 1.0165 Test: 0.8003\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 151, Loss: 0.3704 Val: 1.0135 Test: 0.7820\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 152, Loss: 0.2835 Val: 1.0074 Test: 0.7762\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 153, Loss: 0.3664 Val: 1.0051 Test: 0.7700\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 154, Loss: 0.4007 Val: 1.0060 Test: 0.7754\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 155, Loss: 0.4339 Val: 1.0248 Test: 0.8799\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 156, Loss: 0.3698 Val: 1.0215 Test: 1.0067\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 157, Loss: 0.4109 Val: 1.0110 Test: 0.8435\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 158, Loss: 0.3308 Val: 1.0079 Test: 0.7883\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 159, Loss: 0.3416 Val: 0.9990 Test: 0.7708\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 160, Loss: 0.3569 Val: 0.9898 Test: 0.7618\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 161, Loss: 0.3823 Val: 0.9955 Test: 0.7738\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 162, Loss: 0.3578 Val: 0.9973 Test: 0.8016\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 163, Loss: 0.3878 Val: 0.9799 Test: 0.8419\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 164, Loss: 0.3571 Val: 0.9634 Test: 0.8233\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 165, Loss: 0.3426 Val: 0.9602 Test: 0.8309\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 166, Loss: 0.3701 Val: 0.9708 Test: 0.8138\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 167, Loss: 0.3042 Val: 0.9828 Test: 0.8005\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 168, Loss: 0.3185 Val: 0.9981 Test: 0.8032\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 169, Loss: 0.2942 Val: 1.0031 Test: 0.7804\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 170, Loss: 0.3815 Val: 0.9950 Test: 0.7662\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 171, Loss: 0.2895 Val: 0.9827 Test: 0.7653\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 172, Loss: 0.3363 Val: 0.9761 Test: 0.7620\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 173, Loss: 0.3388 Val: 0.9751 Test: 0.7594\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 174, Loss: 0.2928 Val: 0.9767 Test: 0.7692\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 175, Loss: 0.3841 Val: 0.9803 Test: 0.7876\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 176, Loss: 0.3600 Val: 0.9840 Test: 0.8053\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 177, Loss: 0.3018 Val: 0.9856 Test: 0.8227\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 178, Loss: 0.3511 Val: 0.9813 Test: 0.8298\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 179, Loss: 0.3649 Val: 0.9810 Test: 0.8290\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 180, Loss: 0.3255 Val: 0.9754 Test: 0.8277\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 181, Loss: 0.3231 Val: 0.9788 Test: 0.8167\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 182, Loss: 0.3575 Val: 0.9952 Test: 0.8146\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 183, Loss: 0.3347 Val: 1.0238 Test: 0.8100\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 184, Loss: 0.2939 Val: 1.0405 Test: 0.8131\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 185, Loss: 0.3417 Val: 1.0493 Test: 0.8158\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 186, Loss: 0.3123 Val: 1.0472 Test: 0.7836\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 187, Loss: 0.3392 Val: 1.0286 Test: 0.7648\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 188, Loss: 0.2804 Val: 1.0031 Test: 0.7521\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 189, Loss: 0.3753 Val: 0.9917 Test: 0.7638\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 190, Loss: 0.3175 Val: 0.9833 Test: 0.7755\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 191, Loss: 0.3533 Val: 0.9822 Test: 0.7837\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 192, Loss: 0.3524 Val: 0.9838 Test: 0.7877\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 193, Loss: 0.3465 Val: 1.0100 Test: 0.7697\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 194, Loss: 0.2763 Val: 1.0264 Test: 0.7634\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 195, Loss: 0.3483 Val: 1.0135 Test: 0.7687\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 196, Loss: 0.3655 Val: 0.9938 Test: 0.7812\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 197, Loss: 0.3727 Val: 0.9690 Test: 0.8095\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 198, Loss: 0.2781 Val: 0.9550 Test: 0.8156\n",
      "16\n",
      "16\n",
      "16\n",
      "1\n",
      "Epoch: 199, Loss: 0.3522 Val: 0.9566 Test: 0.7921\n",
      "notum\n",
      "\n",
      "torch.Size([2479, 115])\n",
      "{'name': 'notum', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa61032f070>, 'pre_filter': None, '_indices': [42, 32, 21, 97, 96, 78, 113, 46, 14, 61, 33, 76, 106, 12, 66, 101, 53, 55, 30, 25, 68, 71, 81, 5, 70, 29, 39, 75, 19, 47, 9, 123, 73, 67, 62, 11, 2, 87, 0, 107, 38, 77, 48, 104, 103, 4, 27, 43, 69, 41, 34, 99, 115, 44, 98, 7, 95, 65, 40, 112, 8, 72, 102, 13, 114, 105, 92, 111, 24, 16, 1, 84, 108, 100, 90, 120, 117, 31, 51, 126, 6, 88, 36, 74, 124, 82, 22, 121, 3, 122, 52, 23, 119, 50, 17, 79, 94, 125, 28, 91, 37, 20, 110, 80, 85, 45, 60, 86, 64, 58, 127, 10, 15, 35, 93, 109, 83, 116, 63, 26, 54, 18, 118, 56, 57, 89, 49, 59], 'data': Data(x=[2479, 115], edge_index=[2, 5338], edge_attr=[5338, 7], y=[128, 1], smiles=[128]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   22,   47,   62,   79,   96,  113,  132,  153,  171,  185,  198,\n",
      "         217,  235,  254,  269,  284,  308,  323,  339,  357,  373,  397,  420,\n",
      "         435,  444,  461,  477,  487,  506,  524,  539,  558,  577,  602,  619,\n",
      "         637,  655,  677,  700,  721,  738,  757,  773,  789,  808,  832,  849,\n",
      "         864,  883,  906,  927,  946,  966,  981, 1006, 1027, 1046, 1064, 1087,\n",
      "        1106, 1120, 1138, 1154, 1171, 1191, 1209, 1227, 1242, 1264, 1285, 1310,\n",
      "        1334, 1361, 1386, 1402, 1428, 1454, 1471, 1487, 1503, 1522, 1543, 1563,\n",
      "        1587, 1609, 1633, 1658, 1679, 1702, 1725, 1749, 1777, 1793, 1812, 1830,\n",
      "        1847, 1864, 1884, 1903, 1921, 1940, 1966, 1985, 2010, 2032, 2057, 2073,\n",
      "        2086, 2106, 2129, 2144, 2165, 2188, 2212, 2238, 2256, 2275, 2284, 2301,\n",
      "        2318, 2338, 2354, 2370, 2384, 2408, 2436, 2462, 2479]), 'edge_index': tensor([   0,   48,  102,  134,  170,  206,  242,  284,  328,  366,  396,  422,\n",
      "         462,  500,  540,  572,  604,  656,  688,  722,  760,  794,  846,  896,\n",
      "         928,  946,  982, 1016, 1036, 1076, 1114, 1146, 1186, 1226, 1280, 1316,\n",
      "        1354, 1392, 1440, 1492, 1538, 1574, 1614, 1648, 1682, 1722, 1776, 1812,\n",
      "        1844, 1884, 1934, 1980, 2020, 2064, 2096, 2150, 2194, 2234, 2272, 2322,\n",
      "        2362, 2392, 2432, 2466, 2502, 2544, 2582, 2620, 2652, 2700, 2746, 2802,\n",
      "        2856, 2918, 2974, 3008, 3068, 3126, 3162, 3196, 3230, 3270, 3314, 3358,\n",
      "        3412, 3460, 3514, 3570, 3616, 3668, 3718, 3770, 3832, 3866, 3908, 3946,\n",
      "        3982, 4018, 4060, 4100, 4138, 4178, 4234, 4274, 4328, 4376, 4430, 4464,\n",
      "        4492, 4534, 4586, 4618, 4664, 4712, 4764, 4822, 4860, 4900, 4918, 4954,\n",
      "        4990, 5032, 5066, 5100, 5130, 5184, 5246, 5302, 5338]), 'edge_attr': tensor([   0,   48,  102,  134,  170,  206,  242,  284,  328,  366,  396,  422,\n",
      "         462,  500,  540,  572,  604,  656,  688,  722,  760,  794,  846,  896,\n",
      "         928,  946,  982, 1016, 1036, 1076, 1114, 1146, 1186, 1226, 1280, 1316,\n",
      "        1354, 1392, 1440, 1492, 1538, 1574, 1614, 1648, 1682, 1722, 1776, 1812,\n",
      "        1844, 1884, 1934, 1980, 2020, 2064, 2096, 2150, 2194, 2234, 2272, 2322,\n",
      "        2362, 2392, 2432, 2466, 2502, 2544, 2582, 2620, 2652, 2700, 2746, 2802,\n",
      "        2856, 2918, 2974, 3008, 3068, 3126, 3162, 3196, 3230, 3270, 3314, 3358,\n",
      "        3412, 3460, 3514, 3570, 3616, 3668, 3718, 3770, 3832, 3866, 3908, 3946,\n",
      "        3982, 4018, 4060, 4100, 4138, 4178, 4234, 4274, 4328, 4376, 4430, 4464,\n",
      "        4492, 4534, 4586, 4618, 4664, 4712, 4764, 4822, 4860, 4900, 4918, 4954,\n",
      "        4990, 5032, 5066, 5100, 5130, 5184, 5246, 5302, 5338]), 'y': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128]), 'smiles': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128])}), '_data_list': None}\n",
      "minv: 4.0\n",
      "maxv: 9.0\n",
      "emb_dim: 300\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 000, Loss: 0.7597 Val: 2.7143 Test: 2.7802\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 001, Loss: 0.7542 Val: 2.6219 Test: 2.7106\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 002, Loss: 0.7147 Val: 2.5657 Test: 2.6674\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 003, Loss: 0.7548 Val: 2.4929 Test: 2.5991\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 004, Loss: 0.7540 Val: 2.3975 Test: 2.5114\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 005, Loss: 0.6831 Val: 2.3330 Test: 2.4411\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 006, Loss: 0.6789 Val: 2.2836 Test: 2.4006\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 007, Loss: 0.6664 Val: 2.2226 Test: 2.3410\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 008, Loss: 0.6261 Val: 2.1606 Test: 2.2865\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 009, Loss: 0.6628 Val: 2.0617 Test: 2.2123\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 010, Loss: 0.6246 Val: 2.0325 Test: 2.2073\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 011, Loss: 0.6277 Val: 1.9990 Test: 2.1828\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 012, Loss: 0.6489 Val: 1.9088 Test: 2.0631\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 013, Loss: 0.6233 Val: 1.9607 Test: 2.0957\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 014, Loss: 0.6164 Val: 1.9135 Test: 2.1202\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 015, Loss: 0.6512 Val: 1.7940 Test: 1.9377\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 016, Loss: 0.6102 Val: 1.6388 Test: 1.7592\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 017, Loss: 0.5780 Val: 1.6713 Test: 1.8596\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 018, Loss: 0.5461 Val: 1.6023 Test: 1.8136\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 019, Loss: 0.6236 Val: 1.5513 Test: 1.7504\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 020, Loss: 0.5862 Val: 1.5483 Test: 1.7946\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 021, Loss: 0.5846 Val: 1.4953 Test: 1.7485\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 022, Loss: 0.5694 Val: 1.3222 Test: 1.5797\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 023, Loss: 0.5336 Val: 1.2360 Test: 1.4562\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 024, Loss: 0.5383 Val: 1.2728 Test: 1.5502\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 025, Loss: 0.4994 Val: 1.1893 Test: 1.4371\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 026, Loss: 0.5461 Val: 1.0598 Test: 1.3549\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 027, Loss: 0.5246 Val: 1.0130 Test: 1.3108\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 028, Loss: 0.5084 Val: 1.1997 Test: 1.3367\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 029, Loss: 0.6534 Val: 1.0838 Test: 1.2880\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 030, Loss: 0.5393 Val: 1.0215 Test: 1.2635\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 031, Loss: 0.4837 Val: 0.8974 Test: 1.0397\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 032, Loss: 0.4768 Val: 0.8590 Test: 1.0026\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 033, Loss: 0.5005 Val: 0.8422 Test: 1.0316\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 034, Loss: 0.4690 Val: 0.7504 Test: 0.9061\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 035, Loss: 0.4439 Val: 0.6651 Test: 0.9346\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 036, Loss: 0.4865 Val: 0.6913 Test: 0.9213\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 037, Loss: 0.4620 Val: 0.7641 Test: 0.8781\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 038, Loss: 0.4640 Val: 0.6483 Test: 0.8219\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 039, Loss: 0.4357 Val: 0.6757 Test: 0.9157\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 040, Loss: 0.4282 Val: 0.7028 Test: 0.8007\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 041, Loss: 0.4714 Val: 0.7147 Test: 0.8883\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 042, Loss: 0.4880 Val: 0.6345 Test: 0.8833\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 043, Loss: 0.4123 Val: 0.6012 Test: 0.7439\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 044, Loss: 0.4603 Val: 0.6889 Test: 0.7160\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 045, Loss: 0.4402 Val: 0.6234 Test: 0.8580\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 046, Loss: 0.4258 Val: 0.5961 Test: 0.8675\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 047, Loss: 0.4742 Val: 0.5596 Test: 0.7633\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 048, Loss: 0.4281 Val: 0.6124 Test: 0.7088\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 049, Loss: 0.4048 Val: 0.6197 Test: 0.7767\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 050, Loss: 0.4399 Val: 0.6602 Test: 0.7629\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 051, Loss: 0.4315 Val: 0.6769 Test: 0.7473\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 052, Loss: 0.4457 Val: 0.6668 Test: 0.7411\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 053, Loss: 0.4937 Val: 0.6578 Test: 0.7862\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 054, Loss: 0.5312 Val: 0.5638 Test: 0.8913\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 055, Loss: 0.4854 Val: 0.5082 Test: 0.7129\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 056, Loss: 0.4701 Val: 0.6057 Test: 0.7733\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 057, Loss: 0.4282 Val: 0.6184 Test: 0.8408\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 058, Loss: 0.4779 Val: 0.6512 Test: 0.8191\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 059, Loss: 0.4095 Val: 0.6487 Test: 0.8198\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 060, Loss: 0.3978 Val: 0.6014 Test: 0.7388\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 061, Loss: 0.3957 Val: 0.6894 Test: 0.7251\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 062, Loss: 0.4191 Val: 0.6867 Test: 0.7578\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 063, Loss: 0.4481 Val: 0.6752 Test: 0.7879\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 064, Loss: 0.3759 Val: 0.6751 Test: 0.7842\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 065, Loss: 0.3579 Val: 0.6717 Test: 0.7100\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 066, Loss: 0.3993 Val: 0.6564 Test: 0.6961\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 067, Loss: 0.3703 Val: 0.5968 Test: 0.7405\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 068, Loss: 0.4748 Val: 0.5695 Test: 0.9296\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 069, Loss: 0.5068 Val: 0.6693 Test: 0.9721\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 070, Loss: 0.4974 Val: 0.5198 Test: 0.7390\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 071, Loss: 0.4607 Val: 0.5666 Test: 0.8252\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 072, Loss: 0.4488 Val: 0.7502 Test: 0.8903\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 073, Loss: 0.4785 Val: 0.6503 Test: 0.8144\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 074, Loss: 0.4722 Val: 0.5887 Test: 0.8078\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 075, Loss: 0.3481 Val: 0.5223 Test: 0.7962\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 076, Loss: 0.3787 Val: 0.5703 Test: 0.8498\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 077, Loss: 0.4661 Val: 0.6218 Test: 0.8229\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 078, Loss: 0.3946 Val: 0.6442 Test: 0.7579\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 079, Loss: 0.3798 Val: 0.6168 Test: 0.6100\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 080, Loss: 0.3866 Val: 0.6302 Test: 0.6523\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 081, Loss: 0.3716 Val: 0.6537 Test: 0.7338\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 082, Loss: 0.3535 Val: 0.6302 Test: 0.7794\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 083, Loss: 0.3758 Val: 0.5859 Test: 0.7252\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 084, Loss: 0.3657 Val: 0.5518 Test: 0.7373\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 085, Loss: 0.3701 Val: 0.5607 Test: 0.7355\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 086, Loss: 0.3167 Val: 0.5240 Test: 0.6659\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 087, Loss: 0.3596 Val: 0.5667 Test: 0.6106\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 088, Loss: 0.4214 Val: 0.5775 Test: 0.6556\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 089, Loss: 0.3973 Val: 0.5353 Test: 0.7932\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 090, Loss: 0.3507 Val: 0.5689 Test: 0.9186\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 091, Loss: 0.3295 Val: 0.5925 Test: 0.8665\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 092, Loss: 0.3837 Val: 0.5826 Test: 0.7311\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 093, Loss: 0.3817 Val: 0.5764 Test: 0.7474\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 094, Loss: 0.4538 Val: 0.5745 Test: 0.8342\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 095, Loss: 0.3709 Val: 0.5603 Test: 0.8246\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 096, Loss: 0.3351 Val: 0.6234 Test: 0.7703\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 097, Loss: 0.5458 Val: 0.5927 Test: 0.7176\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 098, Loss: 0.4079 Val: 0.5783 Test: 0.6436\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 099, Loss: 0.3864 Val: 0.5604 Test: 0.7215\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 100, Loss: 0.3989 Val: 0.6020 Test: 0.7129\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 101, Loss: 0.3904 Val: 0.5554 Test: 0.6888\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 102, Loss: 0.3700 Val: 0.5644 Test: 0.7408\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 103, Loss: 0.3896 Val: 0.5791 Test: 0.7594\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 104, Loss: 0.4021 Val: 0.5759 Test: 0.7779\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 105, Loss: 0.4192 Val: 0.5634 Test: 0.7668\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 106, Loss: 0.3339 Val: 0.5562 Test: 0.7839\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 107, Loss: 0.3446 Val: 0.6041 Test: 0.8090\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 108, Loss: 0.4044 Val: 0.5690 Test: 0.8403\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 109, Loss: 0.3736 Val: 0.5736 Test: 0.7680\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 110, Loss: 0.3954 Val: 0.5551 Test: 0.7424\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 111, Loss: 0.3406 Val: 0.6072 Test: 0.7144\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 112, Loss: 0.3347 Val: 0.6058 Test: 0.6623\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 113, Loss: 0.5165 Val: 0.5771 Test: 0.6498\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 114, Loss: 0.4248 Val: 0.6858 Test: 0.7286\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 115, Loss: 0.4516 Val: 0.6479 Test: 0.7988\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 116, Loss: 0.5062 Val: 0.6190 Test: 0.8249\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 117, Loss: 0.4153 Val: 0.5435 Test: 0.7935\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 118, Loss: 0.4505 Val: 0.5667 Test: 0.6992\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 119, Loss: 0.4283 Val: 0.5931 Test: 0.6393\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 120, Loss: 0.4232 Val: 0.6046 Test: 0.6395\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 121, Loss: 0.4195 Val: 0.5593 Test: 0.6410\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 122, Loss: 0.3656 Val: 0.5002 Test: 0.6446\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 123, Loss: 0.3642 Val: 0.5115 Test: 0.6475\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 124, Loss: 0.3990 Val: 0.5675 Test: 0.6848\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 125, Loss: 0.4774 Val: 0.6604 Test: 0.6736\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 126, Loss: 0.4818 Val: 0.6308 Test: 0.7091\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 127, Loss: 0.3671 Val: 0.6089 Test: 0.7117\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 128, Loss: 0.4190 Val: 0.6764 Test: 0.8506\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 129, Loss: 0.4258 Val: 0.6485 Test: 0.8215\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 130, Loss: 0.4024 Val: 0.5881 Test: 0.7818\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 131, Loss: 0.4338 Val: 0.5799 Test: 0.7725\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 132, Loss: 0.4959 Val: 0.6331 Test: 0.7498\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 133, Loss: 0.4901 Val: 0.5532 Test: 0.7709\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 134, Loss: 0.4453 Val: 0.5195 Test: 0.7773\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 135, Loss: 0.4315 Val: 0.5311 Test: 0.8533\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 136, Loss: 0.4046 Val: 0.5663 Test: 0.7729\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 137, Loss: 0.4195 Val: 0.6076 Test: 0.7296\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 138, Loss: 0.3995 Val: 0.6112 Test: 0.7509\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 139, Loss: 0.4100 Val: 0.5836 Test: 0.7670\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 140, Loss: 0.3731 Val: 0.6285 Test: 0.8138\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 141, Loss: 0.3856 Val: 0.6505 Test: 0.7847\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 142, Loss: 0.3793 Val: 0.6382 Test: 0.7218\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 143, Loss: 0.3663 Val: 0.6123 Test: 0.6869\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 144, Loss: 0.3875 Val: 0.6037 Test: 0.7323\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 145, Loss: 0.3733 Val: 0.6277 Test: 0.8062\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 146, Loss: 0.3724 Val: 0.6131 Test: 0.7806\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 147, Loss: 0.3880 Val: 0.5904 Test: 0.7993\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 148, Loss: 0.3209 Val: 0.5907 Test: 0.7843\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 149, Loss: 0.3415 Val: 0.5739 Test: 0.7242\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 150, Loss: 0.3364 Val: 0.5013 Test: 0.7175\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 151, Loss: 0.3644 Val: 0.4605 Test: 0.7694\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 152, Loss: 0.3148 Val: 0.5447 Test: 0.7190\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 153, Loss: 0.3662 Val: 0.5466 Test: 0.6542\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 154, Loss: 0.4182 Val: 0.5336 Test: 0.7313\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 155, Loss: 0.3637 Val: 0.5733 Test: 0.8112\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 156, Loss: 0.3480 Val: 0.5880 Test: 0.8302\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 157, Loss: 0.3881 Val: 0.6031 Test: 0.7661\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 158, Loss: 0.3645 Val: 0.6184 Test: 0.6696\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 159, Loss: 0.4142 Val: 0.5923 Test: 0.6761\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 160, Loss: 0.4203 Val: 0.5529 Test: 0.6744\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 161, Loss: 0.4128 Val: 0.6244 Test: 0.7318\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 162, Loss: 0.3717 Val: 0.5340 Test: 0.7287\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 163, Loss: 0.4894 Val: 0.5269 Test: 0.6734\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 164, Loss: 0.4217 Val: 0.5848 Test: 0.6568\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 165, Loss: 0.3553 Val: 0.5807 Test: 0.6484\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 166, Loss: 0.5263 Val: 0.6142 Test: 0.6062\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 167, Loss: 0.4524 Val: 0.6136 Test: 0.7609\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 168, Loss: 0.3693 Val: 0.6436 Test: 0.8061\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 169, Loss: 0.3534 Val: 0.6434 Test: 0.7271\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 170, Loss: 0.3680 Val: 0.6125 Test: 0.6384\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 171, Loss: 0.3717 Val: 0.6061 Test: 0.6545\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 172, Loss: 0.4415 Val: 0.6025 Test: 0.6422\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 173, Loss: 0.3430 Val: 0.6297 Test: 0.6357\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 174, Loss: 0.3550 Val: 0.6345 Test: 0.7808\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 175, Loss: 0.3489 Val: 0.6427 Test: 0.7471\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 176, Loss: 0.3474 Val: 0.6686 Test: 0.7364\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 177, Loss: 0.3483 Val: 0.6018 Test: 0.6438\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 178, Loss: 0.3585 Val: 0.6017 Test: 0.6344\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 179, Loss: 0.3222 Val: 0.6118 Test: 0.6144\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 180, Loss: 0.3690 Val: 0.5525 Test: 0.7700\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 181, Loss: 0.3567 Val: 0.6039 Test: 0.8796\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 182, Loss: 0.3673 Val: 0.6520 Test: 0.8489\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 183, Loss: 0.4424 Val: 0.5489 Test: 0.7598\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 184, Loss: 0.3537 Val: 0.5473 Test: 0.6922\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 185, Loss: 0.3605 Val: 0.5270 Test: 0.6591\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 186, Loss: 0.4148 Val: 0.5369 Test: 0.6592\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 187, Loss: 0.3042 Val: 0.5920 Test: 0.6671\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 188, Loss: 0.3834 Val: 0.5763 Test: 0.7358\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 189, Loss: 0.3805 Val: 0.5282 Test: 0.7215\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 190, Loss: 0.3129 Val: 0.5559 Test: 0.6230\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 191, Loss: 0.3749 Val: 0.5660 Test: 0.6354\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 192, Loss: 0.3314 Val: 0.6078 Test: 0.7647\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 193, Loss: 0.2964 Val: 0.5799 Test: 0.7776\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 194, Loss: 0.3136 Val: 0.5952 Test: 0.7435\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 195, Loss: 0.3073 Val: 0.5776 Test: 0.7815\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 196, Loss: 0.3046 Val: 0.6411 Test: 0.8295\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 197, Loss: 0.2857 Val: 0.6785 Test: 0.8702\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 198, Loss: 0.3126 Val: 0.6462 Test: 0.7909\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "Epoch: 199, Loss: 0.3070 Val: 0.5689 Test: 0.7223\n",
      "eaat3\n",
      "\n",
      "torch.Size([3180, 115])\n",
      "{'name': 'eaat3', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fa61033d880>, 'pre_filter': None, '_indices': [15, 149, 10, 138, 19, 132, 111, 62, 98, 84, 106, 165, 32, 4, 72, 44, 97, 82, 33, 159, 59, 121, 108, 50, 133, 30, 147, 95, 67, 20, 80, 52, 150, 120, 27, 115, 40, 118, 12, 104, 75, 38, 23, 73, 6, 139, 161, 71, 107, 58, 2, 112, 134, 13, 101, 51, 68, 45, 162, 77, 92, 103, 136, 141, 60, 61, 69, 14, 116, 8, 154, 64, 163, 123, 129, 87, 3, 43, 7, 109, 74, 105, 153, 24, 31, 89, 83, 144, 78, 113, 25, 36, 9, 21, 145, 93, 91, 66, 76, 125, 18, 102, 135, 28, 1, 88, 117, 81, 57, 86, 164, 29, 148, 35, 158, 127, 16, 140, 119, 128, 11, 79, 65, 99, 146, 160, 124, 47, 26, 70, 55, 110, 22, 49, 17, 41, 5, 85, 39, 142, 131, 130, 152, 56, 37, 122, 48, 157, 0, 42, 53, 46, 100, 156, 143, 151, 114, 90, 94, 126, 54, 34, 96, 137, 63, 155, 166, 167], 'data': Data(x=[3180, 115], edge_index=[2, 6420], edge_attr=[6420, 7], y=[168, 1], smiles=[168]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   14,   28,   38,   48,   64,   80,   93,  106,  115,  124,  142,\n",
      "         160,  170,  180,  197,  214,  228,  242,  256,  270,  286,  302,  319,\n",
      "         336,  351,  366,  391,  416,  432,  445,  461,  477,  493,  506,  522,\n",
      "         538,  554,  570,  586,  602,  615,  628,  658,  688,  718,  748,  779,\n",
      "         810,  840,  870,  902,  934,  967, 1000, 1030, 1060, 1073, 1086, 1100,\n",
      "        1114, 1130, 1146, 1156, 1166, 1175, 1184, 1197, 1210, 1224, 1238, 1248,\n",
      "        1258, 1272, 1286, 1302, 1318, 1331, 1344, 1360, 1376, 1394, 1412, 1429,\n",
      "        1446, 1461, 1476, 1492, 1508, 1524, 1540, 1556, 1572, 1588, 1604, 1629,\n",
      "        1654, 1671, 1688, 1718, 1748, 1779, 1810, 1840, 1870, 1903, 1936, 1966,\n",
      "        1996, 2028, 2058, 2088, 2120, 2133, 2146, 2160, 2174, 2184, 2194, 2210,\n",
      "        2219, 2235, 2244, 2254, 2264, 2278, 2292, 2305, 2318, 2336, 2354, 2371,\n",
      "        2388, 2401, 2417, 2430, 2446, 2460, 2474, 2490, 2506, 2522, 2538, 2554,\n",
      "        2570, 2586, 2602, 2618, 2634, 2649, 2664, 2681, 2698, 2729, 2760, 2790,\n",
      "        2820, 2845, 2870, 2900, 2930, 2963, 2996, 3028, 3060, 3090, 3120, 3150,\n",
      "        3180]), 'edge_index': tensor([   0,   28,   56,   74,   92,  124,  156,  180,  204,  220,  236,  272,\n",
      "         308,  326,  344,  378,  412,  440,  468,  496,  524,  556,  588,  622,\n",
      "         656,  686,  716,  768,  820,  852,  876,  908,  940,  972,  996, 1028,\n",
      "        1060, 1092, 1124, 1156, 1188, 1212, 1236, 1298, 1360, 1422, 1484, 1548,\n",
      "        1612, 1674, 1736, 1802, 1868, 1938, 2008, 2074, 2140, 2164, 2188, 2216,\n",
      "        2244, 2276, 2308, 2326, 2344, 2360, 2376, 2400, 2424, 2452, 2480, 2498,\n",
      "        2516, 2544, 2572, 2604, 2636, 2660, 2684, 2716, 2748, 2784, 2820, 2854,\n",
      "        2888, 2918, 2948, 2980, 3012, 3044, 3076, 3108, 3140, 3172, 3204, 3256,\n",
      "        3308, 3342, 3376, 3438, 3500, 3564, 3628, 3694, 3760, 3830, 3900, 3962,\n",
      "        4024, 4090, 4152, 4214, 4280, 4304, 4328, 4356, 4384, 4402, 4420, 4452,\n",
      "        4468, 4500, 4516, 4534, 4552, 4580, 4608, 4632, 4656, 4692, 4728, 4762,\n",
      "        4796, 4820, 4852, 4876, 4908, 4936, 4964, 4996, 5028, 5060, 5092, 5124,\n",
      "        5156, 5188, 5220, 5252, 5284, 5314, 5344, 5378, 5412, 5476, 5540, 5602,\n",
      "        5664, 5716, 5768, 5834, 5900, 5970, 6040, 6106, 6172, 6234, 6296, 6358,\n",
      "        6420]), 'edge_attr': tensor([   0,   28,   56,   74,   92,  124,  156,  180,  204,  220,  236,  272,\n",
      "         308,  326,  344,  378,  412,  440,  468,  496,  524,  556,  588,  622,\n",
      "         656,  686,  716,  768,  820,  852,  876,  908,  940,  972,  996, 1028,\n",
      "        1060, 1092, 1124, 1156, 1188, 1212, 1236, 1298, 1360, 1422, 1484, 1548,\n",
      "        1612, 1674, 1736, 1802, 1868, 1938, 2008, 2074, 2140, 2164, 2188, 2216,\n",
      "        2244, 2276, 2308, 2326, 2344, 2360, 2376, 2400, 2424, 2452, 2480, 2498,\n",
      "        2516, 2544, 2572, 2604, 2636, 2660, 2684, 2716, 2748, 2784, 2820, 2854,\n",
      "        2888, 2918, 2948, 2980, 3012, 3044, 3076, 3108, 3140, 3172, 3204, 3256,\n",
      "        3308, 3342, 3376, 3438, 3500, 3564, 3628, 3694, 3760, 3830, 3900, 3962,\n",
      "        4024, 4090, 4152, 4214, 4280, 4304, 4328, 4356, 4384, 4402, 4420, 4452,\n",
      "        4468, 4500, 4516, 4534, 4552, 4580, 4608, 4632, 4656, 4692, 4728, 4762,\n",
      "        4796, 4820, 4852, 4876, 4908, 4936, 4964, 4996, 5028, 5060, 5092, 5124,\n",
      "        5156, 5188, 5220, 5252, 5284, 5314, 5344, 5378, 5412, 5476, 5540, 5602,\n",
      "        5664, 5716, 5768, 5834, 5900, 5970, 6040, 6106, 6172, 6234, 6296, 6358,\n",
      "        6420]), 'y': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168]), 'smiles': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168])}), '_data_list': None}\n",
      "minv: 4.0\n",
      "maxv: 8.899999618530273\n",
      "emb_dim: 300\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 000, Loss: 0.6939 Val: 2.6662 Test: 2.3992\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 001, Loss: 0.7055 Val: 2.5582 Test: 2.3006\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 002, Loss: 0.6769 Val: 2.4453 Test: 2.1980\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 003, Loss: 0.6935 Val: 2.3322 Test: 2.1113\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 004, Loss: 0.6804 Val: 2.2598 Test: 2.0186\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 005, Loss: 0.6973 Val: 2.1573 Test: 1.9110\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 006, Loss: 0.6444 Val: 2.0791 Test: 1.8625\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 007, Loss: 0.6303 Val: 1.9849 Test: 1.7826\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 008, Loss: 0.6216 Val: 1.9109 Test: 1.7133\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 009, Loss: 0.6067 Val: 1.8099 Test: 1.6303\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 010, Loss: 0.6198 Val: 1.7089 Test: 1.5430\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 011, Loss: 0.5242 Val: 1.6086 Test: 1.4669\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 012, Loss: 0.6073 Val: 1.4988 Test: 1.3907\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 013, Loss: 0.5389 Val: 1.3942 Test: 1.3328\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 014, Loss: 0.5730 Val: 1.3285 Test: 1.2392\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 015, Loss: 0.5961 Val: 1.2523 Test: 1.1932\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 016, Loss: 0.5527 Val: 1.1507 Test: 1.1197\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 017, Loss: 0.5584 Val: 1.0374 Test: 1.0223\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 018, Loss: 0.5842 Val: 1.0220 Test: 0.9991\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 019, Loss: 0.5491 Val: 1.0472 Test: 0.9640\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 020, Loss: 0.5579 Val: 0.9943 Test: 0.9426\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 021, Loss: 0.5401 Val: 0.8857 Test: 0.8923\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 022, Loss: 0.5453 Val: 0.8727 Test: 0.8980\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 023, Loss: 0.5668 Val: 0.9328 Test: 0.9291\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 024, Loss: 0.5547 Val: 1.0097 Test: 0.9439\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 025, Loss: 0.5426 Val: 0.8875 Test: 0.8245\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 026, Loss: 0.5259 Val: 0.8799 Test: 0.8473\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 027, Loss: 0.5548 Val: 0.7549 Test: 0.8200\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 028, Loss: 0.5223 Val: 0.7570 Test: 0.8400\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 029, Loss: 0.4948 Val: 0.7964 Test: 0.8311\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 030, Loss: 0.5635 Val: 0.7508 Test: 0.8145\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 031, Loss: 0.5686 Val: 0.7075 Test: 0.8120\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 032, Loss: 0.5328 Val: 0.6774 Test: 0.7862\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 033, Loss: 0.5401 Val: 0.6845 Test: 0.7882\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 034, Loss: 0.5191 Val: 0.6959 Test: 0.7948\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 035, Loss: 0.5481 Val: 0.6643 Test: 0.8298\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 036, Loss: 0.4758 Val: 0.7005 Test: 0.7086\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 037, Loss: 0.5057 Val: 0.7132 Test: 0.7321\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 038, Loss: 0.5468 Val: 0.6880 Test: 0.7127\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 039, Loss: 0.5434 Val: 0.6821 Test: 0.7825\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 040, Loss: 0.4823 Val: 0.6797 Test: 0.7874\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 041, Loss: 0.5406 Val: 0.7081 Test: 0.8053\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 042, Loss: 0.5100 Val: 0.7481 Test: 0.7629\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 043, Loss: 0.5488 Val: 0.7286 Test: 0.7737\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 044, Loss: 0.5243 Val: 0.7064 Test: 0.6690\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 045, Loss: 0.4749 Val: 0.7197 Test: 0.7519\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 046, Loss: 0.5162 Val: 0.6831 Test: 0.7690\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 047, Loss: 0.4835 Val: 0.7284 Test: 0.7605\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 048, Loss: 0.4868 Val: 0.7068 Test: 0.7405\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 049, Loss: 0.5201 Val: 0.6900 Test: 0.7995\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 050, Loss: 0.4908 Val: 0.7178 Test: 0.8104\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 051, Loss: 0.5093 Val: 0.7117 Test: 0.8107\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 052, Loss: 0.5221 Val: 0.7253 Test: 0.8070\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 053, Loss: 0.4790 Val: 0.6912 Test: 0.8017\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 054, Loss: 0.5219 Val: 0.6929 Test: 0.7667\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 055, Loss: 0.5323 Val: 0.6742 Test: 0.7762\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 056, Loss: 0.5061 Val: 0.6615 Test: 0.7767\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 057, Loss: 0.4822 Val: 0.6633 Test: 0.7475\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 058, Loss: 0.4979 Val: 0.6499 Test: 0.7318\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 059, Loss: 0.5194 Val: 0.6822 Test: 0.7684\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 060, Loss: 0.4332 Val: 0.7032 Test: 0.7990\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 061, Loss: 0.5025 Val: 0.7210 Test: 0.8190\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 062, Loss: 0.5060 Val: 0.6987 Test: 0.7801\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 063, Loss: 0.5397 Val: 0.7361 Test: 0.7941\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 064, Loss: 0.5220 Val: 0.6982 Test: 0.7622\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 065, Loss: 0.5717 Val: 0.6960 Test: 0.7888\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 066, Loss: 0.5673 Val: 0.7208 Test: 0.7423\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 067, Loss: 0.5397 Val: 0.7065 Test: 0.7382\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 068, Loss: 0.5038 Val: 0.6914 Test: 0.7812\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 069, Loss: 0.5276 Val: 0.6957 Test: 0.7493\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 070, Loss: 0.5629 Val: 0.6911 Test: 0.7331\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 071, Loss: 0.4908 Val: 0.6830 Test: 0.7167\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 072, Loss: 0.5000 Val: 0.6981 Test: 0.7591\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 073, Loss: 0.4700 Val: 0.6848 Test: 0.7588\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 074, Loss: 0.5107 Val: 0.6820 Test: 0.7324\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 075, Loss: 0.5132 Val: 0.6695 Test: 0.6560\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 076, Loss: 0.5224 Val: 0.7764 Test: 0.8603\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 077, Loss: 0.4940 Val: 0.7067 Test: 0.8023\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 078, Loss: 0.5450 Val: 0.6871 Test: 0.8170\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 079, Loss: 0.5744 Val: 0.7332 Test: 0.9623\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 080, Loss: 0.5815 Val: 0.8109 Test: 0.9907\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 081, Loss: 0.5775 Val: 0.7159 Test: 0.8772\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 082, Loss: 0.5641 Val: 0.6734 Test: 0.8255\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 083, Loss: 0.5405 Val: 0.7205 Test: 0.9590\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 084, Loss: 0.5475 Val: 0.7309 Test: 0.8263\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 085, Loss: 0.5460 Val: 0.7149 Test: 0.7375\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 086, Loss: 0.5473 Val: 0.7164 Test: 0.6858\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 087, Loss: 0.5139 Val: 0.7101 Test: 0.7105\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 088, Loss: 0.5176 Val: 0.6981 Test: 0.7662\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 089, Loss: 0.5045 Val: 0.6900 Test: 0.7719\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 090, Loss: 0.5507 Val: 0.6853 Test: 0.8031\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 091, Loss: 0.4756 Val: 0.6788 Test: 0.8065\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 092, Loss: 0.4733 Val: 0.6770 Test: 0.7722\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 093, Loss: 0.5006 Val: 0.6652 Test: 0.7659\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 094, Loss: 0.5249 Val: 0.6710 Test: 0.7453\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 095, Loss: 0.5099 Val: 0.6764 Test: 0.6997\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 096, Loss: 0.4939 Val: 0.6982 Test: 0.6808\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 097, Loss: 0.5100 Val: 0.6798 Test: 0.6981\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 098, Loss: 0.5057 Val: 0.6627 Test: 0.7259\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 099, Loss: 0.4983 Val: 0.6746 Test: 0.7304\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 100, Loss: 0.5055 Val: 0.6688 Test: 0.7123\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 101, Loss: 0.4820 Val: 0.6854 Test: 0.6761\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 102, Loss: 0.4890 Val: 0.6751 Test: 0.6757\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 103, Loss: 0.5025 Val: 0.6809 Test: 0.7090\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 104, Loss: 0.5035 Val: 0.6945 Test: 0.7535\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 105, Loss: 0.4880 Val: 0.6715 Test: 0.7043\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 106, Loss: 0.4702 Val: 0.6599 Test: 0.7143\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 107, Loss: 0.4584 Val: 0.6620 Test: 0.6796\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 108, Loss: 0.5056 Val: 0.6722 Test: 0.7073\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 109, Loss: 0.5014 Val: 0.6817 Test: 0.7029\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 110, Loss: 0.5076 Val: 0.7011 Test: 0.7134\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 111, Loss: 0.5261 Val: 0.6916 Test: 0.7295\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 112, Loss: 0.5386 Val: 0.6802 Test: 0.7547\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 113, Loss: 0.4960 Val: 0.6648 Test: 0.7228\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 114, Loss: 0.5222 Val: 0.6671 Test: 0.7013\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 115, Loss: 0.5182 Val: 0.6547 Test: 0.7215\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 116, Loss: 0.5325 Val: 0.6616 Test: 0.7651\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 117, Loss: 0.5209 Val: 0.6759 Test: 0.7546\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 118, Loss: 0.5546 Val: 0.6623 Test: 0.7147\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 119, Loss: 0.5185 Val: 0.6465 Test: 0.6927\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 120, Loss: 0.4633 Val: 0.6451 Test: 0.6672\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 121, Loss: 0.5270 Val: 0.6576 Test: 0.6759\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 122, Loss: 0.5009 Val: 0.6669 Test: 0.6942\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 123, Loss: 0.4567 Val: 0.6728 Test: 0.6967\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 124, Loss: 0.5031 Val: 0.6984 Test: 0.7036\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 125, Loss: 0.4791 Val: 0.6957 Test: 0.7080\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 126, Loss: 0.4827 Val: 0.6678 Test: 0.6898\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 127, Loss: 0.4646 Val: 0.6720 Test: 0.6851\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 128, Loss: 0.4758 Val: 0.6773 Test: 0.6818\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 129, Loss: 0.4747 Val: 0.6826 Test: 0.6886\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 130, Loss: 0.4695 Val: 0.6824 Test: 0.6875\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 131, Loss: 0.4691 Val: 0.6673 Test: 0.6710\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 132, Loss: 0.5013 Val: 0.7236 Test: 0.6799\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 133, Loss: 0.5085 Val: 0.6999 Test: 0.6716\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 134, Loss: 0.5178 Val: 0.6515 Test: 0.6796\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 135, Loss: 0.4838 Val: 0.6389 Test: 0.6741\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 136, Loss: 0.4711 Val: 0.6429 Test: 0.7069\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 137, Loss: 0.5091 Val: 0.6460 Test: 0.6694\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 138, Loss: 0.5150 Val: 0.6380 Test: 0.7164\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 139, Loss: 0.5020 Val: 0.6928 Test: 0.6782\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 140, Loss: 0.5018 Val: 0.6902 Test: 0.6938\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 141, Loss: 0.5617 Val: 0.6735 Test: 0.7339\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 142, Loss: 0.5714 Val: 0.6929 Test: 0.8185\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 143, Loss: 0.5021 Val: 0.6930 Test: 0.8101\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 144, Loss: 0.5304 Val: 0.6606 Test: 0.7969\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 145, Loss: 0.4869 Val: 0.6517 Test: 0.7868\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 146, Loss: 0.5392 Val: 0.6420 Test: 0.7840\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 147, Loss: 0.4940 Val: 0.6441 Test: 0.7940\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 148, Loss: 0.5052 Val: 0.6322 Test: 0.7614\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 149, Loss: 0.5266 Val: 0.6348 Test: 0.7587\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 150, Loss: 0.4910 Val: 0.6719 Test: 0.7651\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 151, Loss: 0.5169 Val: 0.6719 Test: 0.7787\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 152, Loss: 0.5245 Val: 0.6642 Test: 0.7693\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 153, Loss: 0.5109 Val: 0.6577 Test: 0.7785\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 154, Loss: 0.5103 Val: 0.6647 Test: 0.7707\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 155, Loss: 0.4993 Val: 0.6854 Test: 0.7528\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 156, Loss: 0.5158 Val: 0.7008 Test: 0.7527\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 157, Loss: 0.5446 Val: 0.6740 Test: 0.7758\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 158, Loss: 0.4972 Val: 0.6758 Test: 0.8110\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 159, Loss: 0.5072 Val: 0.6701 Test: 0.7818\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 160, Loss: 0.5440 Val: 0.7639 Test: 0.7880\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 161, Loss: 0.5647 Val: 0.6748 Test: 0.6834\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 162, Loss: 0.5113 Val: 0.6836 Test: 0.6859\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 163, Loss: 0.4927 Val: 0.6748 Test: 0.7139\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 164, Loss: 0.4960 Val: 0.6648 Test: 0.7073\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 165, Loss: 0.4968 Val: 0.6469 Test: 0.7858\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 166, Loss: 0.4647 Val: 0.6405 Test: 0.7865\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 167, Loss: 0.5229 Val: 0.6347 Test: 0.7980\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 168, Loss: 0.5250 Val: 0.6344 Test: 0.7960\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 169, Loss: 0.5323 Val: 0.6183 Test: 0.7540\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 170, Loss: 0.4820 Val: 0.6101 Test: 0.7492\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 171, Loss: 0.5150 Val: 0.6110 Test: 0.7540\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 172, Loss: 0.4311 Val: 0.6222 Test: 0.8112\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 173, Loss: 0.5477 Val: 0.6554 Test: 0.8203\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 174, Loss: 0.5279 Val: 0.6491 Test: 0.7978\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 175, Loss: 0.5143 Val: 0.6559 Test: 0.7817\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 176, Loss: 0.5679 Val: 0.6556 Test: 0.7728\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 177, Loss: 0.5200 Val: 0.6500 Test: 0.7399\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 178, Loss: 0.5176 Val: 0.6456 Test: 0.7577\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 179, Loss: 0.4854 Val: 0.6217 Test: 0.7555\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 180, Loss: 0.4964 Val: 0.6223 Test: 0.7527\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 181, Loss: 0.5070 Val: 0.6256 Test: 0.7294\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 182, Loss: 0.5480 Val: 0.6273 Test: 0.7035\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 183, Loss: 0.5130 Val: 0.6844 Test: 0.7539\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 184, Loss: 0.4779 Val: 0.6880 Test: 0.7267\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 185, Loss: 0.4483 Val: 0.6544 Test: 0.7419\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 186, Loss: 0.4887 Val: 0.6675 Test: 0.7521\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 187, Loss: 0.5072 Val: 0.6515 Test: 0.7601\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 188, Loss: 0.5188 Val: 0.6420 Test: 0.7525\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 189, Loss: 0.5645 Val: 0.6341 Test: 0.7844\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 190, Loss: 0.5290 Val: 0.6528 Test: 0.7316\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 191, Loss: 0.5015 Val: 0.6822 Test: 0.7349\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 192, Loss: 0.4877 Val: 0.6789 Test: 0.7537\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 193, Loss: 0.5504 Val: 0.6716 Test: 0.7652\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 194, Loss: 0.5427 Val: 0.6726 Test: 0.7716\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 195, Loss: 0.4681 Val: 0.6559 Test: 0.7641\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 196, Loss: 0.4752 Val: 0.6599 Test: 0.7630\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 197, Loss: 0.5015 Val: 0.6463 Test: 0.7689\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 198, Loss: 0.4709 Val: 0.6361 Test: 0.7920\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "6\n",
      "Epoch: 199, Loss: 0.5188 Val: 0.6265 Test: 0.7818\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn.models import AttentiveFP\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_gz)\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn.models import AttentiveFP\n",
    "\n",
    "from model import GNN,GNN_graphpred\n",
    "from dataset import LSSInhibitor,GenAtomFeatures,GenAttentiveFeatures\n",
    "from loss import ada_batch_all_triplet_loss\n",
    "\n",
    "device = 'cuda:6'\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "lr = 0.0001\n",
    "decay = 1e-3\n",
    "num_layer = 5\n",
    "emb_dim = 300\n",
    "dropout_ratio = 0\n",
    "JK = 'last'\n",
    "dataset = 'EAAT3'\n",
    "output_model_file = ''\n",
    "gnn_type = 'gin'\n",
    "seed = 0\n",
    "num_workers = 8\n",
    "mode = 'ada_batch_all_triplet_loss'   #ada_batch_all_triplet_loss,ada_batch_hard_triplet_loss,triplet_loss\n",
    "feature_type = 'custom'  #random,onehot,custom,pseudo\n",
    "graph_pooling = 'set2set2' #mean,last,sum,set2set,atention\n",
    "\n",
    "\n",
    "def train():\n",
    "    total_loss = total_examples = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        '''\n",
    "        data.x = data.x.to(torch.float32)\n",
    "        data.edge_index=data.edge_index.to(torch.long)\n",
    "        data.edge_attr=data.edge_attr.to(torch.float32)\n",
    "        data.batch=data.batch.to(torch.long)\n",
    "        '''\n",
    "        #out = model(float(data.x), data.edge_index.to(torch.long), data.edge_attr.to(torch.float32), data.batch.to(torch.long))\n",
    "        emb,pre = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "\n",
    "        #loss = F.mse_loss(out, data.y)\n",
    "        loss = ada_batch_all_triplet_loss(embeddings=emb, labels=data.y, prediction=pre, device=device, minv=minv, maxv=maxv, weight=0.5, cliff=2,squared=False)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "    return sqrt(total_loss / total_examples)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    mse = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        emb,pre = model(data.x.to(torch.float32), data.edge_index, data.edge_attr, data.batch)\n",
    "        pre = pre*(maxv-minv)+minv\n",
    "        mse.append(F.mse_loss(pre, data.y, reduction='none').cpu())\n",
    "        #print('mse:',mse)\n",
    "    return float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "\n",
    "\n",
    "for dataset_name in LSSInhibitor.names.keys():\n",
    "    \n",
    "    print(dataset_name + \"\\n\")\n",
    "    \n",
    "    path = './data'\n",
    "    \n",
    "    # use the attentiveFP node and edge features during the mol-2-graph transoformation\n",
    "    dataset = LSSInhibitor(path, name=dataset_name, pre_transform=GenAtomFeatures('custom')).shuffle()\n",
    "    #dataset = LSSInhibitor(path, name=dataset_name, pre_transform=GenAttentiveFeatures()).shuffle()\n",
    "    #dataset = MoleculeNet(path, name='FreeSolv', pre_transform=GenFeatures()).shuffle()\n",
    "    print(dataset.data.x.shape)\n",
    "    print(dataset.__dict__)\n",
    "    \n",
    "    minv = 1e12\n",
    "    maxv = -1e12\n",
    "    for i in dataset:\n",
    "        if i.y<minv:\n",
    "            minv = i.y.item()\n",
    "        if i.y>maxv:\n",
    "            maxv = i.y.item()\n",
    "    print('minv:',minv) \n",
    "    print('maxv:',maxv)\n",
    "    \n",
    "    #batch_size = 8\n",
    "    \n",
    "    # train, valid, test splitting\n",
    "    N = len(dataset) // 5\n",
    "    val_dataset = dataset[:N]\n",
    "    test_dataset = dataset[N:2 * N]\n",
    "    train_dataset = dataset[2 * N:]\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = GNN_graphpred(num_layer, emb_dim, num_tasks = 1, JK = JK, drop_ratio =dropout_ratio,feature_type = feature_type,graph_pooling = graph_pooling, gnn_type = gnn_type).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
    "                                 weight_decay=decay)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_rmse = train()\n",
    "        val_rmse = test(val_loader)\n",
    "        test_rmse = test(test_loader)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_rmse:.4f} Val: {val_rmse:.4f} '\n",
    "              f'Test: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa786c5-1843-4966-a6df-27a18de6790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mglur2\n",
      "\n",
      "Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F')\n",
      "mGluR2(4)\n",
      "dict {0: {'train': [Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(C(C)C)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(C)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCOCC3)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1nnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)n1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1')], 'test': [Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=c1[nH]nc2nc(-c3ccc(F)cc3)c3ccccc3n12'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C#N)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=C1NCc2c1cc(-c1ccc(F)cc1)c1ccccc21'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='O=c1[nH]nc2ccccccc(-c3ccc(F)cc3)nn12'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccccc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4cccc(F)c4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCC3=O)cc2n1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCC(F)(F)C3)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cn4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCCC3=O)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)cn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)c1)C(F)(F)F')]}, 1: {'train': [Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=c1[nH]nc2nc(-c3ccc(F)cc3)c3ccccc3n12'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccccc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCC(F)(F)C3)cc2n1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)cn1)C(F)(F)F')], 'test': [Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(C(C)C)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C#N)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=C1NCc2c1cc(-c1ccc(F)cc1)c1ccccc21'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='O=c1[nH]nc2ccccccc(-c3ccc(F)cc3)nn12'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(C)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4cccc(F)c4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCC3=O)cc2n1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCOCC3)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cn4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1nnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)n1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)c1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1')]}, 2: {'train': [Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C#N)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4cccc(F)c4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCCC3=O)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F')], 'test': [Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(C(C)C)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=c1[nH]nc2nc(-c3ccc(F)cc3)c3ccccc3n12'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=C1NCc2c1cc(-c1ccc(F)cc1)c1ccccc21'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='O=c1[nH]nc2ccccccc(-c3ccc(F)cc3)nn12'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(C)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccccc2n1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCC3=O)cc2n1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCOCC3)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCC(F)(F)C3)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cn4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCCC3=O)cc2n1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1nnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)n1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)cn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)c1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1')]}, 3: {'train': [Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=C1NCc2c1cc(-c1ccc(F)cc1)c1ccccc21'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cn4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F')], 'test': [Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(C(C)C)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=c1[nH]nc2nc(-c3ccc(F)cc3)c3ccccc3n12'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C#N)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='O=c1[nH]nc2ccccccc(-c3ccc(F)cc3)nn12'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(C)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccccc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4cccc(F)c4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCOCC3)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCC(F)(F)C3)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCCC3=O)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1nnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)n1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)cn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)c1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1')]}, 4: {'train': [Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='O=c1[nH]nc2ccccccc(-c3ccc(F)cc3)nn12'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)c1)C(F)(F)F')], 'test': [Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(C(C)C)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=c1[nH]nc2nc(-c3ccc(F)cc3)c3ccccc3n12'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C#N)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=C1NCc2c1cc(-c1ccc(F)cc1)c1ccccc21'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(C)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccccc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4cccc(F)c4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCC3=O)cc2n1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCOCC3)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCC(F)(F)C3)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cn4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCCC3=O)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1nnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)n1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)cn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1')]}}\n",
      "6\n",
      "20\n",
      "1\n",
      "2\n",
      "torch.Size([791, 115])\n",
      "{'name': 'mglur2', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fc061552430>, 'pre_filter': None, '_indices': [16, 14, 15, 0, 1, 19, 23, 13, 8, 2, 5, 6, 24, 10, 20, 17, 4, 3, 9, 21, 11, 22, 7, 25, 12, 18], 'data': Data(x=[791, 115], edge_index=[2, 1734], edge_attr=[1734, 7], y=[26, 1], smiles=[26]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([  0,  33,  54,  74, 102, 135, 169, 203, 230, 251, 285, 320, 348, 376,\n",
      "        410, 444, 472, 506, 540, 576, 611, 632, 661, 695, 730, 764, 791]), 'edge_index': tensor([   0,   72,  118,  162,  224,  296,  370,  444,  504,  552,  626,  702,\n",
      "         764,  826,  900,  974, 1036, 1110, 1184, 1262, 1338, 1386, 1450, 1524,\n",
      "        1600, 1674, 1734]), 'edge_attr': tensor([   0,   72,  118,  162,  224,  296,  370,  444,  504,  552,  626,  702,\n",
      "         764,  826,  900,  974, 1036, 1110, 1184, 1262, 1338, 1386, 1450, 1524,\n",
      "        1600, 1674, 1734]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])}), '_data_list': [Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C#N)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='O=c1[nH]nc2ccccccc(-c3ccc(F)cc3)nn12'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccccc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCCC3=O)cc2n1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cn4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4cccc(F)c4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCOCC3)cc2n1'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=C1NCc2c1cc(-c1ccc(F)cc1)c1ccccc21'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccccc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1nnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)n1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cnn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)c1)C(F)(F)F'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCC(F)(F)C3)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(C(C)C)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(C(C)c2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='O=c1[nH]nc2nc(-c3ccc(F)cc3)c3ccccc3n12'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3C(=O)CCCC3=O)cc2n1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(C)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(Cl)cc4F)cc(C(N)=O)nc3c2)nn1)C(F)(F)F'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CC[C@@](O)(c1cn(Cc2ccc3c(-c4ccc(F)cc4)cc(C(N)=O)nc3c2)cn1)C(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='NC(=O)c1cc(-c2ccc(F)cc2)c2ccc(CN3CCCC3=O)cc2n1')]}\n",
      "minv: 5.570000171661377\n",
      "maxv: 8.050000190734863\n",
      "emb_dim: 300\n",
      "Epoch: 000, Loss: 1.0074 Val: 1.9057 Test: 1.9749\n",
      "Epoch: 001, Loss: 0.9774 Val: 1.8847 Test: 1.9498\n",
      "Epoch: 002, Loss: 0.8597 Val: 1.8643 Test: 1.9247\n",
      "Epoch: 003, Loss: 0.7918 Val: 1.8460 Test: 1.9075\n",
      "Epoch: 004, Loss: 0.7531 Val: 1.8349 Test: 1.8859\n",
      "Epoch: 005, Loss: 0.7090 Val: 1.8317 Test: 1.8684\n",
      "Epoch: 006, Loss: 0.7120 Val: 1.8242 Test: 1.8482\n",
      "Epoch: 007, Loss: 0.6776 Val: 1.8133 Test: 1.8419\n",
      "Epoch: 008, Loss: 0.6803 Val: 1.8049 Test: 1.8242\n",
      "Epoch: 009, Loss: 0.6835 Val: 1.7943 Test: 1.8155\n",
      "Epoch: 010, Loss: 0.6976 Val: 1.7742 Test: 1.8114\n",
      "Epoch: 011, Loss: 0.6905 Val: 1.7606 Test: 1.8031\n",
      "Epoch: 012, Loss: 0.6757 Val: 1.7535 Test: 1.7967\n",
      "Epoch: 013, Loss: 0.6693 Val: 1.7472 Test: 1.7975\n",
      "Epoch: 014, Loss: 0.6349 Val: 1.7397 Test: 1.7855\n",
      "Epoch: 015, Loss: 0.6468 Val: 1.7314 Test: 1.7801\n",
      "Epoch: 016, Loss: 0.6411 Val: 1.7219 Test: 1.7907\n",
      "Epoch: 017, Loss: 0.6117 Val: 1.7121 Test: 1.7771\n",
      "Epoch: 018, Loss: 0.6201 Val: 1.7053 Test: 1.7620\n",
      "Epoch: 019, Loss: 0.7066 Val: 1.6991 Test: 1.7173\n",
      "Epoch: 020, Loss: 0.6321 Val: 1.6873 Test: 1.7126\n",
      "Epoch: 021, Loss: 0.6036 Val: 1.6757 Test: 1.7230\n",
      "Epoch: 022, Loss: 0.6055 Val: 1.6714 Test: 1.7205\n",
      "Epoch: 023, Loss: 0.6256 Val: 1.6670 Test: 1.7100\n",
      "Epoch: 024, Loss: 0.6175 Val: 1.6622 Test: 1.6974\n",
      "Epoch: 025, Loss: 0.6084 Val: 1.6563 Test: 1.6859\n",
      "Epoch: 026, Loss: 0.5920 Val: 1.6491 Test: 1.6755\n",
      "Epoch: 027, Loss: 0.5993 Val: 1.6404 Test: 1.6638\n",
      "Epoch: 028, Loss: 0.6105 Val: 1.6335 Test: 1.6631\n",
      "Epoch: 029, Loss: 0.5799 Val: 1.6274 Test: 1.6691\n",
      "Epoch: 030, Loss: 0.5867 Val: 1.6205 Test: 1.6706\n",
      "Epoch: 031, Loss: 0.5840 Val: 1.6134 Test: 1.6578\n",
      "Epoch: 032, Loss: 0.6003 Val: 1.6021 Test: 1.6393\n",
      "Epoch: 033, Loss: 0.5696 Val: 1.5909 Test: 1.6243\n",
      "Epoch: 034, Loss: 0.5684 Val: 1.5785 Test: 1.6166\n",
      "Epoch: 035, Loss: 0.5964 Val: 1.5773 Test: 1.6284\n",
      "Epoch: 036, Loss: 0.5797 Val: 1.5708 Test: 1.6318\n",
      "Epoch: 037, Loss: 0.5718 Val: 1.5634 Test: 1.6264\n",
      "Epoch: 038, Loss: 0.6080 Val: 1.5549 Test: 1.6195\n",
      "Epoch: 039, Loss: 0.5735 Val: 1.5431 Test: 1.5987\n",
      "Epoch: 040, Loss: 0.5857 Val: 1.5316 Test: 1.5678\n",
      "Epoch: 041, Loss: 0.5834 Val: 1.5183 Test: 1.5346\n",
      "Epoch: 042, Loss: 0.5761 Val: 1.5034 Test: 1.5119\n",
      "Epoch: 043, Loss: 0.5726 Val: 1.4886 Test: 1.4983\n",
      "Epoch: 044, Loss: 0.5704 Val: 1.4785 Test: 1.4892\n",
      "Epoch: 045, Loss: 0.5596 Val: 1.4696 Test: 1.4814\n",
      "Epoch: 046, Loss: 0.5783 Val: 1.4619 Test: 1.4738\n",
      "Epoch: 047, Loss: 0.5790 Val: 1.4603 Test: 1.4677\n",
      "Epoch: 048, Loss: 0.5432 Val: 1.4647 Test: 1.4609\n",
      "Epoch: 049, Loss: 0.5676 Val: 1.4613 Test: 1.4500\n",
      "Epoch: 050, Loss: 0.5740 Val: 1.4535 Test: 1.4422\n",
      "Epoch: 051, Loss: 0.5650 Val: 1.4427 Test: 1.4386\n",
      "Epoch: 052, Loss: 0.5800 Val: 1.4299 Test: 1.4326\n",
      "Epoch: 053, Loss: 0.5541 Val: 1.4146 Test: 1.4217\n",
      "Epoch: 054, Loss: 0.5649 Val: 1.3975 Test: 1.4119\n",
      "Epoch: 055, Loss: 0.5487 Val: 1.3965 Test: 1.4013\n",
      "Epoch: 056, Loss: 0.5478 Val: 1.3855 Test: 1.3856\n",
      "Epoch: 057, Loss: 0.6017 Val: 1.3725 Test: 1.3692\n",
      "Epoch: 058, Loss: 0.5616 Val: 1.3596 Test: 1.3535\n",
      "Epoch: 059, Loss: 0.5413 Val: 1.3454 Test: 1.3403\n",
      "Epoch: 060, Loss: 0.5336 Val: 1.3293 Test: 1.3281\n",
      "Epoch: 061, Loss: 0.5325 Val: 1.3113 Test: 1.3184\n",
      "Epoch: 062, Loss: 0.5579 Val: 1.2943 Test: 1.3157\n",
      "Epoch: 063, Loss: 0.5084 Val: 1.2822 Test: 1.3548\n",
      "Epoch: 064, Loss: 0.5127 Val: 1.2755 Test: 1.3693\n",
      "Epoch: 065, Loss: 0.5183 Val: 1.2669 Test: 1.2887\n",
      "Epoch: 066, Loss: 0.5965 Val: 1.2579 Test: 1.2515\n",
      "Epoch: 067, Loss: 0.5260 Val: 1.2494 Test: 1.2399\n",
      "Epoch: 068, Loss: 0.5045 Val: 1.2407 Test: 1.2462\n",
      "Epoch: 069, Loss: 0.5300 Val: 1.2307 Test: 1.2596\n",
      "Epoch: 070, Loss: 0.5257 Val: 1.2189 Test: 1.2725\n",
      "Epoch: 071, Loss: 0.5412 Val: 1.2063 Test: 1.2826\n",
      "Epoch: 072, Loss: 0.5059 Val: 1.1957 Test: 1.2026\n",
      "Epoch: 073, Loss: 0.5268 Val: 1.1791 Test: 1.1733\n",
      "Epoch: 074, Loss: 0.4972 Val: 1.1639 Test: 1.1590\n",
      "Epoch: 075, Loss: 0.4883 Val: 1.1523 Test: 1.1491\n",
      "Epoch: 076, Loss: 0.4936 Val: 1.1501 Test: 1.1423\n",
      "Epoch: 077, Loss: 0.5764 Val: 1.1473 Test: 1.1348\n",
      "Epoch: 078, Loss: 0.5749 Val: 1.1436 Test: 1.1264\n",
      "Epoch: 079, Loss: 0.5735 Val: 1.1388 Test: 1.1172\n",
      "Epoch: 080, Loss: 0.5218 Val: 1.1273 Test: 1.1074\n",
      "Epoch: 081, Loss: 0.4641 Val: 1.1132 Test: 1.0929\n",
      "Epoch: 082, Loss: 0.5069 Val: 1.0977 Test: 1.0789\n",
      "Epoch: 083, Loss: 0.5646 Val: 1.0827 Test: 1.0648\n",
      "Epoch: 084, Loss: 0.5617 Val: 1.0676 Test: 1.0505\n",
      "Epoch: 085, Loss: 0.5589 Val: 1.0530 Test: 1.0362\n",
      "Epoch: 086, Loss: 0.4914 Val: 1.0369 Test: 1.0263\n",
      "Epoch: 087, Loss: 0.4734 Val: 1.0383 Test: 1.0167\n",
      "Epoch: 088, Loss: 0.5525 Val: 1.0383 Test: 1.0062\n",
      "Epoch: 089, Loss: 0.5506 Val: 1.0366 Test: 0.9949\n",
      "Epoch: 090, Loss: 0.4647 Val: 1.0292 Test: 0.9842\n",
      "Epoch: 091, Loss: 0.4854 Val: 1.0201 Test: 0.9739\n",
      "Epoch: 092, Loss: 0.5447 Val: 1.0101 Test: 0.9629\n",
      "Epoch: 093, Loss: 0.5425 Val: 0.9996 Test: 0.9514\n",
      "Epoch: 094, Loss: 0.5401 Val: 0.9882 Test: 0.9393\n",
      "Epoch: 095, Loss: 0.5376 Val: 0.9762 Test: 0.9266\n",
      "Epoch: 096, Loss: 0.5349 Val: 0.9636 Test: 0.9135\n",
      "Epoch: 097, Loss: 0.4504 Val: 0.9487 Test: 0.8999\n",
      "Epoch: 098, Loss: 0.4703 Val: 0.9319 Test: 0.8878\n",
      "Epoch: 099, Loss: 0.4433 Val: 0.9137 Test: 0.8771\n",
      "Epoch: 100, Loss: 0.4314 Val: 0.8989 Test: 0.8686\n",
      "Epoch: 101, Loss: 0.4187 Val: 0.8889 Test: 0.8618\n",
      "Epoch: 102, Loss: 0.4503 Val: 0.8744 Test: 0.8544\n",
      "Epoch: 103, Loss: 0.5141 Val: 0.8598 Test: 0.8458\n",
      "Epoch: 104, Loss: 0.5124 Val: 0.8451 Test: 0.8362\n",
      "Epoch: 105, Loss: 0.4152 Val: 0.8507 Test: 0.8330\n",
      "Epoch: 106, Loss: 0.4469 Val: 0.8531 Test: 0.8283\n",
      "Epoch: 107, Loss: 0.4348 Val: 0.8514 Test: 0.8218\n",
      "Epoch: 108, Loss: 0.4356 Val: 0.8460 Test: 0.8144\n",
      "Epoch: 109, Loss: 0.4566 Val: 0.8366 Test: 0.8063\n",
      "Epoch: 110, Loss: 0.4384 Val: 0.8247 Test: 0.7985\n",
      "Epoch: 111, Loss: 0.4996 Val: 0.8134 Test: 0.7898\n",
      "Epoch: 112, Loss: 0.4283 Val: 0.8066 Test: 0.7846\n",
      "Epoch: 113, Loss: 0.4233 Val: 0.8045 Test: 0.7726\n",
      "Epoch: 114, Loss: 0.4920 Val: 0.8005 Test: 0.7600\n",
      "Epoch: 115, Loss: 0.4897 Val: 0.7952 Test: 0.7473\n",
      "Epoch: 116, Loss: 0.3931 Val: 0.7876 Test: 0.7364\n",
      "Epoch: 117, Loss: 0.3983 Val: 0.7781 Test: 0.7275\n",
      "Epoch: 118, Loss: 0.4034 Val: 0.7769 Test: 0.7171\n",
      "Epoch: 119, Loss: 0.4264 Val: 0.7733 Test: 0.7084\n",
      "Epoch: 120, Loss: 0.4136 Val: 0.7683 Test: 0.7018\n",
      "Epoch: 121, Loss: 0.3674 Val: 0.7503 Test: 0.7240\n",
      "Epoch: 122, Loss: 0.4724 Val: 0.7309 Test: 0.7445\n",
      "Epoch: 123, Loss: 0.4696 Val: 0.7112 Test: 0.7601\n",
      "Epoch: 124, Loss: 0.4692 Val: 0.6935 Test: 0.7682\n",
      "Epoch: 125, Loss: 0.3593 Val: 0.7025 Test: 0.7572\n",
      "Epoch: 126, Loss: 0.4633 Val: 0.7107 Test: 0.7424\n",
      "Epoch: 127, Loss: 0.3851 Val: 0.7068 Test: 0.7315\n",
      "Epoch: 128, Loss: 0.3846 Val: 0.6980 Test: 0.7264\n",
      "Epoch: 129, Loss: 0.3500 Val: 0.6836 Test: 0.7207\n",
      "Epoch: 130, Loss: 0.3474 Val: 0.6648 Test: 0.7144\n",
      "Epoch: 131, Loss: 0.3694 Val: 0.6452 Test: 0.7077\n",
      "Epoch: 132, Loss: 0.4505 Val: 0.6265 Test: 0.7007\n",
      "Epoch: 133, Loss: 0.3653 Val: 0.6235 Test: 0.6941\n",
      "Epoch: 134, Loss: 0.3299 Val: 0.6250 Test: 0.6938\n",
      "Epoch: 135, Loss: 0.3608 Val: 0.6183 Test: 0.6972\n",
      "Epoch: 136, Loss: 0.4450 Val: 0.6114 Test: 0.6993\n",
      "Epoch: 137, Loss: 0.4435 Val: 0.6048 Test: 0.7001\n",
      "Epoch: 138, Loss: 0.4419 Val: 0.5988 Test: 0.7005\n",
      "Epoch: 139, Loss: 0.4402 Val: 0.5920 Test: 0.7006\n",
      "Epoch: 140, Loss: 0.3370 Val: 0.5997 Test: 0.7016\n",
      "Epoch: 141, Loss: 0.3550 Val: 0.6046 Test: 0.7014\n",
      "Epoch: 142, Loss: 0.3533 Val: 0.6063 Test: 0.6987\n",
      "Epoch: 143, Loss: 0.4358 Val: 0.6051 Test: 0.6956\n",
      "Epoch: 144, Loss: 0.3630 Val: 0.5974 Test: 0.6972\n",
      "Epoch: 145, Loss: 0.3605 Val: 0.5833 Test: 0.7040\n",
      "Epoch: 146, Loss: 0.4312 Val: 0.5681 Test: 0.7116\n",
      "Epoch: 147, Loss: 0.3400 Val: 0.5500 Test: 0.7210\n",
      "Epoch: 148, Loss: 0.4275 Val: 0.5334 Test: 0.7294\n",
      "Epoch: 149, Loss: 0.2797 Val: 0.5637 Test: 0.7120\n",
      "Epoch: 150, Loss: 0.4268 Val: 0.5895 Test: 0.7010\n",
      "Epoch: 151, Loss: 0.4285 Val: 0.6065 Test: 0.6949\n",
      "Epoch: 152, Loss: 0.4290 Val: 0.6162 Test: 0.6916\n",
      "Epoch: 153, Loss: 0.4286 Val: 0.6198 Test: 0.6905\n",
      "Epoch: 154, Loss: 0.3372 Val: 0.5998 Test: 0.7058\n",
      "Epoch: 155, Loss: 0.4231 Val: 0.5778 Test: 0.7172\n",
      "Epoch: 156, Loss: 0.4236 Val: 0.5594 Test: 0.7240\n",
      "Epoch: 157, Loss: 0.2918 Val: 0.5755 Test: 0.7125\n",
      "Epoch: 158, Loss: 0.3284 Val: 0.5886 Test: 0.7070\n",
      "Epoch: 159, Loss: 0.4172 Val: 0.6004 Test: 0.7021\n",
      "Epoch: 160, Loss: 0.4162 Val: 0.6077 Test: 0.6990\n",
      "Epoch: 161, Loss: 0.2898 Val: 0.6096 Test: 0.6976\n",
      "Epoch: 162, Loss: 0.2920 Val: 0.6011 Test: 0.7035\n",
      "Epoch: 163, Loss: 0.3281 Val: 0.5687 Test: 0.7175\n",
      "Epoch: 164, Loss: 0.4118 Val: 0.5380 Test: 0.7281\n",
      "Epoch: 165, Loss: 0.4120 Val: 0.5146 Test: 0.7367\n",
      "Epoch: 166, Loss: 0.3175 Val: 0.5169 Test: 0.7360\n",
      "Epoch: 167, Loss: 0.4115 Val: 0.5208 Test: 0.7361\n",
      "Epoch: 168, Loss: 0.3216 Val: 0.5229 Test: 0.7361\n",
      "Epoch: 169, Loss: 0.4090 Val: 0.5231 Test: 0.7374\n",
      "Epoch: 170, Loss: 0.4075 Val: 0.5217 Test: 0.7400\n",
      "Epoch: 171, Loss: 0.4056 Val: 0.5187 Test: 0.7433\n",
      "Epoch: 172, Loss: 0.4035 Val: 0.5137 Test: 0.7471\n",
      "Epoch: 173, Loss: 0.4019 Val: 0.5075 Test: 0.7507\n",
      "Epoch: 174, Loss: 0.4018 Val: 0.5003 Test: 0.7543\n",
      "Epoch: 175, Loss: 0.3001 Val: 0.4909 Test: 0.7567\n",
      "Epoch: 176, Loss: 0.3990 Val: 0.4819 Test: 0.7588\n",
      "Epoch: 177, Loss: 0.3979 Val: 0.4734 Test: 0.7620\n",
      "Epoch: 178, Loss: 0.3973 Val: 0.4653 Test: 0.7665\n",
      "Epoch: 179, Loss: 0.3962 Val: 0.4557 Test: 0.7718\n",
      "Epoch: 180, Loss: 0.3961 Val: 0.4484 Test: 0.7756\n",
      "Epoch: 181, Loss: 0.2978 Val: 0.4400 Test: 0.7808\n",
      "Epoch: 182, Loss: 0.3958 Val: 0.4338 Test: 0.7855\n",
      "Epoch: 183, Loss: 0.3948 Val: 0.4296 Test: 0.7897\n",
      "Epoch: 184, Loss: 0.3933 Val: 0.4298 Test: 0.7913\n",
      "Epoch: 185, Loss: 0.3927 Val: 0.4341 Test: 0.7902\n",
      "Epoch: 186, Loss: 0.3919 Val: 0.4380 Test: 0.7888\n",
      "Epoch: 187, Loss: 0.3926 Val: 0.4377 Test: 0.7884\n",
      "Epoch: 188, Loss: 0.3927 Val: 0.4335 Test: 0.7893\n",
      "Epoch: 189, Loss: 0.3922 Val: 0.4283 Test: 0.7897\n",
      "Epoch: 190, Loss: 0.3915 Val: 0.4255 Test: 0.7876\n",
      "Epoch: 191, Loss: 0.3912 Val: 0.4203 Test: 0.7846\n",
      "Epoch: 192, Loss: 0.3911 Val: 0.4168 Test: 0.7808\n",
      "Epoch: 193, Loss: 0.3904 Val: 0.4150 Test: 0.7761\n",
      "Epoch: 194, Loss: 0.3898 Val: 0.4176 Test: 0.7703\n",
      "Epoch: 195, Loss: 0.3891 Val: 0.4219 Test: 0.7662\n",
      "Epoch: 196, Loss: 0.3886 Val: 0.4278 Test: 0.7635\n",
      "Epoch: 197, Loss: 0.3892 Val: 0.4310 Test: 0.7633\n",
      "Epoch: 198, Loss: 0.3892 Val: 0.4292 Test: 0.7651\n",
      "Epoch: 199, Loss: 0.3889 Val: 0.4248 Test: 0.7682\n",
      "usp7\n",
      "\n",
      "Data(x=[31, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(C4CC4)csc3c2=O)CC1')\n",
      "USP7(4)\n",
      "dict {0: {'train': [Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1cc2ncn(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)c(=O)c2n1'), Data(x=[31, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(C4CC4)csc3c2=O)CC1'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(OCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4N)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C=C(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[32, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C#Cc1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[40, 115], edge_index=[2, 88], edge_attr=[88, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN(C)C)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 80], edge_attr=[80, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4)n(C)nc3c2=O)CC1)c1ccccc1')], 'test': [Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3occc3c2=O)CC1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3ccsc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3cc(Br)sc3c2=O)CC1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3scc(Br)c3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1ncc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc21'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnccc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3sccc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='COCCNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[34, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(-c4ccccc4)csc3c2=O)CC1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C#Cc1csc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc12'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(C#Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Nc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCOCC3)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(N(C)CCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[31, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(C#CC(C)(C)O)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[43, 115], edge_index=[2, 96], edge_attr=[96, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN5CCOCC5)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C#N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4F)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCCC3)cc2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(C(N)=O)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CO)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccn[nH]4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C(N)=O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[41, 115], edge_index=[2, 90], edge_attr=[90, 7], y=[1, 1], smiles='Cn1nc2c(=O)n(CC3(O)CCN(C(=O)C[C@H](c4ccccc4)C(F)(F)F)CC3)cnc2c1-c1ccc(CN)cc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1')]}, 1: {'train': [Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3occc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3scc(Br)c3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCOCC3)cc2=O)CC1)c1ccccc1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C#N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(C(N)=O)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C(N)=O)c4)n(C)nc3c2=O)CC1)c1ccccc1')], 'test': [Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3ccsc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3cc(Br)sc3c2=O)CC1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1cc2ncn(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)c(=O)c2n1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1ncc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc21'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnccc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3sccc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(C4CC4)csc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='COCCNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[34, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(-c4ccccc4)csc3c2=O)CC1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C#Cc1csc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc12'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(OCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(C#Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Nc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4N)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(N(C)CCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C=C(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[31, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(C#CC(C)(C)O)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[43, 115], edge_index=[2, 96], edge_attr=[96, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN5CCOCC5)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C#Cc1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4F)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCCC3)cc2=O)CC1)c1ccccc1'), Data(x=[40, 115], edge_index=[2, 88], edge_attr=[88, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN(C)C)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CO)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccn[nH]4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 80], edge_attr=[80, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[41, 115], edge_index=[2, 90], edge_attr=[90, 7], y=[1, 1], smiles='Cn1nc2c(=O)n(CC3(O)CCN(C(=O)C[C@H](c4ccccc4)C(F)(F)F)CC3)cnc2c1-c1ccc(CN)cc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1')]}, 2: {'train': [Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3ccsc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1ncc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc21'), Data(x=[31, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='COCCNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(C#Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[31, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CO)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(N)c4)n(C)nc3c2=O)CC1)c1ccccc1')], 'test': [Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3occc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3cc(Br)sc3c2=O)CC1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1cc2ncn(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)c(=O)c2n1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3scc(Br)c3c2=O)CC1'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnccc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3sccc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(C4CC4)csc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1'), Data(x=[34, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(-c4ccccc4)csc3c2=O)CC1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C#Cc1csc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc12'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(OCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Nc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4N)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCOCC3)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(N(C)CCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C=C(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(C#CC(C)(C)O)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[43, 115], edge_index=[2, 96], edge_attr=[96, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN5CCOCC5)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C#Cc1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C#N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4F)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCCC3)cc2=O)CC1)c1ccccc1'), Data(x=[40, 115], edge_index=[2, 88], edge_attr=[88, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN(C)C)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(C(N)=O)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccn[nH]4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 80], edge_attr=[80, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C(N)=O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[41, 115], edge_index=[2, 90], edge_attr=[90, 7], y=[1, 1], smiles='Cn1nc2c(=O)n(CC3(O)CCN(C(=O)C[C@H](c4ccccc4)C(F)(F)F)CC3)cnc2c1-c1ccc(CN)cc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1')]}, 3: {'train': [Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3cc(Br)sc3c2=O)CC1'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnccc2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(-c4ccccc4)csc3c2=O)CC1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(C#CC(C)(C)O)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4F)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[41, 115], edge_index=[2, 90], edge_attr=[90, 7], y=[1, 1], smiles='Cn1nc2c(=O)n(CC3(O)CCN(C(=O)C[C@H](c4ccccc4)C(F)(F)F)CC3)cnc2c1-c1ccc(CN)cc1')], 'test': [Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3occc3c2=O)CC1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3ccsc3c2=O)CC1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1cc2ncn(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)c(=O)c2n1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3scc(Br)c3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1ncc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc21'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3sccc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(C4CC4)csc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='COCCNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C#Cc1csc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc12'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(OCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(C#Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Nc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4N)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCOCC3)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(N(C)CCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C=C(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[31, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[43, 115], edge_index=[2, 96], edge_attr=[96, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN5CCOCC5)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C#Cc1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C#N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCCC3)cc2=O)CC1)c1ccccc1'), Data(x=[40, 115], edge_index=[2, 88], edge_attr=[88, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN(C)C)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(C(N)=O)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CO)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccn[nH]4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 80], edge_attr=[80, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C(N)=O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1')]}, 4: {'train': [Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3sccc3c2=O)CC1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C#Cc1csc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc12'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Nc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(N(C)CCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[43, 115], edge_index=[2, 96], edge_attr=[96, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN5CCOCC5)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCCC3)cc2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccn[nH]4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1')], 'test': [Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3occc3c2=O)CC1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3ccsc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3cc(Br)sc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1cc2ncn(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)c(=O)c2n1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3scc(Br)c3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1ncc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc21'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnccc2=O)CC1)c1ccccc1'), Data(x=[31, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(C4CC4)csc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='COCCNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[34, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(-c4ccccc4)csc3c2=O)CC1'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(OCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(C#Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4N)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCOCC3)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C=C(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[31, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(C#CC(C)(C)O)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C#Cc1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C#N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4F)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[40, 115], edge_index=[2, 88], edge_attr=[88, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN(C)C)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(C(N)=O)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CO)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 80], edge_attr=[80, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C(N)=O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[41, 115], edge_index=[2, 90], edge_attr=[90, 7], y=[1, 1], smiles='Cn1nc2c(=O)n(CC3(O)CCN(C(=O)C[C@H](c4ccccc4)C(F)(F)F)CC3)cnc2c1-c1ccc(CN)cc1')]}}\n",
      "9\n",
      "36\n",
      "1\n",
      "3\n",
      "torch.Size([1506, 115])\n",
      "{'name': 'usp7', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fc06152afa0>, 'pre_filter': None, '_indices': [9, 33, 13, 26, 43, 16, 4, 23, 15, 32, 19, 39, 12, 38, 11, 10, 20, 18, 1, 6, 8, 37, 14, 7, 36, 41, 0, 25, 35, 28, 31, 40, 24, 42, 29, 30, 3, 21, 44, 5, 34, 17, 22, 27, 2], 'data': Data(x=[1506, 115], edge_index=[2, 3304], edge_attr=[3304, 7], y=[45, 1], smiles=[45]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   37,   70,  103,  132,  162,  193,  230,  262,  291,  322,  361,\n",
      "         394,  426,  456,  485,  516,  550,  585,  621,  661,  697,  735,  768,\n",
      "         806,  849,  887,  916,  951,  990, 1027, 1060, 1094, 1122, 1151, 1181,\n",
      "        1215, 1247, 1280, 1308, 1345, 1373, 1399, 1427, 1468, 1506]), 'edge_index': tensor([   0,   82,  154,  224,  288,  354,  420,  502,  570,  634,  704,  790,\n",
      "         862,  930,  996, 1060, 1128, 1202, 1278, 1356, 1444, 1524, 1608, 1680,\n",
      "        1764, 1860, 1944, 2008, 2086, 2172, 2254, 2324, 2398, 2460, 2524, 2590,\n",
      "        2666, 2736, 2808, 2870, 2952, 3014, 3070, 3130, 3220, 3304]), 'edge_attr': tensor([   0,   82,  154,  224,  288,  354,  420,  502,  570,  634,  704,  790,\n",
      "         862,  930,  996, 1060, 1128, 1202, 1278, 1356, 1444, 1524, 1608, 1680,\n",
      "        1764, 1860, 1944, 2008, 2086, 2172, 2254, 2324, 2398, 2460, 2524, 2590,\n",
      "        2666, 2736, 2808, 2870, 2952, 3014, 3070, 3130, 3220, 3304]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45])}), '_data_list': [Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4F)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Nc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(N(C)CCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1cc2ncn(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)c(=O)c2n1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[31, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='COCCNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(OCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3cc(Br)sc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(C4CC4)csc3c2=O)CC1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(C(N)=O)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[32, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(Br)csc3c2=O)CC1'), Data(x=[31, 115], edge_index=[2, 68], edge_attr=[68, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(Br)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(C#Cc3ccccc3)cc2=O)CC1)c1ccccc1'), Data(x=[35, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCOCC3)cc2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(C#CC(C)(C)O)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[40, 115], edge_index=[2, 88], edge_attr=[88, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN(C)C)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[36, 115], edge_index=[2, 80], edge_attr=[80, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='CC(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C#N)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[43, 115], edge_index=[2, 96], edge_attr=[96, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(CN5CCOCC5)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CO)cc4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3scc(Br)c3c2=O)CC1'), Data(x=[35, 115], edge_index=[2, 78], edge_attr=[78, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccn[nH]4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[39, 115], edge_index=[2, 86], edge_attr=[86, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(C(N)=O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4cccc(O)c4)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[33, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCCN(C)C)cc2=O)CC1)c1ccccc1'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc(NCCN3CCCC3)cc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3ccsc3c2=O)CC1'), Data(x=[29, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cn1ncc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc21'), Data(x=[30, 115], edge_index=[2, 66], edge_attr=[66, 7], y=[1, 1], smiles='C#Cc1csc2c(=O)n(CC3(O)CCN(C(=O)CCc4ccccc4)CC3)cnc12'), Data(x=[34, 115], edge_index=[2, 76], edge_attr=[76, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3c(-c4ccccc4)csc3c2=O)CC1'), Data(x=[32, 115], edge_index=[2, 70], edge_attr=[70, 7], y=[1, 1], smiles='C#Cc1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[33, 115], edge_index=[2, 72], edge_attr=[72, 7], y=[1, 1], smiles='C=C(C)c1c2ncn(CC3(O)CCN(C(=O)C[C@@H](C)c4ccccc4)CC3)c(=O)c2nn1C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3occc3c2=O)CC1'), Data(x=[37, 115], edge_index=[2, 82], edge_attr=[82, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccccc4N)n(C)nc3c2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(CCc1ccccc1)N1CCC(O)(Cn2cnc3sccc3c2=O)CC1'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='C[C@H](CC(=O)N1CCC(O)(Cn2cnccc2=O)CC1)c1ccccc1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CNc1cc(=O)n(CC2(O)CCN(C(=O)C[C@@H](C)c3ccccc3)CC2)cn1'), Data(x=[41, 115], edge_index=[2, 90], edge_attr=[90, 7], y=[1, 1], smiles='Cn1nc2c(=O)n(CC3(O)CCN(C(=O)C[C@H](c4ccccc4)C(F)(F)F)CC3)cnc2c1-c1ccc(CN)cc1'), Data(x=[38, 115], edge_index=[2, 84], edge_attr=[84, 7], y=[1, 1], smiles='C[C@@H](CC(=O)N1CCC(O)(Cn2cnc3c(-c4ccc(CN)cc4)n(C)nc3c2=O)CC1)c1ccccc1')]}\n",
      "minv: 4.050000190734863\n",
      "maxv: 8.220000267028809\n",
      "emb_dim: 300\n",
      "Epoch: 000, Loss: 0.7892 Val: 2.0279 Test: 2.3770\n",
      "Epoch: 001, Loss: 0.7544 Val: 1.9930 Test: 2.3229\n",
      "Epoch: 002, Loss: 0.8628 Val: 1.9771 Test: 2.3008\n",
      "Epoch: 003, Loss: 0.8004 Val: 1.9564 Test: 2.2809\n",
      "Epoch: 004, Loss: 0.7493 Val: 1.9218 Test: 2.2468\n",
      "Epoch: 005, Loss: 0.7449 Val: 1.9015 Test: 2.2028\n",
      "Epoch: 006, Loss: 0.7598 Val: 1.8685 Test: 2.1580\n",
      "Epoch: 007, Loss: 0.7340 Val: 1.8382 Test: 2.1165\n",
      "Epoch: 008, Loss: 0.7283 Val: 1.8133 Test: 2.0782\n",
      "Epoch: 009, Loss: 0.7690 Val: 1.7843 Test: 2.0412\n",
      "Epoch: 010, Loss: 0.7029 Val: 1.7600 Test: 2.0235\n",
      "Epoch: 011, Loss: 0.7318 Val: 1.7484 Test: 2.0197\n",
      "Epoch: 012, Loss: 0.7143 Val: 1.7414 Test: 2.0118\n",
      "Epoch: 013, Loss: 0.6756 Val: 1.7158 Test: 1.9794\n",
      "Epoch: 014, Loss: 0.6903 Val: 1.6718 Test: 1.9374\n",
      "Epoch: 015, Loss: 0.6607 Val: 1.6273 Test: 1.8707\n",
      "Epoch: 016, Loss: 0.6997 Val: 1.5914 Test: 1.8230\n",
      "Epoch: 017, Loss: 0.6506 Val: 1.5564 Test: 1.7946\n",
      "Epoch: 018, Loss: 0.6932 Val: 1.5165 Test: 1.7550\n",
      "Epoch: 019, Loss: 0.6678 Val: 1.4769 Test: 1.7141\n",
      "Epoch: 020, Loss: 0.5986 Val: 1.4465 Test: 1.6898\n",
      "Epoch: 021, Loss: 0.6158 Val: 1.4343 Test: 1.6883\n",
      "Epoch: 022, Loss: 0.6355 Val: 1.4111 Test: 1.6756\n",
      "Epoch: 023, Loss: 0.6281 Val: 1.3805 Test: 1.6579\n",
      "Epoch: 024, Loss: 0.6390 Val: 1.3420 Test: 1.6051\n",
      "Epoch: 025, Loss: 0.6242 Val: 1.3035 Test: 1.5538\n",
      "Epoch: 026, Loss: 0.5962 Val: 1.2780 Test: 1.5305\n",
      "Epoch: 027, Loss: 0.6295 Val: 1.2545 Test: 1.4904\n",
      "Epoch: 028, Loss: 0.5530 Val: 1.2317 Test: 1.4661\n",
      "Epoch: 029, Loss: 0.5959 Val: 1.2096 Test: 1.4371\n",
      "Epoch: 030, Loss: 0.5885 Val: 1.1893 Test: 1.4105\n",
      "Epoch: 031, Loss: 0.5848 Val: 1.1664 Test: 1.3757\n",
      "Epoch: 032, Loss: 0.5728 Val: 1.1370 Test: 1.3437\n",
      "Epoch: 033, Loss: 0.6379 Val: 1.1444 Test: 1.3371\n",
      "Epoch: 034, Loss: 0.6082 Val: 1.1603 Test: 1.3432\n",
      "Epoch: 035, Loss: 0.5377 Val: 1.1509 Test: 1.3174\n",
      "Epoch: 036, Loss: 0.6509 Val: 1.1472 Test: 1.2789\n",
      "Epoch: 037, Loss: 0.5327 Val: 1.1454 Test: 1.2374\n",
      "Epoch: 038, Loss: 0.6813 Val: 1.1256 Test: 1.1785\n",
      "Epoch: 039, Loss: 0.6170 Val: 1.1120 Test: 1.1611\n",
      "Epoch: 040, Loss: 0.6238 Val: 1.0878 Test: 1.1432\n",
      "Epoch: 041, Loss: 0.5424 Val: 1.0384 Test: 1.0990\n",
      "Epoch: 042, Loss: 0.6279 Val: 0.9813 Test: 1.0448\n",
      "Epoch: 043, Loss: 0.5902 Val: 0.9437 Test: 0.9863\n",
      "Epoch: 044, Loss: 0.5790 Val: 0.9319 Test: 0.9621\n",
      "Epoch: 045, Loss: 0.6151 Val: 0.9039 Test: 0.9429\n",
      "Epoch: 046, Loss: 0.6381 Val: 0.8609 Test: 0.9363\n",
      "Epoch: 047, Loss: 0.6104 Val: 0.8148 Test: 0.9360\n",
      "Epoch: 048, Loss: 0.5924 Val: 0.7726 Test: 0.9141\n",
      "Epoch: 049, Loss: 0.5869 Val: 0.7954 Test: 0.8646\n",
      "Epoch: 050, Loss: 0.5800 Val: 0.8166 Test: 0.8546\n",
      "Epoch: 051, Loss: 0.5997 Val: 0.8254 Test: 0.8490\n",
      "Epoch: 052, Loss: 0.5620 Val: 0.8384 Test: 0.8110\n",
      "Epoch: 053, Loss: 0.4833 Val: 0.8578 Test: 0.8163\n",
      "Epoch: 054, Loss: 0.5132 Val: 0.8612 Test: 0.8191\n",
      "Epoch: 055, Loss: 0.6615 Val: 0.8654 Test: 0.8047\n",
      "Epoch: 056, Loss: 0.6479 Val: 0.8896 Test: 0.7997\n",
      "Epoch: 057, Loss: 0.6786 Val: 0.8918 Test: 0.7878\n",
      "Epoch: 058, Loss: 0.6129 Val: 0.8809 Test: 0.7793\n",
      "Epoch: 059, Loss: 0.5324 Val: 0.8569 Test: 0.8043\n",
      "Epoch: 060, Loss: 0.5182 Val: 0.8490 Test: 0.7931\n",
      "Epoch: 061, Loss: 0.5396 Val: 0.8617 Test: 0.7654\n",
      "Epoch: 062, Loss: 0.5743 Val: 0.8657 Test: 0.7344\n",
      "Epoch: 063, Loss: 0.5003 Val: 0.8682 Test: 0.7408\n",
      "Epoch: 064, Loss: 0.6325 Val: 0.8643 Test: 0.7530\n",
      "Epoch: 065, Loss: 0.5175 Val: 0.8661 Test: 0.8003\n",
      "Epoch: 066, Loss: 0.6184 Val: 0.8564 Test: 0.7855\n",
      "Epoch: 067, Loss: 0.5477 Val: 0.8455 Test: 0.7453\n",
      "Epoch: 068, Loss: 0.5809 Val: 0.8578 Test: 0.7161\n",
      "Epoch: 069, Loss: 0.5290 Val: 0.8706 Test: 0.7105\n",
      "Epoch: 070, Loss: 0.5079 Val: 0.8712 Test: 0.7306\n",
      "Epoch: 071, Loss: 0.6144 Val: 0.8700 Test: 0.7611\n",
      "Epoch: 072, Loss: 0.5639 Val: 0.8773 Test: 0.7803\n",
      "Epoch: 073, Loss: 0.4969 Val: 0.8914 Test: 0.7857\n",
      "Epoch: 074, Loss: 0.4350 Val: 0.9027 Test: 0.7528\n",
      "Epoch: 075, Loss: 0.5410 Val: 0.9102 Test: 0.6257\n",
      "Epoch: 076, Loss: 0.4566 Val: 0.9430 Test: 0.6461\n",
      "Epoch: 077, Loss: 0.5585 Val: 0.9621 Test: 0.7046\n",
      "Epoch: 078, Loss: 0.5184 Val: 0.9677 Test: 0.7508\n",
      "Epoch: 079, Loss: 0.5529 Val: 0.9508 Test: 0.7789\n",
      "Epoch: 080, Loss: 0.4646 Val: 0.9445 Test: 0.7666\n",
      "Epoch: 081, Loss: 0.5586 Val: 0.9471 Test: 0.7524\n",
      "Epoch: 082, Loss: 0.4972 Val: 0.9548 Test: 0.7103\n",
      "Epoch: 083, Loss: 0.5494 Val: 0.9781 Test: 0.6391\n",
      "Epoch: 084, Loss: 0.5149 Val: 1.0043 Test: 0.6236\n",
      "Epoch: 085, Loss: 0.5912 Val: 1.0055 Test: 0.6344\n",
      "Epoch: 086, Loss: 0.4779 Val: 0.9666 Test: 0.6354\n",
      "Epoch: 087, Loss: 0.6072 Val: 0.9396 Test: 0.6616\n",
      "Epoch: 088, Loss: 0.5678 Val: 0.9239 Test: 0.6985\n",
      "Epoch: 089, Loss: 0.5449 Val: 0.9187 Test: 0.7179\n",
      "Epoch: 090, Loss: 0.5102 Val: 0.9183 Test: 0.7290\n",
      "Epoch: 091, Loss: 0.5495 Val: 0.9207 Test: 0.7480\n",
      "Epoch: 092, Loss: 0.5370 Val: 0.9270 Test: 0.7604\n",
      "Epoch: 093, Loss: 0.5727 Val: 0.9277 Test: 0.7279\n",
      "Epoch: 094, Loss: 0.5908 Val: 0.9254 Test: 0.6976\n",
      "Epoch: 095, Loss: 0.5370 Val: 0.9236 Test: 0.7041\n",
      "Epoch: 096, Loss: 0.5016 Val: 0.9283 Test: 0.7323\n",
      "Epoch: 097, Loss: 0.5314 Val: 0.9298 Test: 0.7685\n",
      "Epoch: 098, Loss: 0.5414 Val: 0.9328 Test: 0.7922\n",
      "Epoch: 099, Loss: 0.5612 Val: 0.9366 Test: 0.8026\n",
      "Epoch: 100, Loss: 0.4926 Val: 0.9469 Test: 0.7867\n",
      "Epoch: 101, Loss: 0.5428 Val: 0.9549 Test: 0.7695\n",
      "Epoch: 102, Loss: 0.5929 Val: 0.9598 Test: 0.7592\n",
      "Epoch: 103, Loss: 0.5133 Val: 0.9672 Test: 0.7371\n",
      "Epoch: 104, Loss: 0.4917 Val: 0.9695 Test: 0.7179\n",
      "Epoch: 105, Loss: 0.5361 Val: 0.9664 Test: 0.7081\n",
      "Epoch: 106, Loss: 0.5179 Val: 0.9596 Test: 0.7050\n",
      "Epoch: 107, Loss: 0.5230 Val: 0.9521 Test: 0.7086\n",
      "Epoch: 108, Loss: 0.4949 Val: 0.9482 Test: 0.7212\n",
      "Epoch: 109, Loss: 0.4449 Val: 0.9402 Test: 0.7364\n",
      "Epoch: 110, Loss: 0.4687 Val: 0.9421 Test: 0.7564\n",
      "Epoch: 111, Loss: 0.5304 Val: 0.9582 Test: 0.7769\n",
      "Epoch: 112, Loss: 0.5074 Val: 0.9727 Test: 0.7919\n",
      "Epoch: 113, Loss: 0.6031 Val: 0.9766 Test: 0.8016\n",
      "Epoch: 114, Loss: 0.4670 Val: 0.9708 Test: 0.7853\n",
      "Epoch: 115, Loss: 0.4844 Val: 0.9764 Test: 0.7872\n",
      "Epoch: 116, Loss: 0.5768 Val: 0.9895 Test: 0.7964\n",
      "Epoch: 117, Loss: 0.5605 Val: 0.9968 Test: 0.8019\n",
      "Epoch: 118, Loss: 0.5915 Val: 0.9996 Test: 0.8116\n",
      "Epoch: 119, Loss: 0.5134 Val: 0.9987 Test: 0.7967\n",
      "Epoch: 120, Loss: 0.5052 Val: 0.9958 Test: 0.7759\n",
      "Epoch: 121, Loss: 0.5257 Val: 0.9872 Test: 0.7573\n",
      "Epoch: 122, Loss: 0.4307 Val: 0.9839 Test: 0.7437\n",
      "Epoch: 123, Loss: 0.5751 Val: 0.9843 Test: 0.7451\n",
      "Epoch: 124, Loss: 0.4492 Val: 0.9859 Test: 0.7556\n",
      "Epoch: 125, Loss: 0.5589 Val: 0.9867 Test: 0.7619\n",
      "Epoch: 126, Loss: 0.5534 Val: 0.9879 Test: 0.7843\n",
      "Epoch: 127, Loss: 0.6435 Val: 0.9993 Test: 0.7945\n",
      "Epoch: 128, Loss: 0.4600 Val: 1.0246 Test: 0.8048\n",
      "Epoch: 129, Loss: 0.4993 Val: 1.0439 Test: 0.8087\n",
      "Epoch: 130, Loss: 0.5214 Val: 1.0587 Test: 0.8208\n",
      "Epoch: 131, Loss: 0.4423 Val: 1.0707 Test: 0.8501\n",
      "Epoch: 132, Loss: 0.5196 Val: 1.0783 Test: 0.8849\n",
      "Epoch: 133, Loss: 0.5335 Val: 1.0844 Test: 0.8500\n",
      "Epoch: 134, Loss: 0.6075 Val: 1.0888 Test: 0.8134\n",
      "Epoch: 135, Loss: 0.5338 Val: 1.0920 Test: 0.7709\n",
      "Epoch: 136, Loss: 0.5148 Val: 1.0902 Test: 0.7349\n",
      "Epoch: 137, Loss: 0.4647 Val: 1.0861 Test: 0.7036\n",
      "Epoch: 138, Loss: 0.5638 Val: 1.0931 Test: 0.6654\n",
      "Epoch: 139, Loss: 0.4775 Val: 1.0987 Test: 0.6937\n",
      "Epoch: 140, Loss: 0.5384 Val: 1.0864 Test: 0.7828\n",
      "Epoch: 141, Loss: 0.4221 Val: 1.0681 Test: 0.8000\n",
      "Epoch: 142, Loss: 0.5660 Val: 1.0478 Test: 0.7129\n",
      "Epoch: 143, Loss: 0.5693 Val: 1.0227 Test: 0.6967\n",
      "Epoch: 144, Loss: 0.4145 Val: 0.9996 Test: 0.7193\n",
      "Epoch: 145, Loss: 0.5216 Val: 0.9809 Test: 0.7585\n",
      "Epoch: 146, Loss: 0.5008 Val: 0.9522 Test: 0.7668\n",
      "Epoch: 147, Loss: 0.4909 Val: 0.9380 Test: 0.8003\n",
      "Epoch: 148, Loss: 0.6315 Val: 0.9186 Test: 0.8069\n",
      "Epoch: 149, Loss: 0.4364 Val: 0.8880 Test: 0.7545\n",
      "Epoch: 150, Loss: 0.5979 Val: 0.8737 Test: 0.7301\n",
      "Epoch: 151, Loss: 0.5420 Val: 0.8637 Test: 0.7388\n",
      "Epoch: 152, Loss: 0.5214 Val: 0.8573 Test: 0.7565\n",
      "Epoch: 153, Loss: 0.5488 Val: 0.8703 Test: 0.7746\n",
      "Epoch: 154, Loss: 0.5238 Val: 0.8867 Test: 0.7918\n",
      "Epoch: 155, Loss: 0.5271 Val: 0.9136 Test: 0.8058\n",
      "Epoch: 156, Loss: 0.5814 Val: 0.9367 Test: 0.8168\n",
      "Epoch: 157, Loss: 0.4285 Val: 0.9529 Test: 0.8196\n",
      "Epoch: 158, Loss: 0.4998 Val: 0.9618 Test: 0.8177\n",
      "Epoch: 159, Loss: 0.4334 Val: 0.9602 Test: 0.8118\n",
      "Epoch: 160, Loss: 0.4895 Val: 0.9566 Test: 0.8033\n",
      "Epoch: 161, Loss: 0.4546 Val: 0.9393 Test: 0.8010\n",
      "Epoch: 162, Loss: 0.4605 Val: 0.9170 Test: 0.8007\n",
      "Epoch: 163, Loss: 0.5413 Val: 0.9359 Test: 0.8021\n",
      "Epoch: 164, Loss: 0.4679 Val: 0.9805 Test: 0.8168\n",
      "Epoch: 165, Loss: 0.5399 Val: 0.9323 Test: 0.8411\n",
      "Epoch: 166, Loss: 0.4874 Val: 0.8844 Test: 0.8528\n",
      "Epoch: 167, Loss: 0.5468 Val: 0.8424 Test: 0.8508\n",
      "Epoch: 168, Loss: 0.5462 Val: 0.8153 Test: 0.8382\n",
      "Epoch: 169, Loss: 0.4406 Val: 0.8075 Test: 0.8231\n",
      "Epoch: 170, Loss: 0.5578 Val: 0.8053 Test: 0.8172\n",
      "Epoch: 171, Loss: 0.4569 Val: 0.8091 Test: 0.8151\n",
      "Epoch: 172, Loss: 0.5805 Val: 0.8314 Test: 0.8235\n",
      "Epoch: 173, Loss: 0.6126 Val: 0.8689 Test: 0.8418\n",
      "Epoch: 174, Loss: 0.5788 Val: 0.9074 Test: 0.8615\n",
      "Epoch: 175, Loss: 0.4786 Val: 0.9176 Test: 0.9026\n",
      "Epoch: 176, Loss: 0.4665 Val: 0.8882 Test: 0.9407\n",
      "Epoch: 177, Loss: 0.4029 Val: 0.8389 Test: 0.9385\n",
      "Epoch: 178, Loss: 0.5934 Val: 0.7954 Test: 0.9195\n",
      "Epoch: 179, Loss: 0.5448 Val: 0.7774 Test: 0.8797\n",
      "Epoch: 180, Loss: 0.5164 Val: 0.7774 Test: 0.8412\n",
      "Epoch: 181, Loss: 0.5061 Val: 0.7801 Test: 0.8127\n",
      "Epoch: 182, Loss: 0.5328 Val: 0.7746 Test: 0.7920\n",
      "Epoch: 183, Loss: 0.4930 Val: 0.7721 Test: 0.7799\n",
      "Epoch: 184, Loss: 0.5204 Val: 0.7659 Test: 0.7874\n",
      "Epoch: 185, Loss: 0.5157 Val: 0.7244 Test: 0.8326\n",
      "Epoch: 186, Loss: 0.4496 Val: 0.7027 Test: 0.8581\n",
      "Epoch: 187, Loss: 0.5285 Val: 0.6861 Test: 0.8521\n",
      "Epoch: 188, Loss: 0.4157 Val: 0.6769 Test: 0.8415\n",
      "Epoch: 189, Loss: 0.5904 Val: 0.7196 Test: 0.8212\n",
      "Epoch: 190, Loss: 0.5326 Val: 0.8100 Test: 0.8059\n",
      "Epoch: 191, Loss: 0.4757 Val: 0.8829 Test: 0.7875\n",
      "Epoch: 192, Loss: 0.5297 Val: 0.9247 Test: 0.7747\n",
      "Epoch: 193, Loss: 0.5098 Val: 0.9570 Test: 0.7483\n",
      "Epoch: 194, Loss: 0.5674 Val: 0.9727 Test: 0.7397\n",
      "Epoch: 195, Loss: 0.5952 Val: 0.9766 Test: 0.7359\n",
      "Epoch: 196, Loss: 0.4779 Val: 0.9799 Test: 0.7533\n",
      "Epoch: 197, Loss: 0.5669 Val: 0.9869 Test: 0.7759\n",
      "Epoch: 198, Loss: 0.5568 Val: 1.0074 Test: 0.8067\n",
      "Epoch: 199, Loss: 0.4850 Val: 1.0377 Test: 0.8349\n",
      "mth1\n",
      "\n",
      "Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='CC(C)(CO)CNc1ccnc(N)n1')\n",
      "MTH1(4)\n",
      "dict {0: {'train': [Data(x=[14, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CCOC(=O)c1ccnc2[nH]ccc12'), Data(x=[12, 115], edge_index=[2, 24], edge_attr=[24, 7], y=[1, 1], smiles='Nc1nccc(NCCCO)n1'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2CN(c3ccnc4[nH]ccc34)CCO2)cc1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)CCN(c1ccnc3[nH]ccc13)C2'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)OCCN2c1ccnc2[nH]ccc12'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='COc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='COC(C)(C)C1CCCN1c1ccnc2[nH]ncc12'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)C'), Data(x=[23, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOCC3C3CC3)ccnc2[nH]1')], 'test': [Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='NC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='N#Cc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 34], edge_attr=[34, 7], y=[1, 1], smiles='c1cncc(-c2ccnc3[nH]ccc23)c1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ncc23)c1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CN(C)C(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cc(-c2cnc3[nH]ccc3c2)c2cc[nH]c2n1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ccc23)c1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='OCc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='CC(C)(CO)CNc1ccnc(N)n1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cnc2c(c1)CCN2c1ccnc2[nH]ccc12'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)CO)nc(N)n1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccnc3)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='COCC(C)(C)CNc1ccnc(N)n1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)C)nc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)CNc1ccnc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)COc1ccnc(N)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1cncc(C2CCCN2c2ccnc3[nH]ncc23)c1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)ncc1Cl'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[22, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='O=C(NC1CC1)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ccc23)cc1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)nc2c1CCC2'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)CO'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2COCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1CCC(C)(C)C'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOC[C@@H]3C)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)CO'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)C'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)C'), Data(x=[27, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(NC1COC1)c1cc2c(N3CCCC3c3cccnc3)ccnc2[nH]1')]}, 1: {'train': [Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='NC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CN(C)C(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='CC(C)(CO)CNc1ccnc(N)n1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='COCC(C)(C)CNc1ccnc(N)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1cncc(C2CCCN2c2ccnc3[nH]ncc23)c1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)nc2c1CCC2'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)CO')], 'test': [Data(x=[14, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CCOC(=O)c1ccnc2[nH]ccc12'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='N#Cc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 34], edge_attr=[34, 7], y=[1, 1], smiles='c1cncc(-c2ccnc3[nH]ccc23)c1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ncc23)c1'), Data(x=[12, 115], edge_index=[2, 24], edge_attr=[24, 7], y=[1, 1], smiles='Nc1nccc(NCCCO)n1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cc(-c2cnc3[nH]ccc3c2)c2cc[nH]c2n1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ccc23)c1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='OCc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2CN(c3ccnc4[nH]ccc34)CCO2)cc1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cnc2c(c1)CCN2c1ccnc2[nH]ccc12'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)CO)nc(N)n1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccnc3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)CCN(c1ccnc3[nH]ccc13)C2'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)C)nc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)CNc1ccnc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)COc1ccnc(N)n1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)OCCN2c1ccnc2[nH]ccc12'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)ncc1Cl'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='COc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[22, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='O=C(NC1CC1)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ccc23)cc1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='COC(C)(C)C1CCCN1c1ccnc2[nH]ncc12'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)CO'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2COCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1CCC(C)(C)C'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOC[C@@H]3C)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)C'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)C'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)C'), Data(x=[27, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(NC1COC1)c1cc2c(N3CCCC3c3cccnc3)ccnc2[nH]1'), Data(x=[23, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOCC3C3CC3)ccnc2[nH]1')]}, 2: {'train': [Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='N#Cc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cc(-c2cnc3[nH]ccc3c2)c2cc[nH]c2n1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cnc2c(c1)CCN2c1ccnc2[nH]ccc12'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)C)nc(N)n1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)ncc1Cl'), Data(x=[22, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='O=C(NC1CC1)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)CO'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)C')], 'test': [Data(x=[14, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CCOC(=O)c1ccnc2[nH]ccc12'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='NC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 34], edge_attr=[34, 7], y=[1, 1], smiles='c1cncc(-c2ccnc3[nH]ccc23)c1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ncc23)c1'), Data(x=[12, 115], edge_index=[2, 24], edge_attr=[24, 7], y=[1, 1], smiles='Nc1nccc(NCCCO)n1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CN(C)C(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ccc23)c1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='OCc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2CN(c3ccnc4[nH]ccc34)CCO2)cc1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='CC(C)(CO)CNc1ccnc(N)n1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)CO)nc(N)n1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccnc3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)CCN(c1ccnc3[nH]ccc13)C2'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='COCC(C)(C)CNc1ccnc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)CNc1ccnc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)COc1ccnc(N)n1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)OCCN2c1ccnc2[nH]ccc12'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1cncc(C2CCCN2c2ccnc3[nH]ncc23)c1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='COc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ccc23)cc1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='COC(C)(C)C1CCCN1c1ccnc2[nH]ncc12'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)nc2c1CCC2'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2COCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1CCC(C)(C)C'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOC[C@@H]3C)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)C'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)CO'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)C'), Data(x=[27, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(NC1COC1)c1cc2c(N3CCCC3c3cccnc3)ccnc2[nH]1'), Data(x=[23, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOCC3C3CC3)ccnc2[nH]1')]}, 3: {'train': [Data(x=[15, 115], edge_index=[2, 34], edge_attr=[34, 7], y=[1, 1], smiles='c1cncc(-c2ccnc3[nH]ccc23)c1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ccc23)c1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)CO)nc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)CNc1ccnc(N)n1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2COCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOC[C@@H]3C)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)C')], 'test': [Data(x=[14, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CCOC(=O)c1ccnc2[nH]ccc12'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='NC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='N#Cc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ncc23)c1'), Data(x=[12, 115], edge_index=[2, 24], edge_attr=[24, 7], y=[1, 1], smiles='Nc1nccc(NCCCO)n1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CN(C)C(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cc(-c2cnc3[nH]ccc3c2)c2cc[nH]c2n1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='OCc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2CN(c3ccnc4[nH]ccc34)CCO2)cc1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='CC(C)(CO)CNc1ccnc(N)n1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cnc2c(c1)CCN2c1ccnc2[nH]ccc12'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccnc3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)CCN(c1ccnc3[nH]ccc13)C2'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='COCC(C)(C)CNc1ccnc(N)n1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)C)nc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)COc1ccnc(N)n1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)OCCN2c1ccnc2[nH]ccc12'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1cncc(C2CCCN2c2ccnc3[nH]ncc23)c1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)ncc1Cl'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='COc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[22, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='O=C(NC1CC1)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ccc23)cc1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='COC(C)(C)C1CCCN1c1ccnc2[nH]ncc12'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)nc2c1CCC2'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)CO'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1CCC(C)(C)C'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)C'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)CO'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)C'), Data(x=[27, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(NC1COC1)c1cc2c(N3CCCC3c3cccnc3)ccnc2[nH]1'), Data(x=[23, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOCC3C3CC3)ccnc2[nH]1')]}, 4: {'train': [Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ncc23)c1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='OCc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccnc3)ccnc2[nH]1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)COc1ccnc(N)n1'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ccc23)cc1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1CCC(C)(C)C'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[27, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(NC1COC1)c1cc2c(N3CCCC3c3cccnc3)ccnc2[nH]1')], 'test': [Data(x=[14, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CCOC(=O)c1ccnc2[nH]ccc12'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='NC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='N#Cc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 34], edge_attr=[34, 7], y=[1, 1], smiles='c1cncc(-c2ccnc3[nH]ccc23)c1'), Data(x=[12, 115], edge_index=[2, 24], edge_attr=[24, 7], y=[1, 1], smiles='Nc1nccc(NCCCO)n1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CN(C)C(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cc(-c2cnc3[nH]ccc3c2)c2cc[nH]c2n1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ccc23)c1'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2CN(c3ccnc4[nH]ccc34)CCO2)cc1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='CC(C)(CO)CNc1ccnc(N)n1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cnc2c(c1)CCN2c1ccnc2[nH]ccc12'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)CO)nc(N)n1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)CCN(c1ccnc3[nH]ccc13)C2'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='COCC(C)(C)CNc1ccnc(N)n1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)C)nc(N)n1'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)CNc1ccnc(N)n1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)OCCN2c1ccnc2[nH]ccc12'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1cncc(C2CCCN2c2ccnc3[nH]ncc23)c1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)ncc1Cl'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='COc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[22, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='O=C(NC1CC1)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='COC(C)(C)C1CCCN1c1ccnc2[nH]ncc12'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)nc2c1CCC2'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)CO'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2COCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOC[C@@H]3C)ccnc2[nH]1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)C'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)CO'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)C'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)C'), Data(x=[23, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOCC3C3CC3)ccnc2[nH]1')]}}\n",
      "10\n",
      "36\n",
      "1\n",
      "3\n",
      "torch.Size([804, 115])\n",
      "{'name': 'mth1', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fc0614c7940>, 'pre_filter': None, '_indices': [41, 23, 11, 37, 29, 35, 43, 39, 10, 20, 33, 16, 40, 26, 13, 4, 3, 21, 32, 31, 12, 28, 0, 18, 24, 45, 15, 17, 14, 34, 25, 27, 38, 44, 6, 2, 5, 42, 19, 1, 8, 36, 30, 22, 7, 9], 'data': Data(x=[804, 115], edge_index=[2, 1746], edge_attr=[1746, 7], y=[46, 1], smiles=[46]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([  0,  19,  31,  50,  77,  98, 115, 137, 152, 173, 196, 210, 225, 238,\n",
      "        255, 272, 287, 307, 323, 339, 354, 370, 384, 399, 413, 433, 451, 470,\n",
      "        490, 508, 526, 545, 559, 573, 586, 601, 622, 643, 664, 680, 699, 718,\n",
      "        732, 747, 766, 784, 804]), 'edge_index': tensor([   0,   44,   68,  112,  174,  220,  256,  306,  340,  386,  438,  466,\n",
      "         496,  522,  558,  594,  624,  668,  704,  736,  766,  798,  826,  856,\n",
      "         884,  930,  970, 1012, 1058, 1100, 1140, 1182, 1210, 1240, 1266, 1296,\n",
      "        1344, 1390, 1438, 1474, 1516, 1558, 1586, 1616, 1658, 1700, 1746]), 'edge_attr': tensor([   0,   44,   68,  112,  174,  220,  256,  306,  340,  386,  438,  466,\n",
      "         496,  522,  558,  594,  624,  668,  704,  736,  766,  798,  826,  856,\n",
      "         884,  930,  970, 1012, 1058, 1100, 1140, 1182, 1210, 1240, 1266, 1296,\n",
      "        1344, 1390, 1438, 1474, 1516, 1558, 1586, 1616, 1658, 1700, 1746]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46])}), '_data_list': [Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)OCCN2c1ccnc2[nH]ccc12'), Data(x=[12, 115], edge_index=[2, 24], edge_attr=[24, 7], y=[1, 1], smiles='Nc1nccc(NCCCO)n1'), Data(x=[19, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='c1ccc2c(c1)CCN(c1ccnc3[nH]ccc13)C2'), Data(x=[27, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='O=C(NC1COC1)c1cc2c(N3CCCC3c3cccnc3)ccnc2[nH]1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOC[C@@H]3C)ccnc2[nH]1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)nc2c1CCC2'), Data(x=[22, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='O=C(NC1CC1)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[15, 115], edge_index=[2, 34], edge_attr=[34, 7], y=[1, 1], smiles='c1cncc(-c2ccnc3[nH]ccc23)c1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CN(C)C(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[23, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(N3CCOCC3C3CC3)ccnc2[nH]1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1CCC(C)(C)C'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CC(C)(CO)COc1nc(N)ncc1Cl'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)CNc1ccnc(N)n1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[17, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='CNc1cc(-c2cccc(Cl)c2Cl)nc(N)n1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)C'), Data(x=[20, 115], edge_index=[2, 44], edge_attr=[44, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ccc23)c1'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='Cc1cnc(N)nc1N(C)CC(C)(C)CO'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='COCC(C)(C)CNc1ccnc(N)n1'), Data(x=[16, 115], edge_index=[2, 32], edge_attr=[32, 7], y=[1, 1], smiles='COc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)C'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)CO)nc(N)n1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cc(OCC(C)(C)C)nc(N)n1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ccc23)cc1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='OCc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='NC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1cncc(C2CCCN2c2ccnc3[nH]ncc23)c1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cc(-c2cnc3[nH]ccc3c2)c2cc[nH]c2n1'), Data(x=[18, 115], edge_index=[2, 40], edge_attr=[40, 7], y=[1, 1], smiles='N#Cc1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='COC(C)(C)C1CCCN1c1ccnc2[nH]ncc12'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)C'), Data(x=[14, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='CCOC(=O)c1ccnc2[nH]ccc12'), Data(x=[13, 115], edge_index=[2, 26], edge_attr=[26, 7], y=[1, 1], smiles='CC(C)(C)COc1ccnc(N)n1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1NCC(C)(C)CO'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2CN(c3ccnc4[nH]ccc34)CCO2)cc1'), Data(x=[21, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='CCNC(=O)c1cc2c(-c3cccc(Cl)c3)ccnc2[nH]1'), Data(x=[21, 115], edge_index=[2, 48], edge_attr=[48, 7], y=[1, 1], smiles='c1ccc(C2COCCN2c2ccnc3[nH]ncc23)cc1'), Data(x=[16, 115], edge_index=[2, 36], edge_attr=[36, 7], y=[1, 1], smiles='Clc1cccc(-c2ccnc3[nH]ncc23)c1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='Nc1nc(NC2CC2)cc(-c2cccc(Cl)c2Cl)n1'), Data(x=[14, 115], edge_index=[2, 28], edge_attr=[28, 7], y=[1, 1], smiles='CC(C)(CO)CNc1ccnc(N)n1'), Data(x=[15, 115], edge_index=[2, 30], edge_attr=[30, 7], y=[1, 1], smiles='Cc1cnc(N)nc1OCC(C)(C)CO'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='CNC(=O)c1cc2c(-c3cccnc3)ccnc2[nH]1'), Data(x=[18, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='c1cnc2c(c1)CCN2c1ccnc2[nH]ccc12'), Data(x=[20, 115], edge_index=[2, 46], edge_attr=[46, 7], y=[1, 1], smiles='c1ccc(C2CCCN2c2ccnc3[nH]ncc23)cc1')]}\n",
      "minv: 5.0\n",
      "maxv: 10.0\n",
      "emb_dim: 300\n",
      "Epoch: 000, Loss: 0.8397 Val: 2.5112 Test: 3.4875\n",
      "Epoch: 001, Loss: 0.8174 Val: 2.4675 Test: 3.4346\n",
      "Epoch: 002, Loss: 0.7645 Val: 2.4284 Test: 3.4009\n",
      "Epoch: 003, Loss: 0.7071 Val: 2.3885 Test: 3.3642\n",
      "Epoch: 004, Loss: 0.6865 Val: 2.3541 Test: 3.3314\n",
      "Epoch: 005, Loss: 0.7054 Val: 2.3196 Test: 3.2979\n",
      "Epoch: 006, Loss: 0.7323 Val: 2.3057 Test: 3.2783\n",
      "Epoch: 007, Loss: 0.7080 Val: 2.2697 Test: 3.2479\n",
      "Epoch: 008, Loss: 0.7265 Val: 2.2432 Test: 3.2188\n",
      "Epoch: 009, Loss: 0.7210 Val: 2.2197 Test: 3.1944\n",
      "Epoch: 010, Loss: 0.7040 Val: 2.1906 Test: 3.1554\n",
      "Epoch: 011, Loss: 0.6359 Val: 2.1706 Test: 3.1198\n",
      "Epoch: 012, Loss: 0.6647 Val: 2.1407 Test: 3.0941\n",
      "Epoch: 013, Loss: 0.7130 Val: 2.1096 Test: 3.0566\n",
      "Epoch: 014, Loss: 0.7027 Val: 2.0765 Test: 3.0173\n",
      "Epoch: 015, Loss: 0.6279 Val: 2.0422 Test: 2.9765\n",
      "Epoch: 016, Loss: 0.6111 Val: 2.0092 Test: 2.9454\n",
      "Epoch: 017, Loss: 0.6138 Val: 1.9802 Test: 2.9115\n",
      "Epoch: 018, Loss: 0.5760 Val: 1.9526 Test: 2.8773\n",
      "Epoch: 019, Loss: 0.6153 Val: 1.9223 Test: 2.8414\n",
      "Epoch: 020, Loss: 0.5441 Val: 1.8972 Test: 2.8218\n",
      "Epoch: 021, Loss: 0.6730 Val: 1.8707 Test: 2.8129\n",
      "Epoch: 022, Loss: 0.5837 Val: 1.8341 Test: 2.7536\n",
      "Epoch: 023, Loss: 0.6668 Val: 1.7976 Test: 2.7489\n",
      "Epoch: 024, Loss: 0.6442 Val: 1.7782 Test: 2.7521\n",
      "Epoch: 025, Loss: 0.7295 Val: 1.7542 Test: 2.7363\n",
      "Epoch: 026, Loss: 0.6425 Val: 1.7273 Test: 2.7131\n",
      "Epoch: 027, Loss: 0.6303 Val: 1.6839 Test: 2.6826\n",
      "Epoch: 028, Loss: 0.6019 Val: 1.6444 Test: 2.6432\n",
      "Epoch: 029, Loss: 0.5965 Val: 1.6069 Test: 2.5894\n",
      "Epoch: 030, Loss: 0.6165 Val: 1.5860 Test: 2.5347\n",
      "Epoch: 031, Loss: 0.6280 Val: 1.5472 Test: 2.4866\n",
      "Epoch: 032, Loss: 0.5594 Val: 1.5126 Test: 2.4407\n",
      "Epoch: 033, Loss: 0.5493 Val: 1.4815 Test: 2.4111\n",
      "Epoch: 034, Loss: 0.5215 Val: 1.4521 Test: 2.3632\n",
      "Epoch: 035, Loss: 0.5446 Val: 1.4289 Test: 2.3203\n",
      "Epoch: 036, Loss: 0.5821 Val: 1.4104 Test: 2.2685\n",
      "Epoch: 037, Loss: 0.6639 Val: 1.3979 Test: 2.2400\n",
      "Epoch: 038, Loss: 0.5916 Val: 1.3750 Test: 2.2357\n",
      "Epoch: 039, Loss: 0.4791 Val: 1.3172 Test: 2.0476\n",
      "Epoch: 040, Loss: 0.3887 Val: 1.2657 Test: 1.9663\n",
      "Epoch: 041, Loss: 0.4779 Val: 1.2315 Test: 1.9294\n",
      "Epoch: 042, Loss: 0.4450 Val: 1.2133 Test: 1.9274\n",
      "Epoch: 043, Loss: 0.4794 Val: 1.1864 Test: 1.8834\n",
      "Epoch: 044, Loss: 0.4216 Val: 1.1532 Test: 1.8154\n",
      "Epoch: 045, Loss: 0.3744 Val: 1.1178 Test: 1.7713\n",
      "Epoch: 046, Loss: 0.4454 Val: 1.0818 Test: 1.6994\n",
      "Epoch: 047, Loss: 0.3962 Val: 1.0364 Test: 1.6174\n",
      "Epoch: 048, Loss: 0.4635 Val: 1.0035 Test: 1.6247\n",
      "Epoch: 049, Loss: 0.3837 Val: 1.0026 Test: 1.6407\n",
      "Epoch: 050, Loss: 0.3649 Val: 0.9771 Test: 1.6247\n",
      "Epoch: 051, Loss: 0.3933 Val: 0.9761 Test: 1.6004\n",
      "Epoch: 052, Loss: 0.3675 Val: 0.9742 Test: 1.5534\n",
      "Epoch: 053, Loss: 0.3893 Val: 0.9845 Test: 1.5037\n",
      "Epoch: 054, Loss: 0.3959 Val: 1.0156 Test: 1.5081\n",
      "Epoch: 055, Loss: 0.4726 Val: 0.9871 Test: 1.4131\n",
      "Epoch: 056, Loss: 0.4225 Val: 0.9804 Test: 1.5174\n",
      "Epoch: 057, Loss: 0.4432 Val: 1.0057 Test: 1.5738\n",
      "Epoch: 058, Loss: 0.5377 Val: 1.0100 Test: 1.6759\n",
      "Epoch: 059, Loss: 0.4835 Val: 0.9372 Test: 1.6794\n",
      "Epoch: 060, Loss: 0.5599 Val: 0.9279 Test: 1.6634\n",
      "Epoch: 061, Loss: 0.4246 Val: 0.9066 Test: 1.6464\n",
      "Epoch: 062, Loss: 0.3647 Val: 0.9078 Test: 1.6086\n",
      "Epoch: 063, Loss: 0.3476 Val: 0.9300 Test: 1.5620\n",
      "Epoch: 064, Loss: 0.4702 Val: 0.9355 Test: 1.5089\n",
      "Epoch: 065, Loss: 0.4221 Val: 0.9703 Test: 1.4521\n",
      "Epoch: 066, Loss: 0.3173 Val: 0.9890 Test: 1.3653\n",
      "Epoch: 067, Loss: 0.4474 Val: 0.9554 Test: 1.3893\n",
      "Epoch: 068, Loss: 0.6154 Val: 0.8336 Test: 1.3115\n",
      "Epoch: 069, Loss: 0.4047 Val: 0.8127 Test: 1.3159\n",
      "Epoch: 070, Loss: 0.3297 Val: 0.8529 Test: 1.2802\n",
      "Epoch: 071, Loss: 0.3417 Val: 0.8976 Test: 1.2361\n",
      "Epoch: 072, Loss: 0.3299 Val: 0.8934 Test: 1.2108\n",
      "Epoch: 073, Loss: 0.3426 Val: 0.8757 Test: 1.1909\n",
      "Epoch: 074, Loss: 0.3940 Val: 0.8500 Test: 1.1792\n",
      "Epoch: 075, Loss: 0.3084 Val: 0.8195 Test: 1.1792\n",
      "Epoch: 076, Loss: 0.3435 Val: 0.8131 Test: 1.1837\n",
      "Epoch: 077, Loss: 0.4100 Val: 0.7745 Test: 1.1987\n",
      "Epoch: 078, Loss: 0.3377 Val: 0.7760 Test: 1.2308\n",
      "Epoch: 079, Loss: 0.3662 Val: 0.7495 Test: 1.2150\n",
      "Epoch: 080, Loss: 0.2573 Val: 0.7841 Test: 1.1913\n",
      "Epoch: 081, Loss: 0.3886 Val: 0.7982 Test: 1.1696\n",
      "Epoch: 082, Loss: 0.4374 Val: 0.7869 Test: 1.1634\n",
      "Epoch: 083, Loss: 0.3059 Val: 0.7851 Test: 1.1483\n",
      "Epoch: 084, Loss: 0.3354 Val: 0.8089 Test: 1.1359\n",
      "Epoch: 085, Loss: 0.4353 Val: 0.8622 Test: 1.1402\n",
      "Epoch: 086, Loss: 0.3655 Val: 0.8834 Test: 1.1400\n",
      "Epoch: 087, Loss: 0.3537 Val: 0.8787 Test: 1.1373\n",
      "Epoch: 088, Loss: 0.3529 Val: 0.8640 Test: 1.1314\n",
      "Epoch: 089, Loss: 0.4489 Val: 0.8045 Test: 1.1004\n",
      "Epoch: 090, Loss: 0.3847 Val: 0.8462 Test: 1.6129\n",
      "Epoch: 091, Loss: 0.5129 Val: 0.7538 Test: 1.4063\n",
      "Epoch: 092, Loss: 0.5043 Val: 0.7918 Test: 1.0363\n",
      "Epoch: 093, Loss: 0.3370 Val: 0.8145 Test: 0.7487\n",
      "Epoch: 094, Loss: 0.3182 Val: 0.8446 Test: 0.7016\n",
      "Epoch: 095, Loss: 0.4121 Val: 0.8384 Test: 0.6912\n",
      "Epoch: 096, Loss: 0.3816 Val: 0.8137 Test: 0.7258\n",
      "Epoch: 097, Loss: 0.4134 Val: 0.7922 Test: 0.8227\n",
      "Epoch: 098, Loss: 0.4208 Val: 0.7616 Test: 1.1045\n",
      "Epoch: 099, Loss: 0.3500 Val: 0.8080 Test: 1.1730\n",
      "Epoch: 100, Loss: 0.2877 Val: 0.7919 Test: 1.1301\n",
      "Epoch: 101, Loss: 0.2487 Val: 0.7979 Test: 1.1041\n",
      "Epoch: 102, Loss: 0.4047 Val: 0.8032 Test: 1.0928\n",
      "Epoch: 103, Loss: 0.2832 Val: 0.8048 Test: 1.0719\n",
      "Epoch: 104, Loss: 0.3101 Val: 0.8137 Test: 1.1132\n",
      "Epoch: 105, Loss: 0.2653 Val: 0.8383 Test: 1.1254\n",
      "Epoch: 106, Loss: 0.3845 Val: 0.8693 Test: 1.0785\n",
      "Epoch: 107, Loss: 0.3033 Val: 0.8729 Test: 0.9852\n",
      "Epoch: 108, Loss: 0.3235 Val: 0.8870 Test: 1.0484\n",
      "Epoch: 109, Loss: 0.3186 Val: 0.8983 Test: 1.0886\n",
      "Epoch: 110, Loss: 0.3867 Val: 0.8900 Test: 1.0887\n",
      "Epoch: 111, Loss: 0.2623 Val: 0.9114 Test: 1.0598\n",
      "Epoch: 112, Loss: 0.3003 Val: 0.9590 Test: 1.0519\n",
      "Epoch: 113, Loss: 0.3098 Val: 0.9762 Test: 1.0410\n",
      "Epoch: 114, Loss: 0.3109 Val: 0.9179 Test: 1.0058\n",
      "Epoch: 115, Loss: 0.2744 Val: 0.8496 Test: 0.9325\n",
      "Epoch: 116, Loss: 0.2222 Val: 0.8085 Test: 0.9934\n",
      "Epoch: 117, Loss: 0.2632 Val: 0.7722 Test: 1.0377\n",
      "Epoch: 118, Loss: 0.3134 Val: 0.7287 Test: 1.0550\n",
      "Epoch: 119, Loss: 0.2651 Val: 0.6957 Test: 1.0634\n",
      "Epoch: 120, Loss: 0.3526 Val: 0.8115 Test: 0.9612\n",
      "Epoch: 121, Loss: 0.4817 Val: 0.9041 Test: 1.0412\n",
      "Epoch: 122, Loss: 0.2728 Val: 0.9822 Test: 1.1093\n",
      "Epoch: 123, Loss: 0.2708 Val: 1.0603 Test: 1.0811\n",
      "Epoch: 124, Loss: 0.2415 Val: 1.1250 Test: 1.0561\n",
      "Epoch: 125, Loss: 0.3521 Val: 1.1455 Test: 1.0411\n",
      "Epoch: 126, Loss: 0.2993 Val: 1.1100 Test: 1.0728\n",
      "Epoch: 127, Loss: 0.2738 Val: 0.9900 Test: 1.6407\n",
      "Epoch: 128, Loss: 0.2407 Val: 0.8267 Test: 1.8247\n",
      "Epoch: 129, Loss: 0.3203 Val: 0.7872 Test: 1.8402\n",
      "Epoch: 130, Loss: 0.2943 Val: 0.7550 Test: 1.8441\n",
      "Epoch: 131, Loss: 0.2848 Val: 0.7307 Test: 1.8391\n",
      "Epoch: 132, Loss: 0.2981 Val: 0.7471 Test: 1.8190\n",
      "Epoch: 133, Loss: 0.2402 Val: 0.7865 Test: 1.8072\n",
      "Epoch: 134, Loss: 0.2422 Val: 0.8210 Test: 1.8247\n",
      "Epoch: 135, Loss: 0.2805 Val: 0.8358 Test: 1.8407\n",
      "Epoch: 136, Loss: 0.3147 Val: 0.7983 Test: 1.7464\n",
      "Epoch: 137, Loss: 0.3144 Val: 0.7640 Test: 1.6510\n",
      "Epoch: 138, Loss: 0.3098 Val: 0.7643 Test: 1.6732\n",
      "Epoch: 139, Loss: 0.3725 Val: 0.7680 Test: 1.6656\n",
      "Epoch: 140, Loss: 0.2969 Val: 0.7790 Test: 1.6324\n",
      "Epoch: 141, Loss: 0.3052 Val: 0.7905 Test: 1.6329\n",
      "Epoch: 142, Loss: 0.2741 Val: 0.8174 Test: 1.6639\n",
      "Epoch: 143, Loss: 0.2290 Val: 0.8310 Test: 1.6804\n",
      "Epoch: 144, Loss: 0.2969 Val: 0.8361 Test: 1.6877\n",
      "Epoch: 145, Loss: 0.2646 Val: 0.8299 Test: 1.6839\n",
      "Epoch: 146, Loss: 0.3084 Val: 0.8192 Test: 1.6723\n",
      "Epoch: 147, Loss: 0.2355 Val: 0.8187 Test: 1.6625\n",
      "Epoch: 148, Loss: 0.1785 Val: 0.8306 Test: 1.6602\n",
      "Epoch: 149, Loss: 0.1329 Val: 0.8536 Test: 1.6617\n",
      "Epoch: 150, Loss: 0.2330 Val: 0.8393 Test: 1.6579\n",
      "Epoch: 151, Loss: 0.3249 Val: 0.8073 Test: 1.6555\n",
      "Epoch: 152, Loss: 0.3006 Val: 0.7753 Test: 1.6299\n",
      "Epoch: 153, Loss: 0.2401 Val: 0.7442 Test: 1.5694\n",
      "Epoch: 154, Loss: 0.2588 Val: 0.7202 Test: 1.5628\n",
      "Epoch: 155, Loss: 0.2673 Val: 0.7049 Test: 1.5861\n",
      "Epoch: 156, Loss: 0.2284 Val: 0.6932 Test: 1.5897\n",
      "Epoch: 157, Loss: 0.2726 Val: 0.6794 Test: 1.5915\n",
      "Epoch: 158, Loss: 0.3005 Val: 0.6902 Test: 1.5851\n",
      "Epoch: 159, Loss: 0.2949 Val: 0.7162 Test: 1.5209\n",
      "Epoch: 160, Loss: 0.2506 Val: 0.7192 Test: 1.5024\n",
      "Epoch: 161, Loss: 0.2449 Val: 0.7086 Test: 1.5071\n",
      "Epoch: 162, Loss: 0.2439 Val: 0.8304 Test: 1.5011\n",
      "Epoch: 163, Loss: 0.2349 Val: 0.9027 Test: 1.5369\n",
      "Epoch: 164, Loss: 0.2636 Val: 0.9385 Test: 1.5698\n",
      "Epoch: 165, Loss: 0.2671 Val: 0.9756 Test: 1.5277\n",
      "Epoch: 166, Loss: 0.2759 Val: 1.0035 Test: 1.5132\n",
      "Epoch: 167, Loss: 0.1317 Val: 1.0493 Test: 1.4503\n",
      "Epoch: 168, Loss: 0.5673 Val: 0.9455 Test: 1.6537\n",
      "Epoch: 169, Loss: 0.2631 Val: 0.8748 Test: 1.6366\n",
      "Epoch: 170, Loss: 0.5023 Val: 0.8803 Test: 1.6725\n",
      "Epoch: 171, Loss: 0.3165 Val: 0.8611 Test: 1.6663\n",
      "Epoch: 172, Loss: 0.4650 Val: 0.8639 Test: 1.6586\n",
      "Epoch: 173, Loss: 0.4261 Val: 0.8772 Test: 1.6649\n",
      "Epoch: 174, Loss: 0.3873 Val: 0.9024 Test: 1.7287\n",
      "Epoch: 175, Loss: 0.3159 Val: 1.0641 Test: 1.7142\n",
      "Epoch: 176, Loss: 0.4210 Val: 1.1000 Test: 1.6974\n",
      "Epoch: 177, Loss: 0.5116 Val: 1.0941 Test: 1.6664\n",
      "Epoch: 178, Loss: 0.4399 Val: 1.0479 Test: 1.6824\n",
      "Epoch: 179, Loss: 0.4252 Val: 0.9953 Test: 1.7140\n",
      "Epoch: 180, Loss: 0.3193 Val: 0.9456 Test: 1.7335\n",
      "Epoch: 181, Loss: 0.3110 Val: 0.9050 Test: 1.7525\n",
      "Epoch: 182, Loss: 0.3168 Val: 0.8760 Test: 1.7673\n",
      "Epoch: 183, Loss: 0.3250 Val: 0.8823 Test: 1.7885\n",
      "Epoch: 184, Loss: 0.2940 Val: 0.8833 Test: 1.8093\n",
      "Epoch: 185, Loss: 0.4275 Val: 0.8830 Test: 1.8202\n",
      "Epoch: 186, Loss: 0.3551 Val: 0.8935 Test: 1.8226\n",
      "Epoch: 187, Loss: 0.2634 Val: 0.9327 Test: 1.7681\n",
      "Epoch: 188, Loss: 0.2582 Val: 0.9091 Test: 1.5780\n",
      "Epoch: 189, Loss: 0.2835 Val: 0.9226 Test: 1.5602\n",
      "Epoch: 190, Loss: 0.3304 Val: 0.9443 Test: 1.5742\n",
      "Epoch: 191, Loss: 0.4618 Val: 0.9034 Test: 1.0610\n",
      "Epoch: 192, Loss: 0.7501 Val: 1.0602 Test: 1.1525\n",
      "Epoch: 193, Loss: 0.6624 Val: 1.0633 Test: 1.1990\n",
      "Epoch: 194, Loss: 0.7269 Val: 1.0464 Test: 1.2300\n",
      "Epoch: 195, Loss: 0.5550 Val: 1.0406 Test: 1.2556\n",
      "Epoch: 196, Loss: 0.3465 Val: 0.7807 Test: 1.2913\n",
      "Epoch: 197, Loss: 0.3986 Val: 0.9352 Test: 1.3172\n",
      "Epoch: 198, Loss: 0.3764 Val: 0.9754 Test: 1.2735\n",
      "Epoch: 199, Loss: 0.2349 Val: 0.9494 Test: 1.3171\n",
      "rip2\n",
      "\n",
      "Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C')\n",
      "RIP2(4)\n",
      "dict {0: {'train': [Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4c3CCCC4)c2c1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(Cl)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4cn[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)cc1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)(C)C')], 'test': [Data(x=[23, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3cc[nH]n3)c2c1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='O=C(Nc1ccccc1Cl)c1cnn2ccccc12'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ncc(F)cc34)c2c1'), Data(x=[24, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='Cc1cc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)n[nH]1'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccccc1-c1cnc2cc(OC)c(S(=O)(=O)C(C)(C)C)cn12'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OC(F)(F)F)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C(N)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ccc(F)cc34)c2c1'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C#N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4nc[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OC1CC1'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(Cl)cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Oc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Nc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OCCO)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)ccc1O'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(O)cc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CN1CCN(CCOc2cc3ncc(-c4cc(N)nc(Cl)c4)n3cc2S(=O)(=O)C(C)(C)C)CC1'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OCC(F)(F)F'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)Oc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COCCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='COCCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C')]}, 1: {'train': [Data(x=[23, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3cc[nH]n3)c2c1'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccccc1-c1cnc2cc(OC)c(S(=O)(=O)C(C)(C)C)cn12'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C#N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4nc[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OC1CC1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Oc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OCCO)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(O)cc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COCCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C')], 'test': [Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4c3CCCC4)c2c1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='O=C(Nc1ccccc1Cl)c1cnn2ccccc12'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ncc(F)cc34)c2c1'), Data(x=[24, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='Cc1cc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)n[nH]1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(Cl)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OC(F)(F)F)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C(N)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ccc(F)cc34)c2c1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4cn[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)cc1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(Cl)cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Nc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)ccc1O'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CN1CCN(CCOc2cc3ncc(-c4cc(N)nc(Cl)c4)n3cc2S(=O)(=O)C(C)(C)C)CC1'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OCC(F)(F)F'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)Oc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='COCCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C')]}, 2: {'train': [Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='O=C(Nc1ccccc1Cl)c1cnn2ccccc12'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OC(F)(F)F)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(Cl)cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Nc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)ccc1O'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CN1CCN(CCOc2cc3ncc(-c4cc(N)nc(Cl)c4)n3cc2S(=O)(=O)C(C)(C)C)CC1'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='COCCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C')], 'test': [Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4c3CCCC4)c2c1'), Data(x=[23, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3cc[nH]n3)c2c1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ncc(F)cc34)c2c1'), Data(x=[24, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='Cc1cc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)n[nH]1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(Cl)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccccc1-c1cnc2cc(OC)c(S(=O)(=O)C(C)(C)C)cn12'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C(N)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ccc(F)cc34)c2c1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4cn[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C#N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)cc1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4nc[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OC1CC1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Oc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OCCO)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(O)cc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OCC(F)(F)F'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)Oc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COCCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C')]}, 3: {'train': [Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ncc(F)cc34)c2c1'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C(N)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OCC(F)(F)F'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C')], 'test': [Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4c3CCCC4)c2c1'), Data(x=[23, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3cc[nH]n3)c2c1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='O=C(Nc1ccccc1Cl)c1cnn2ccccc12'), Data(x=[24, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='Cc1cc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)n[nH]1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(Cl)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccccc1-c1cnc2cc(OC)c(S(=O)(=O)C(C)(C)C)cn12'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OC(F)(F)F)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ccc(F)cc34)c2c1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4cn[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C#N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)cc1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4nc[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OC1CC1'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(Cl)cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Oc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Nc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OCCO)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)ccc1O'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(O)cc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CN1CCN(CCOc2cc3ncc(-c4cc(N)nc(Cl)c4)n3cc2S(=O)(=O)C(C)(C)C)CC1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)Oc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COCCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='COCCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C')]}, 4: {'train': [Data(x=[24, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='Cc1cc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)n[nH]1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ccc(F)cc34)c2c1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)Oc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C')], 'test': [Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4c3CCCC4)c2c1'), Data(x=[23, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3cc[nH]n3)c2c1'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='O=C(Nc1ccccc1Cl)c1cnn2ccccc12'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ncc(F)cc34)c2c1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(Cl)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccccc1-c1cnc2cc(OC)c(S(=O)(=O)C(C)(C)C)cn12'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OC(F)(F)F)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C(N)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4cn[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C#N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)cc1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4nc[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OC1CC1'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(Cl)cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Oc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Nc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OCCO)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)ccc1O'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(O)cc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CN1CCN(CCOc2cc3ncc(-c4cc(N)nc(Cl)c4)n3cc2S(=O)(=O)C(C)(C)C)CC1'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OCC(F)(F)F'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COCCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='COCCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C')]}}\n",
      "11\n",
      "42\n",
      "1\n",
      "3\n",
      "torch.Size([1428, 115])\n",
      "{'name': 'rip2', 'root': 'data', 'transform': None, 'pre_transform': <dataset.GenAtomFeatures object at 0x7fc06152ad90>, 'pre_filter': None, '_indices': [23, 26, 15, 46, 38, 6, 41, 37, 12, 0, 49, 35, 24, 27, 8, 16, 47, 44, 33, 36, 2, 22, 32, 19, 14, 4, 5, 7, 21, 25, 42, 48, 1, 9, 10, 45, 30, 51, 43, 20, 50, 28, 17, 40, 34, 52, 31, 11, 13, 29, 18, 39, 3], 'data': Data(x=[1428, 115], edge_index=[2, 3086], edge_attr=[3086, 7], y=[53, 1], smiles=[53]), 'slices': defaultdict(<class 'dict'>, {'x': tensor([   0,   26,   52,   79,  107,  133,  159,  188,  215,  241,  269,  295,\n",
      "         322,  345,  372,  400,  425,  451,  477,  505,  530,  556,  580,  609,\n",
      "         636,  664,  694,  721,  751,  781,  806,  832,  857,  884,  903,  932,\n",
      "         959,  988, 1016, 1044, 1072, 1099, 1124, 1151, 1176, 1201, 1229, 1263,\n",
      "        1290, 1317, 1345, 1373, 1400, 1428]), 'edge_index': tensor([   0,   56,  112,  172,  234,  290,  346,  408,  466,  522,  582,  638,\n",
      "         698,  748,  808,  868,  922,  978, 1034, 1094, 1148, 1204, 1256, 1318,\n",
      "        1376, 1436, 1500, 1560, 1624, 1688, 1742, 1798, 1852, 1912, 1954, 2016,\n",
      "        2074, 2136, 2196, 2256, 2316, 2374, 2428, 2486, 2540, 2594, 2654, 2728,\n",
      "        2786, 2844, 2906, 2968, 3026, 3086]), 'edge_attr': tensor([   0,   56,  112,  172,  234,  290,  346,  408,  466,  522,  582,  638,\n",
      "         698,  748,  808,  868,  922,  978, 1034, 1094, 1148, 1204, 1256, 1318,\n",
      "        1376, 1436, 1500, 1560, 1624, 1688, 1742, 1798, 1852, 1912, 1954, 2016,\n",
      "        2074, 2136, 2196, 2256, 2316, 2374, 2428, 2486, 2540, 2594, 2654, 2728,\n",
      "        2786, 2844, 2906, 2968, 3026, 3086]), 'y': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]), 'smiles': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53])}), '_data_list': [Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C#N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(O)cc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4cn[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OC1CC1'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COCCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)ccc1O'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)Oc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4c3CCCC4)c2c1'), Data(x=[23, 115], edge_index=[2, 50], edge_attr=[50, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3cc[nH]n3)c2c1'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4nc[nH]c4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Oc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(Cl)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccccc1-c1cnc2cc(OC)c(S(=O)(=O)C(C)(C)C)cn12'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1cccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[24, 115], edge_index=[2, 52], edge_attr=[52, 7], y=[1, 1], smiles='Cc1cc(Nc2ccnc3ccc(S(=O)(=O)C(C)(C)C)cc23)n[nH]1'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OCCO)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='CCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1cn2c(-c3cc(N)nc(Cl)c3)cnc2cc1OCC(F)(F)F'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='COCCOc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[30, 115], edge_index=[2, 64], edge_attr=[64, 7], y=[1, 1], smiles='Cc1[nH]nc(Nc2ccnc3cc(OC(F)(F)F)c(S(=O)(=O)C(C)(C)C)cc23)c1C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[26, 115], edge_index=[2, 56], edge_attr=[56, 7], y=[1, 1], smiles='COc1ccc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)cc1'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(N)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc4[nH]ncc4c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[19, 115], edge_index=[2, 42], edge_attr=[42, 7], y=[1, 1], smiles='O=C(Nc1ccccc1Cl)c1cnn2ccccc12'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc(Cl)cc(-c2cnc3cc(OC)c(S(=O)(=O)C(C)(C)C)cn23)c1'), Data(x=[29, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cc(Cl)cc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(C(=O)Nc3ccccc3C)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(C(N)=O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3cccc(O)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[25, 115], edge_index=[2, 54], edge_attr=[54, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(O)cc3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccc(C(N)=O)c(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[34, 115], edge_index=[2, 74], edge_attr=[74, 7], y=[1, 1], smiles='CN1CCN(CCOc2cc3ncc(-c4cc(N)nc(Cl)c4)n3cc2S(=O)(=O)C(C)(C)C)CC1'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(F)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='CCOc1cc2ncc(-c3cc(N)nc(Cl)c3)n2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ccc(F)cc34)c2c1'), Data(x=[28, 115], edge_index=[2, 62], edge_attr=[62, 7], y=[1, 1], smiles='CC(C)(C)S(=O)(=O)c1ccc2nccc(Nc3n[nH]c4ncc(F)cc34)c2c1'), Data(x=[27, 115], edge_index=[2, 58], edge_attr=[58, 7], y=[1, 1], smiles='COc1cc2nccc(Nc3n[nH]c(C)c3C)c2cc1S(=O)(=O)C(C)(C)C'), Data(x=[28, 115], edge_index=[2, 60], edge_attr=[60, 7], y=[1, 1], smiles='COc1cc2ncc(-c3ccnc(NC(C)=O)c3)n2cc1S(=O)(=O)C(C)(C)C')]}\n",
      "minv: 5.329999923706055\n",
      "maxv: 8.699999809265137\n",
      "emb_dim: 300\n",
      "Epoch: 000, Loss: 0.8010 Val: 2.2660 Test: 2.5714\n",
      "Epoch: 001, Loss: 0.8414 Val: 2.2286 Test: 2.5466\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_490620/3591247754.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mtrain_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mval_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mtest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_490620/3591247754.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuic/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuic/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuic/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cuic/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0m\u001b[1;32m     20\u001b[0m                                         self.exclude_keys)\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuic/lib/python3.8/site-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     67\u001b[0m         Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         batch, slice_dict, inc_dict = collate(\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mdata_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuic/lib/python3.8/site-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# Collate attributes into a unified representation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             value, slices, incs = _collate(attr, values, data_list, stores,\n\u001b[0m\u001b[1;32m     86\u001b[0m                                            increment)\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuic/lib/python3.8/site-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_incs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuic/lib/python3.8/site-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_incs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn.models import AttentiveFP\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_gz)\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn.models import AttentiveFP\n",
    "\n",
    "from model import GNN,GNN_graphpred\n",
    "from dataset import LSSInhibitor,GenAtomFeatures,GenAttentiveFeatures\n",
    "from loss import ada_batch_all_triplet_loss\n",
    "\n",
    "device = 'cuda:7'\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "lr = 0.0001\n",
    "decay = 0\n",
    "num_layer = 5\n",
    "emb_dim = 300\n",
    "dropout_ratio = 0\n",
    "JK = 'last'\n",
    "dataset = 'EAAT3'\n",
    "output_model_file = ''\n",
    "gnn_type = 'gin'\n",
    "seed = 0\n",
    "num_workers = 8\n",
    "mode = 'ada_batch_all_triplet_loss'   #ada_batch_all_triplet_loss,ada_batch_hard_triplet_loss,triplet_loss\n",
    "feature_type = 'custom'  #random,onehot,custom,pseudo\n",
    "graph_pooling = 'set2set2' #mean,last,sum,set2set,atention\n",
    "\n",
    "\n",
    "def train():\n",
    "    total_loss = total_examples = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        '''\n",
    "        data.x = data.x.to(torch.float32)\n",
    "        data.edge_index=data.edge_index.to(torch.long)\n",
    "        data.edge_attr=data.edge_attr.to(torch.float32)\n",
    "        data.batch=data.batch.to(torch.long)\n",
    "        '''\n",
    "        #out = model(float(data.x), data.edge_index.to(torch.long), data.edge_attr.to(torch.float32), data.batch.to(torch.long))\n",
    "        emb,pre = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "\n",
    "        #loss = F.mse_loss(out, data.y)\n",
    "        loss = ada_batch_all_triplet_loss(embeddings=emb, labels=data.y, prediction=pre, device=device, minv=minv, maxv=maxv, weight=0.5, cliff=2,squared=False)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "    return sqrt(total_loss / total_examples)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    mse = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        emb,pre = model(data.x.to(torch.float32), data.edge_index, data.edge_attr, data.batch)\n",
    "        pre = pre*(maxv-minv)+minv\n",
    "        mse.append(F.mse_loss(pre, data.y, reduction='none').cpu())\n",
    "        #print('mse:',mse)\n",
    "    return float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "\n",
    "\n",
    "for dataset_name in LSSInhibitor.names.keys():\n",
    "    \n",
    "    print(dataset_name + \"\\n\")\n",
    "    \n",
    "    path = './data'\n",
    "    \n",
    "    # use the attentiveFP node and edge features during the mol-2-graph transoformation\n",
    "    dataset = LSSInhibitor(path, name=dataset_name, pre_transform=GenAtomFeatures('custom')).shuffle()\n",
    "    print(dataset[0])\n",
    "    print(dataset[1:5])\n",
    "    \n",
    "    dt = sorted(dataset,key = lambda data:data.y )\n",
    "    dt_dict={}\n",
    "    for i in range(5):\n",
    "        dt_dict[i] = {'train':[],'test':[]}\n",
    "    \n",
    "    for i in range(len(dt)):\n",
    "        tmp = i % 5\n",
    "        for j in range(5):\n",
    "            if tmp == j:\n",
    "                dt_dict[j]['test'].append(dt[i])\n",
    "            else:\n",
    "                dt_dict[j]['train'].append(dt[i])\n",
    "  \n",
    "    print('dict',dt_dict)\n",
    "    print(len(dt_dict[0]['train']))\n",
    "    print(len(dt_dict[0]['test']))\n",
    "    train_data = DataLoader(dt_dict[0]['train'], batch_size=batch_size, shuffle=True)\n",
    "    test_data = DataLoader(dt_dict[0]['test'], batch_size=batch_size, shuffle=False)\n",
    "    print(len(train_data))\n",
    "    print(len(test_data))\n",
    "    exit(0)\n",
    "    #dataset = LSSInhibitor(path, name=dataset_name, pre_transform=GenAttentiveFeatures()).shuffle()\n",
    "    #dataset = MoleculeNet(path, name='FreeSolv', pre_transform=GenFeatures()).shuffle()\n",
    "    print(dataset.data.x.shape)\n",
    "    print(dataset.__dict__)\n",
    "    \n",
    "    \n",
    "    minv = 1e12\n",
    "    maxv = -1e12\n",
    "    for i in dataset:\n",
    "        if i.y<minv:\n",
    "            minv = i.y.item()\n",
    "        if i.y>maxv:\n",
    "            maxv = i.y.item()\n",
    "    print('minv:',minv) \n",
    "    print('maxv:',maxv)\n",
    "    \n",
    "    #batch_size = 8\n",
    "    \n",
    "    # train, valid, test splitting\n",
    "    N = len(dataset) // 5\n",
    "    val_dataset = dataset[:N]\n",
    "    test_dataset = dataset[N:2 * N]\n",
    "    train_dataset = dataset[2 * N:]\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = GNN_graphpred(num_layer, emb_dim, num_tasks = 1, JK = JK, drop_ratio =dropout_ratio,feature_type = feature_type,graph_pooling = graph_pooling, gnn_type = gnn_type).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
    "                                 weight_decay=decay)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_rmse = train()\n",
    "        val_rmse = test(val_loader)\n",
    "        test_rmse = test(test_loader)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_rmse:.4f} Val: {val_rmse:.4f} '\n",
    "              f'Test: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03b03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db495082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuic] *",
   "language": "python",
   "name": "conda-env-cuic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
